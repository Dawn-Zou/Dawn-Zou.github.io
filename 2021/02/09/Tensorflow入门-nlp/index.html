<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","version":"8.2.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="Tensorflow入门 - nlp">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow入门 - nlp">
<meta property="og:url" content="http://example.com/2021/02/09/Tensorflow%E5%85%A5%E9%97%A8-nlp/index.html">
<meta property="og:site_name" content="Dawn Zou&#39;s Blog">
<meta property="og:description" content="Tensorflow入门 - nlp">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-02-09T15:16:27.000Z">
<meta property="article:modified_time" content="2021-02-09T15:32:00.000Z">
<meta property="article:author" content="Dawn Zou">
<meta property="article:tag" content="Tensorflow">
<meta property="article:tag" content="nlp">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2021/02/09/Tensorflow%E5%85%A5%E9%97%A8-nlp/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>Tensorflow入门 - nlp | Dawn Zou's Blog</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Dawn Zou's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90"><span class="nav-number">1.</span> <span class="nav-text">文本生成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="nav-number">2.</span> <span class="nav-text">文本分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%92%8C%E9%A2%84%E6%B5%8B"><span class="nav-number">3.</span> <span class="nav-text">时间序列和预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E5%BA%8F%E4%BF%A1%E5%8F%B7%E7%94%9F%E6%88%90"><span class="nav-number">3.1.</span> <span class="nav-text">时序信号生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">时间序列预测方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN%E7%BD%91%E7%BB%9C%E6%A0%B7%E6%9C%AC"><span class="nav-number">3.3.</span> <span class="nav-text">RNN网络样本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RNN%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B"><span class="nav-number">3.4.</span> <span class="nav-text">RNN时间序列预测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%8C%E5%90%91LSTM%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B"><span class="nav-number">3.5.</span> <span class="nav-text">双向LSTM时间序列预测</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Dawn Zou"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Dawn Zou</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Dawn-Zou" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Dawn-Zou" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/02/09/Tensorflow%E5%85%A5%E9%97%A8-nlp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dawn Zou">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dawn Zou's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tensorflow入门 - nlp
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-02-09 23:16:27 / Modified: 23:32:00" itemprop="dateCreated datePublished" datetime="2021-02-09T23:16:27+08:00">2021-02-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/notes/" itemprop="url" rel="index"><span itemprop="name">notes</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">Tensorflow入门 - nlp</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h2><details>
<summary>文本生成-tensorflow</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, LSTM, Dense, Bidirectional</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(time.time())</span></span><br><span class="line">tokenizer = Tokenizer()</span><br><span class="line"></span><br><span class="line">data=<span class="string">&quot;In the town of Athy one Jeremy Lanigan \n Battered away til he hadnt a pound. \nHis father died and made him a man again \n Left him a farm and ten acres of ground. \nHe gave a grand party for friends and relations \nWho didnt forget him when come to the wall, \nAnd if youll but listen Ill make your eyes glisten \nOf the rows and the ructions of Lanigans Ball. \nMyself to be sure got free invitation, \nFor all the nice girls and boys I might ask, \nAnd just in a minute both friends and relations \nWere dancing round merry as bees round a cask. \nJudy ODaly, that nice little milliner, \nShe tipped me a wink for to give her a call, \nAnd I soon arrived with Peggy McGilligan \nJust in time for Lanigans Ball. \nThere were lashings of punch and wine for the ladies, \nPotatoes and cakes; there was bacon and tea, \nThere were the Nolans, Dolans, OGradys \nCourting the girls and dancing away. \nSongs they went round as plenty as water, \nThe harp that once sounded in Taras old hall,\nSweet Nelly Gray and The Rat Catchers Daughter,\nAll singing together at Lanigans Ball. \nThey were doing all kinds of nonsensical polkas \nAll round the room in a whirligig. \nJulia and I, we banished their nonsense \nAnd tipped them the twist of a reel and a jig. \nAch mavrone, how the girls got all mad at me \nDanced til youd think the ceiling would fall. \nFor I spent three weeks at Brooks Academy \nLearning new steps for Lanigans Ball. \nThree long weeks I spent up in Dublin, \nThree long weeks to learn nothing at all,\n Three long weeks I spent up in Dublin, \nLearning new steps for Lanigans Ball. \nShe stepped out and I stepped in again, \nI stepped out and she stepped in again, \nShe stepped out and I stepped in again, \nLearning new steps for Lanigans Ball. \nBoys were all merry and the girls they were hearty \nAnd danced all around in couples and groups, \nTil an accident happened, young Terrance McCarthy \nPut his right leg through miss Finnertys hoops. \nPoor creature fainted and cried Meelia murther, \nCalled for her brothers and gathered them all. \nCarmody swore that hed go no further \nTil he had satisfaction at Lanigans Ball. \nIn the midst of the row miss Kerrigan fainted, \nHer cheeks at the same time as red as a rose. \nSome of the lads declared she was painted, \nShe took a small drop too much, I suppose. \nHer sweetheart, Ned Morgan, so powerful and able, \nWhen he saw his fair colleen stretched out by the wall, \nTore the left leg from under the table \nAnd smashed all the Chaneys at Lanigans Ball. \nBoys, oh boys, twas then there were runctions. \nMyself got a lick from big Phelim McHugh. \nI soon replied to his introduction \nAnd kicked up a terrible hullabaloo. \nOld Casey, the piper, was near being strangled. \nThey squeezed up his pipes, bellows, chanters and all. \nThe girls, in their ribbons, they got all entangled \nAnd that put an end to Lanigans Ball.&quot;</span></span><br><span class="line"></span><br><span class="line">corpus = data.lower().split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">tokenizer.fit_on_texts(corpus)</span><br><span class="line">total_words = <span class="built_in">len</span>(tokenizer.word_index) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index)</span><br><span class="line">print(total_words)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_sequences = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> corpus:</span><br><span class="line">	token_list = tokenizer.texts_to_sequences([line])[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(token_list)):</span><br><span class="line">		n_gram_sequence = token_list[:i+<span class="number">1</span>]</span><br><span class="line">		input_sequences.append(n_gram_sequence)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pad sequences </span></span><br><span class="line">max_sequence_len = <span class="built_in">max</span>([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> input_sequences])</span><br><span class="line">input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=<span class="string">&#x27;pre&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create predictors and label</span></span><br><span class="line">xs, labels = input_sequences[:,:-<span class="number">1</span>],input_sequences[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)</span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;in&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;the&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;town&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;of&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;athy&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;one&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;jeremy&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;lanigan&#x27;</span>])</span><br><span class="line"></span><br><span class="line">print(xs[<span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(total_words, <span class="number">64</span>, input_length=max_sequence_len-<span class="number">1</span>))</span><br><span class="line">model.add(Bidirectional(LSTM(<span class="number">20</span>)))</span><br><span class="line">model.add(Dense(total_words, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">history = model.fit(xs, ys, epochs=<span class="number">500</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_graphs</span>(<span class="params">history, string</span>):</span></span><br><span class="line">  plt.plot(history.history[string])</span><br><span class="line">  plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">  plt.ylabel(string)</span><br><span class="line">  plt.show()</span><br><span class="line"> </span><br><span class="line">plot_graphs(history, <span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">seed_text = <span class="string">&quot;Laurence went to dublin&quot;</span></span><br><span class="line">next_words = <span class="number">100</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(next_words):</span><br><span class="line">	token_list = tokenizer.texts_to_sequences([seed_text])[<span class="number">0</span>]</span><br><span class="line">	token_list = pad_sequences([token_list], maxlen=max_sequence_len-<span class="number">1</span>, padding=<span class="string">&#x27;pre&#x27;</span>)</span><br><span class="line">	predicted = model.predict_classes(token_list, verbose=<span class="number">0</span>)</span><br><span class="line">	output_word = <span class="string">&quot;&quot;</span></span><br><span class="line">	<span class="keyword">for</span> word, index <span class="keyword">in</span> tokenizer.word_index.items():</span><br><span class="line">		<span class="keyword">if</span> index == predicted:</span><br><span class="line">			output_word = word</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">	seed_text += <span class="string">&quot; &quot;</span> + output_word</span><br><span class="line">print(seed_text) </span><br><span class="line"><span class="comment">#print(time.time())</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><details>
<summary>文本分类 - tensorflow</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">vocab_size = <span class="number">10000</span></span><br><span class="line">embedding_dim = <span class="number">16</span></span><br><span class="line">max_length = <span class="number">100</span></span><br><span class="line">trunc_type=<span class="string">&#x27;post&#x27;</span></span><br><span class="line">padding_type=<span class="string">&#x27;post&#x27;</span></span><br><span class="line">oov_tok = <span class="string">&quot;&lt;OOV&gt;&quot;</span></span><br><span class="line">training_size = <span class="number">20000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../../tensorflow_datasets/sarcasm.json&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    datastore = json.load(f)</span><br><span class="line"></span><br><span class="line">sentences = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> datastore:</span><br><span class="line">    sentences.append(item[<span class="string">&#x27;headline&#x27;</span>])</span><br><span class="line">    labels.append(item[<span class="string">&#x27;is_sarcastic&#x27;</span>])</span><br><span class="line"></span><br><span class="line">training_sentences = sentences[<span class="number">0</span>:training_size]</span><br><span class="line">testing_sentences = sentences[training_size:]</span><br><span class="line">training_labels = labels[<span class="number">0</span>:training_size]</span><br><span class="line">testing_labels = labels[training_size:]</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)</span><br><span class="line">tokenizer.fit_on_texts(training_sentences)</span><br><span class="line"></span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line"></span><br><span class="line">training_sequences = tokenizer.texts_to_sequences(training_sentences)</span><br><span class="line">training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line"></span><br><span class="line">testing_sequences = tokenizer.texts_to_sequences(testing_sentences)</span><br><span class="line">testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),</span><br><span class="line">    tf.keras.layers.GlobalAveragePooling1D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">24</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,optimizer=<span class="string">&#x27;adam&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">30</span></span><br><span class="line">training_padded = np.array(training_padded)</span><br><span class="line">training_labels = np.array(training_labels)</span><br><span class="line">testing_padded = np.array(testing_padded)</span><br><span class="line">testing_labels = np.array(testing_labels)</span><br><span class="line">history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_graphs</span>(<span class="params">history, string</span>):</span></span><br><span class="line">  plt.plot(history.history[string])</span><br><span class="line">  plt.plot(history.history[<span class="string">&#x27;val_&#x27;</span>+string])</span><br><span class="line">  plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">  plt.ylabel(string)</span><br><span class="line">  plt.legend([string, <span class="string">&#x27;val_&#x27;</span>+string])</span><br><span class="line">  plt.show()</span><br><span class="line">  </span><br><span class="line">plot_graphs(history, <span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">plot_graphs(history, <span class="string">&quot;loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">reverse_word_index = <span class="built_in">dict</span>([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode_sentence</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join([reverse_word_index.get(i, <span class="string">&#x27;?&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> text])</span><br><span class="line"></span><br><span class="line">print(decode_sentence(training_padded[<span class="number">0</span>]))</span><br><span class="line">print(training_sentences[<span class="number">2</span>])</span><br><span class="line">print(labels[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">e = model.layers[<span class="number">0</span>]</span><br><span class="line">weights = e.get_weights()[<span class="number">0</span>]</span><br><span class="line">print(weights.shape) <span class="comment"># shape: (vocab_size, embedding_dim)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">out_v = io.<span class="built_in">open</span>(<span class="string">&#x27;vecs.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">out_m = io.<span class="built_in">open</span>(<span class="string">&#x27;meta.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> word_num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, vocab_size):</span><br><span class="line">  word = reverse_word_index[word_num]</span><br><span class="line">  embeddings = weights[word_num]</span><br><span class="line">  out_m.write(word + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">  out_v.write(<span class="string">&#x27;\t&#x27;</span>.join([<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> embeddings]) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">out_v.close()</span><br><span class="line">out_m.close()</span><br><span class="line"></span><br><span class="line">sentence = [<span class="string">&quot;granny starting to fear spiders in the garden might be real&quot;</span>, <span class="string">&quot;game of thrones season finale showing this sunday night&quot;</span>]</span><br><span class="line">sequences = tokenizer.texts_to_sequences(sentence)</span><br><span class="line">padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line">print(model.predict(padded))</span><br></pre></td></tr></table></figure>
</details>

<h2 id="时间序列和预测"><a href="#时间序列和预测" class="headerlink" title="时间序列和预测"></a>时间序列和预测</h2><h3 id="时序信号生成"><a href="#时序信号生成" class="headerlink" title="时序信号生成"></a>时序信号生成</h3><h3 id="时间序列预测方法"><a href="#时间序列预测方法" class="headerlink" title="时间序列预测方法"></a>时间序列预测方法</h3><p>传统：移动平均法</p>
<h3 id="RNN网络样本"><a href="#RNN网络样本" class="headerlink" title="RNN网络样本"></a>RNN网络样本</h3><ol>
<li>生成窗口数据并转化为列表</li>
</ol>
<details>
<summary>RNN网络样本</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="comment"># %tensorflow_version only exists in Colab.</span></span><br><span class="line">  %tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成序列数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> dataset:</span><br><span class="line">   print(val.numpy())</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 获得窗口数据，窗口大小为5</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> window_dataset <span class="keyword">in</span> dataset:</span><br><span class="line">  <span class="keyword">for</span> val <span class="keyword">in</span> window_dataset:</span><br><span class="line">    print(val.numpy(), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">  print()</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 去掉不完整的数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> window_dataset <span class="keyword">in</span> dataset:</span><br><span class="line">  <span class="keyword">for</span> val <span class="keyword">in</span> window_dataset:</span><br><span class="line">    print(val.numpy(), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">  print()</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 转为numpy列表</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.batch(<span class="number">2</span>).perfetch(<span class="number">1</span>)	</span><br><span class="line"><span class="keyword">for</span> window <span class="keyword">in</span> dataset:</span><br><span class="line">  print(window.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打散数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(x.numpy(), y.numpy())</span><br><span class="line">  </span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(x.numpy(), y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据批量，每两个数据为一批次</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(<span class="string">&quot;x = &quot;</span>, x.numpy())</span><br><span class="line">  print(<span class="string">&quot;y = &quot;</span>, y.numpy())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h3 id="RNN时间序列预测"><a href="#RNN时间序列预测" class="headerlink" title="RNN时间序列预测"></a>RNN时间序列预测</h3><details>
<summary>RNN时间序列预测</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="comment"># %tensorflow_version only exists in Colab.</span></span><br><span class="line">  %tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_series</span>(<span class="params">time, series, <span class="built_in">format</span>=<span class="string">&quot;-&quot;</span>, start=<span class="number">0</span>, end=<span class="literal">None</span></span>):</span></span><br><span class="line">    plt.plot(time[start:end], series[start:end], <span class="built_in">format</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Value&quot;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trend</span>(<span class="params">time, slope=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> slope * time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonal_pattern</span>(<span class="params">season_time</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Just an arbitrary pattern, you can change it if you wish&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.where(season_time &lt; <span class="number">0.4</span>,</span><br><span class="line">                    np.cos(season_time * <span class="number">2</span> * np.pi),</span><br><span class="line">                    <span class="number">1</span> / np.exp(<span class="number">3</span> * season_time))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonality</span>(<span class="params">time, period, amplitude=<span class="number">1</span>, phase=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Repeats the same pattern at each period&quot;&quot;&quot;</span></span><br><span class="line">    season_time = ((time + phase) % period) / period</span><br><span class="line">    <span class="keyword">return</span> amplitude * seasonal_pattern(season_time)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise</span>(<span class="params">time, noise_level=<span class="number">1</span>, seed=<span class="literal">None</span></span>):</span></span><br><span class="line">    rnd = np.random.RandomState(seed)</span><br><span class="line">    <span class="keyword">return</span> rnd.randn(<span class="built_in">len</span>(time)) * noise_level</span><br><span class="line"></span><br><span class="line">time = np.arange(<span class="number">4</span> * <span class="number">365</span> + <span class="number">1</span>, dtype=<span class="string">&quot;float32&quot;</span>)  <span class="comment">#1461</span></span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">series = trend(time, <span class="number">0.1</span>)  </span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">amplitude = <span class="number">40</span></span><br><span class="line">slope = <span class="number">0.05</span></span><br><span class="line">noise_level = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the series</span></span><br><span class="line">series = baseline + trend(time, slope) + seasonality(time, period=<span class="number">365</span>, amplitude=amplitude)</span><br><span class="line"><span class="comment"># Update with noise</span></span><br><span class="line">series += noise(time, noise_level, seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">split_time = <span class="number">1000</span></span><br><span class="line">time_train = time[:split_time]</span><br><span class="line">x_train = series[:split_time]</span><br><span class="line">time_valid = time[split_time:]</span><br><span class="line">x_valid = series[split_time:]</span><br><span class="line"></span><br><span class="line">window_size = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">shuffle_buffer_size = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="comment">#参数说明： 序列数据（一维数组），窗口大小，批次大小，随机缓存大小</span></span><br><span class="line"><span class="comment">#输出： (特征， 标签)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">windowed_dataset</span>(<span class="params">series, window_size, batch_size, shuffle_buffer</span>):</span></span><br><span class="line">  dataset = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">  dataset = dataset.window(window_size + <span class="number">1</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(window_size + <span class="number">1</span>))</span><br><span class="line">  dataset = dataset.shuffle(shuffle_buffer).<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>]))</span><br><span class="line">  dataset = dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">    print(<span class="string">&quot;x = &quot;</span>, x.numpy())</span><br><span class="line">    print(<span class="string">&quot;y = &quot;</span>, y.numpy())</span><br><span class="line">  <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建SimpleRNN神经网络，使用LR_scheduler机制调整学习率</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">train_set = windowed_dataset(x_train, window_size, batch_size=<span class="number">128</span>, shuffle_buffer=shuffle_buffer_size)</span><br><span class="line"><span class="comment">#神经网络的搭建</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment">#匿名层：处理输入参数，将输入</span></span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),  <span class="comment"># tf.expand_dims(x,axis=-1) x是input,-1代表最后一维，对应y=时间序列</span></span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>, return_sequences=<span class="literal">True</span>),<span class="comment">#RNN单元数量为40，返回输出序列中的完整序列</span></span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>), <span class="comment">#神经元个数为1</span></span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)<span class="comment">#x的规则</span></span><br><span class="line">])</span><br><span class="line"><span class="comment">#运用lrscheduler来进行学习率的调节 epoch=10的-8次 * 10^(epoch/20)</span></span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    <span class="keyword">lambda</span> epoch: <span class="number">1e-8</span> * <span class="number">10</span>**(epoch / <span class="number">20</span>))</span><br><span class="line"><span class="comment">#SGD随机梯度下降，lr=学习率，momentum：动量参数</span></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">1e-8</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment">#model.compile()方法用于在配置训练方法时候，告知训练时所用的优化器、损失函数和准确率评测</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),<span class="comment">#损失函数</span></span><br><span class="line">              optimizer=optimizer,<span class="comment">#优化器</span></span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])<span class="comment">#准确率评判</span></span><br><span class="line">history = model.fit(train_set, epochs=<span class="number">100</span>, callbacks=[lr_schedule])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.semilogx(history.history[<span class="string">&quot;lr&quot;</span>], history.history[<span class="string">&quot;loss&quot;</span>])</span><br><span class="line">plt.axis([<span class="number">1e-8</span>, <span class="number">1e-4</span>, <span class="number">0</span>, <span class="number">30</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建SimpleRNN神经网络，不调整学习率</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size=<span class="number">128</span>, shuffle_buffer=shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>, return_sequences=<span class="literal">True</span>),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#在需要将隐层的结果作为下一层的输入时，选择return_sequences=True</span></span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">5e-5</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),</span><br><span class="line">              optimizer=optimizer,</span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">history = model.fit(dataset,epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">forecast=[]</span><br><span class="line"><span class="keyword">for</span> time <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(series) - window_size):</span><br><span class="line"><span class="comment">#增加一个轴</span></span><br><span class="line">  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))</span><br><span class="line"></span><br><span class="line">forecast = forecast[split_time-window_size:]</span><br><span class="line">results = np.array(forecast)[:, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plot_series(time_valid, x_valid)</span><br><span class="line">plot_series(time_valid, results)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line">tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从训练集和测试集上获取结果列表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.image  <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">mae=history.history[<span class="string">&#x27;mae&#x27;</span>]</span><br><span class="line">loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs=<span class="built_in">range</span>(<span class="built_in">len</span>(loss)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(ehs, mae, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">epochs_zoom = epochs[<span class="number">20</span>:]</span><br><span class="line">mae_zoom = mae[<span class="number">20</span>:]</span><br><span class="line">loss_zoom = loss[<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot Zoomed MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs_zoom, mae_zoom, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs_zoom, loss_zoom, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h3 id="双向LSTM时间序列预测"><a href="#双向LSTM时间序列预测" class="headerlink" title="双向LSTM时间序列预测"></a>双向LSTM时间序列预测</h3><details>
<summary>双向LSTM时间序列预测</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="comment"># 搭建两个LSTM神经网络，一个使用LR_scheduler机制调整学习率，另一个不做处理</span></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># https://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line">!pip install tf-nightly-<span class="number">2.0</span>-preview</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_series</span>(<span class="params">time, series, <span class="built_in">format</span>=<span class="string">&quot;-&quot;</span>, start=<span class="number">0</span>, end=<span class="literal">None</span></span>):</span></span><br><span class="line">    plt.plot(time[start:end], series[start:end], <span class="built_in">format</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Value&quot;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trend</span>(<span class="params">time, slope=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> slope * time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonal_pattern</span>(<span class="params">season_time</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Just an arbitrary pattern, you can change it if you wish&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.where(season_time &lt; <span class="number">0.4</span>,</span><br><span class="line">                    np.cos(season_time * <span class="number">2</span> * np.pi),</span><br><span class="line">                    <span class="number">1</span> / np.exp(<span class="number">3</span> * season_time))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonality</span>(<span class="params">time, period, amplitude=<span class="number">1</span>, phase=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Repeats the same pattern at each period&quot;&quot;&quot;</span></span><br><span class="line">    season_time = ((time + phase) % period) / period</span><br><span class="line">    <span class="keyword">return</span> amplitude * seasonal_pattern(season_time)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise</span>(<span class="params">time, noise_level=<span class="number">1</span>, seed=<span class="literal">None</span></span>):</span></span><br><span class="line">    rnd = np.random.RandomState(seed)</span><br><span class="line">    <span class="keyword">return</span> rnd.randn(<span class="built_in">len</span>(time)) * noise_level</span><br><span class="line"></span><br><span class="line">time = np.arange(<span class="number">4</span> * <span class="number">365</span> + <span class="number">1</span>, dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">series = trend(time, <span class="number">0.1</span>)  </span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">amplitude = <span class="number">40</span></span><br><span class="line">slope = <span class="number">0.05</span></span><br><span class="line">noise_level = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the series</span></span><br><span class="line">series = baseline + trend(time, slope) + seasonality(time, period=<span class="number">365</span>, amplitude=amplitude)</span><br><span class="line"><span class="comment"># Update with noise</span></span><br><span class="line">series += noise(time, noise_level, seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">split_time = <span class="number">1000</span></span><br><span class="line">time_train = time[:split_time]</span><br><span class="line">x_train = series[:split_time]</span><br><span class="line">time_valid = time[split_time:]</span><br><span class="line">x_valid = series[split_time:]</span><br><span class="line"></span><br><span class="line">window_size = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">shuffle_buffer_size = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">windowed_dataset</span>(<span class="params">series, window_size, batch_size, shuffle_buffer</span>):</span></span><br><span class="line">  dataset = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">  dataset = dataset.window(window_size + <span class="number">1</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(window_size + <span class="number">1</span>))</span><br><span class="line">  dataset = dataset.shuffle(shuffle_buffer).<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>]))</span><br><span class="line">  dataset = dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">return</span> dataset</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 搭建双向LSTM神经网络，使用LR_scheduler机制调整学习率</span></span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    <span class="keyword">lambda</span> epoch: <span class="number">1e-8</span> * <span class="number">10</span>**(epoch / <span class="number">20</span>))</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">1e-8</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),</span><br><span class="line">              optimizer=optimizer,</span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line"><span class="comment"># 回调函数  使用LR_scheduler机制调整学习率</span></span><br><span class="line">history = model.fit(dataset, epochs=<span class="number">100</span>, callbacks=[lr_schedule])</span><br><span class="line"></span><br><span class="line">plt.semilogx(history.history[<span class="string">&quot;lr&quot;</span>], history.history[<span class="string">&quot;loss&quot;</span>])</span><br><span class="line">plt.axis([<span class="number">1e-8</span>, <span class="number">1e-4</span>, <span class="number">0</span>, <span class="number">30</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建双向LSTM神经网络，对学习率不作处理</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-5</span>, momentum=<span class="number">0.9</span>),metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">history = model.fit(dataset,epochs=<span class="number">100</span>,verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">forecast = []</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> time <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(series) - window_size):</span><br><span class="line">  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))</span><br><span class="line"></span><br><span class="line">forecast = forecast[split_time-window_size:]</span><br><span class="line">results = np.array(forecast)[:, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plot_series(time_valid, x_valid)</span><br><span class="line">plot_series(time_valid, results)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line">tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image  <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">mae=history.history[<span class="string">&#x27;mae&#x27;</span>]</span><br><span class="line">loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs=<span class="built_in">range</span>(<span class="built_in">len</span>(loss)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs, mae, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">epochs_zoom = epochs[<span class="number">20</span>:]</span><br><span class="line">mae_zoom = mae[<span class="number">20</span>:]</span><br><span class="line">loss_zoom = loss[<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot Zoomed MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs_zoom, mae_zoom, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs_zoom, loss_zoom, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整不同的学习率和神经网络层数来训练</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>))</span><br><span class="line">model.fit(dataset,epochs=<span class="number">100</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>))</span><br><span class="line">model.fit(dataset,epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</details>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
              <a href="/tags/nlp/" rel="tag"># nlp</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/02/09/pyspark-udf-hive-udf/" rel="prev" title="pyspark udf & hive udf">
                  <i class="fa fa-chevron-left"></i> pyspark udf & hive udf
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/02/12/Tensorflow%E5%85%A5%E9%97%A8-%E5%AE%98%E6%96%B9/" rel="next" title="Tensorflow入门 - 官方">
                  Tensorflow入门 - 官方 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dawn Zou</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/local-search.js"></script>






  




  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'none'
      },
      options: {
        renderActions: {
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</body>
</html>
