<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hive/spark调优</title>
    <url>/2021/02/13/Hive%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h2 id="产生大量小文件的问题"><a href="#产生大量小文件的问题" class="headerlink" title="产生大量小文件的问题"></a>产生大量小文件的问题</h2><p>原因：</p>
<ol>
<li>数据源本身就是就含大量小文件</li>
<li>动态分区插入数据,没有Shuffle的情况下,输入端有多少个逻辑分片,对应的HadoopRDD就会产生多少个HadoopPartition,每个Partition对应于Spark作业的Task（个数为M）,分区数为N.最好的情况就是（M=N） &amp;&amp; （M中的数据也是根据N来预先打散的）,那就刚好写N个文件；最差的情况下,每个Task中都有各个分区的记录,那文件数最终文件数将达到M * N个.这种情况下是极易产生小文件的</li>
</ol>
<ul>
<li>Spark如何控制文件你输出数量？<br>用coalesce或者repartition,num=(1.0*(df.count())/7000000).ceil.toInt</li>
<li>Spark让输出文件大小均匀？<br>在sparksql的查询最后加上distribute by rand()<br>distribute by是控制在map端如何拆分数据给reduce端的,hive会根据distribute by后面列,对应reduce的个数进行分发,默认是采用hash算法.<br>rand()方法会生成一个[0,1]之间的随机数,通过随机数进行数据的划分,因为每次都随机的,所以每个reducer上的数据会很均匀<br>补充：<br>文件数是spark.sql.shuffle.partitions * N,因为rand函数一般会把数据打散的非常均匀.当spark.sql.shuffle.partitions设置过大时,小文件问题就产生了；当spark.sql.shuffle.partitions设置过小时,任务的并行度就下降了,性能随之受到影响.<br>根据分区字段进行shuffle,但是这种情况下也容易出现数据倾斜的问题.<br>将两者结合：在之前的sql上加上distribute by ss_sold_date_sk,cast(rand() * 5 as int), 这个类似于我们处理数据倾斜问题时候给字段加上后缀的形式</li>
</ul>
<h2 id="调整数据块大小对性能的影响"><a href="#调整数据块大小对性能的影响" class="headerlink" title="调整数据块大小对性能的影响"></a>调整数据块大小对性能的影响</h2><ul>
<li>Map读取大文件（总体相同,数据分布不均）与Map读取普通文件<br>读大文件需要网络传输<br>在不同环境下,执行结果有差异：<br>比如当集群的规模较小,整个集群的内网带宽资源充裕的情况下,因网络传输带来的时间损耗和其他原因（例如,hdfs的namenode节点资源紧张,定位查找更多的文件需要耗费更多时间等）相比所造成的时间延迟可能还少的时候,读取大文件的执行速度可能会比读取普通文件稍快.</li>
</ul>
<h2 id="不同数据格式对性能的提升"><a href="#不同数据格式对性能的提升" class="headerlink" title="不同数据格式对性能的提升"></a>不同数据格式对性能的提升</h2><p>Hive提供的格式有TEXT、SequenceFile、RCFile、ORC和Parquet等。<br>SequenceFile是一个二进制key/value对结构的平面文件，在早期的Hadoop平台上被广泛用于MapReduce输出/输出格式，以及作为数据存储格式。<br>Parquet 是一种列式数据存储格式，可以兼容多种计算引擎，如MapRedcue 和Spark等，对多层嵌套的数据结构提供了良好的性能支持，是目前Hive 生产环境中数据存储的主流选择之一。<br>ORC（Optimized Row Columnar）优化是对RCFile的一种优化，它提供了一种高效的方式来存储Hive数据，同时也能够提高Hive的读取、写入和处理数据的性能，能够兼容多种计算引擎。<br>事实上，在实际的生产环境中，ORC已经成为了Hive在数据存储上的主流选择之一。</p>
<h2 id="不同的表的设计对性能的影响"><a href="#不同的表的设计对性能的影响" class="headerlink" title="不同的表的设计对性能的影响"></a>不同的表的设计对性能的影响</h2><ul>
<li>分桶<br>每一个表（table）或者分区，Hive可以进一步组织成桶。也就是说，桶是更为细粒度的数据范围划分。<br>分桶的原理是对分桶列取Hash 值（Hive 中使用hash 函数），再用该Hash值模桶数（Hive中使用pmod函数），用Hive的函数可以表达为pmod(hash分桶列，桶数)。<br>分桶不会改变原有表/分区目录的组织方式，只是更改了数据在文件中的分布<br>分区提供了一个隔离数据和优化查询的便利的方式.但是当分区的数量过多时，会产生过多的小分区,这样会给namenode带来较大的压力.分桶试讲数据集分解成更容易管理的若干部分的另一个技术.</li>
<li>优势<br>  1.分桶加快了join查询的速度.<br>  2.使取样(sampling)更加的高效<br><code>select * from t_bucket tablesample(bucket x out of y on xx);</code></li>
</ul>
<h2 id="通过改写SQL，实现对计算引擎执行过程的干预"><a href="#通过改写SQL，实现对计算引擎执行过程的干预" class="headerlink" title="通过改写SQL，实现对计算引擎执行过程的干预"></a>通过改写SQL，实现对计算引擎执行过程的干预</h2><ol>
<li>尽可能使用SQL 自带的高级命令做操作。例如，在多维统计分析中使用cube、grouping set和rollup等命令去替代多个SQL子句的union all。</li>
<li>分解count(distinct)的SQL优化。（distinct会将b列所有的数据保存到内存中，形成一个类似hash的结构，速度是十分的块；但是在大数据背景下，因为b列所有的值都会形成以key值，极有可能发生OOM）</li>
</ol>
<h2 id="通过SQL-hint语法，实现对计算引擎执行过程的干预"><a href="#通过SQL-hint语法，实现对计算引擎执行过程的干预" class="headerlink" title="通过SQL-hint语法，实现对计算引擎执行过程的干预"></a>通过SQL-hint语法，实现对计算引擎执行过程的干预</h2><ol>
<li>使用MapJoin Hint的SQL<figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line"># -MAPJOIN() 括号中指定的是数据量较小的表，表示在Map阶段完成a,b表的连接</span><br><span class="line"><span class="keyword">SELECT</span> <span class="comment">/* + MAPJOIN(b) */</span> a.<span class="keyword">key</span>,b.<span class="keyword">value</span> <span class="keyword">FROM</span> a <span class="keyword">JOIN</span> b <span class="keyword">on</span> a.<span class="keyword">key</span> = b.<span class="keyword">key</span></span><br></pre></td></tr></table></figure></li>
<li>STREAMTABLE(),括号中指定的是数据量较大的表，<br>默认情况下在reduce阶段进行连接，hive把左表中的数据放在缓存中，右表的数据作为流</li>
</ol>
<h2 id="通过数据库开放的一些配置开关，实现对计算引擎的干预。"><a href="#通过数据库开放的一些配置开关，实现对计算引擎的干预。" class="headerlink" title="通过数据库开放的一些配置开关，实现对计算引擎的干预。"></a>通过数据库开放的一些配置开关，实现对计算引擎的干预。</h2><ol>
<li>开启向量化查询开关<br>开启hive.vectorized.execution.enabled操作，默认是关闭状态，将一个普通的查询转化为向量化查询执行是一个Hive 特性。它大大减少了扫描、过滤器、聚合和连接等典型查询操作的CPU 使用。</li>
</ol>
<figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.vectorized.execution.enabled <span class="comment">=true</span>;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>开启并行执行。 <figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.<span class="built_in">exec</span>.parallel=<span class="literal">true</span>; <span class="comment">//打开任务并行执行</span></span><br><span class="line"><span class="built_in">set</span> hive.<span class="built_in">exec</span>.parallel.thread.number=<span class="number">16</span>; <span class="comment">//同一个 sql 允许最大并行度，默认为 8</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="开发规范"><a href="#开发规范" class="headerlink" title="开发规范"></a>开发规范</h2><ul>
<li>尽可能使用SQL 自带的高级命令做操作。例如，在多维统计分析中使用cube、grouping set和rollup等命令去替代多个SQL子句的union all。</li>
<li>使用set命令，进行配置属性的更改，要有注释。</li>
<li>代码里面不允许包含对表/分区/列的DDL语句，除了新增和删除分区。</li>
<li>Hive SQL 更加适合处理多条数据组合的数据集，不适合处理单条数据，且单条数据之间存在顺序依赖等逻辑关系。例如，有A、B、C 3行数据，当A符合某种条件才能处理B行时，只有A、B符合某种条件，才能处理C行。</li>
<li>保持一个查询语句所处理的表类型单一。例如，一个SQL语句中的表都是ORC类型的表，或者都是Parquet表。</li>
<li>关注NULL值的数据处理。</li>
<li>SQL表连接的条件列和查询的过滤列最好要有分区列和分桶列。</li>
<li>存在多层嵌套，内层嵌套表的过滤条件不要写到外层 </li>
</ul>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux应用</title>
    <url>/2021/02/13/Linux%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h2 id="crontab"><a href="#crontab" class="headerlink" title="crontab"></a>crontab</h2><p>定时任务</p>
<ul>
<li>使用方法<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">*</span> <span class="emphasis">* *</span> <span class="emphasis">* *</span> command</span><br></pre></td></tr></table></figure>
分 0-59<br>时 0-23<br>日 1-31<br>月 1-12<br>周 0-7</li>
</ul>
<p>常用语句</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">crontab -l</span></span><br><span class="line"><span class="attribute">crontab -e</span></span><br></pre></td></tr></table></figure>
<p>另外需注意<br>crontab调用python需加入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">. /etc/profile</span><br><span class="line">. ~/.bash_profil</span><br></pre></td></tr></table></figure>

<h2 id="date"><a href="#date" class="headerlink" title="date"></a>date</h2><figure class="highlight cos"><table><tr><td class="code"><pre><span class="line">the_date=`date -<span class="keyword">d</span> <span class="string">&quot;10 days ago&quot;</span> +<span class="built_in">%Y</span>-<span class="built_in">%m</span>-<span class="built_in">%d</span>`</span><br><span class="line">`date -<span class="keyword">d</span> <span class="string">&quot;+1 day $startdate&quot;</span> +<span class="built_in">%Y</span>-<span class="built_in">%m</span>-<span class="built_in">%d</span>`</span><br><span class="line">`date -<span class="keyword">d</span><span class="string">&quot;1month $the_month&quot;</span> +<span class="built_in">%Y</span>-<span class="built_in">%m</span>-<span class="built_in">%d</span>`</span><br></pre></td></tr></table></figure>
<h2 id="文件文本的处理"><a href="#文件文本的处理" class="headerlink" title="文件文本的处理"></a>文件文本的处理</h2><h2 id="Linux-文件基本属性"><a href="#Linux-文件基本属性" class="headerlink" title="Linux 文件基本属性"></a>Linux 文件基本属性</h2><p>chown (change ownerp) ： 修改所属用户与组。<br><code>chown bin install.log</code><br>chmod (change mode) ： 修改用户的权限。<br> [4+2+1][4+0+1][4+0+0]=754<br><code> chmod [-R] xyz 文件或目录</code><br><code>chmod u=rwx,g=rx,o=r 文件名</code><br>在 Linux 中我们可以使用 ll 或者 ls –l 命令来显示一个文件的属性以及文件所属的用户和组<br>从左至右用 0-9 这些数字来表示。<br>第 0 位确定文件类型，第 1-3 位确定属主（该文件的所有者）拥有该文件的权限。<br>第4-6位确定属组（所有者的同组用户）拥有该文件的权限，第7-9位确定其他用户拥有该文件的权限。<br>其中，第 1、4、7 位表示读权限，如果用 r 字符表示，则有读权限，如果用 - 字符表示，则没有读权限；<br>第 2、5、8 位表示写权限，如果用 w 字符表示，则有写权限，如果用 - 字符表示没有写权限；第 3、6、9 位表示可执行权限，如果用 x 字符表示，则有执行权限，如果用 - 字符表示，则没有执行权限。</p>
<h2 id="Linux-文件与目录管理"><a href="#Linux-文件与目录管理" class="headerlink" title="Linux 文件与目录管理"></a>Linux 文件与目录管理</h2><p>绝对路径：<br>路径的写法，由根目录 / 写起，例如： /usr/share/doc 这个目录。<br>相对路径：<br>路径的写法，不是由 / 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成： cd ../man 这就是相对路径的写法。<br>ls（英文全拼：list files）: 列出目录及文件名<br>cd（英文全拼：change directory）：切换目录<br>pwd（英文全拼：print work directory）：显示目前的目录<br>mkdir（英文全拼：make directory）：创建一个新的目录 <code>mkdir -p test1/test2/test3/test4</code><br>rmdir（英文全拼：remove directory）：删除一个空的目录<br>cp（英文全拼：copy file）: 复制文件或目录<br>rm（英文全拼：remove）: 删除文件或目录<br>mv（英文全拼：move file）: 移动文件与目录，或修改文件与目录的名称<br>你可以使用 man [命令] 来查看各个命令的使用文档，如 ：man cp</p>
<h2 id="Linux-文件查看"><a href="#Linux-文件查看" class="headerlink" title="Linux 文件查看"></a>Linux 文件查看</h2><p>cat  由第一行开始显示文件内容<br>tac  从最后一行开始显示，可以看出 tac 是 cat 的倒着写！<br>nl   显示的时候，顺道输出行号！<br>more 一页一页的显示文件内容<br>less 与 more 类似，但是比 more 更好的是，他可以往前翻页！<br>head 只看头几行<code>head -n 20 /etc/man.config</code><br>tail 只看尾巴几行</p>
<h2 id="Linux-用户和用户组管理"><a href="#Linux-用户和用户组管理" class="headerlink" title="Linux 用户和用户组管理"></a>Linux 用户和用户组管理</h2><h2 id="Linux-磁盘管理"><a href="#Linux-磁盘管理" class="headerlink" title="Linux 磁盘管理"></a>Linux 磁盘管理</h2><p>Linux磁盘管理好坏直接关系到整个系统的性能问题。<br>Linux磁盘管理常用三个命令为df、du和fdisk。<br>df：列出文件系统的整体磁盘使用量<br>du：检查磁盘空间使用量</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="deletion">-a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。</span></span><br><span class="line"><span class="deletion">-h ：以人们较易读的容量格式 (G/M) 显示；</span></span><br><span class="line"><span class="deletion">-s ：列出总量而已，而不列出每个各别的目录占用容量；</span></span><br><span class="line"><span class="deletion">-S ：不包括子目录下的总计，与 -s 有点差别。</span></span><br><span class="line"><span class="deletion">-k ：以 KBytes 列出容量显示；</span></span><br><span class="line"><span class="deletion">-m ：以 MBytes 列出容量显示；</span></span><br></pre></td></tr></table></figure>
<p>fdisk：用于磁盘分区<br>Linux 的磁盘挂载使用 mount 命令，卸载使用 umount 命令。</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">[root@www ~]# mkdir <span class="regexp">/mnt/</span>hdc6</span><br><span class="line">[root@www ~]# mount <span class="regexp">/dev/</span>hdc6 <span class="regexp">/mnt/</span>hdc6</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="yum"><a href="#yum" class="headerlink" title="yum"></a>yum</h2><p>（ Yellow dog Updater, Modified）是一个在 Fedora 和 RedHat 以及 SUSE 中的 Shell 前端软件包管理器。<br>基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。<br>yum 提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。</p>
<ol>
<li>列出所有可更新的软件清单命令：yum check-update</li>
<li>更新所有软件命令：yum update</li>
<li>仅安装指定的软件命令：yum install <package_name></li>
<li>仅更新指定的软件命令：yum update <package_name></li>
<li>列出所有可安裝的软件清单命令：yum list</li>
<li>删除软件包命令：yum remove <package_name></li>
<li>查找软件包命令：yum search <keyword></li>
<li>清除缓存命令:<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">yum <span class="built_in">clean</span> packag<span class="symbol">es:</span> 清除缓存目录下的软件包</span><br><span class="line">yum <span class="built_in">clean</span> heade<span class="symbol">rs:</span> 清除缓存目录下的 headers</span><br><span class="line">yum <span class="built_in">clean</span> oldheade<span class="symbol">rs:</span> 清除缓存目录下旧的 headers</span><br><span class="line">yum <span class="built_in">clean</span>, yum <span class="built_in">clean</span> all (= yum <span class="built_in">clean</span> packages; yum <span class="built_in">clean</span> oldheaders) <span class="symbol">:</span>清除缓存目录下的软件包及旧的 headers</span><br></pre></td></tr></table></figure>
<h2 id="Linux-apt-命令"><a href="#Linux-apt-命令" class="headerlink" title="Linux apt 命令"></a>Linux apt 命令</h2><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2>Shell是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。<br>Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。<br>Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。<br>本教程关注的是 Bash，也就是 Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。<br>在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。<br>运行 Shell 脚本有两种方法：<br>1、作为可执行程序<br>将上面的代码保存为 test.sh，并 cd 到相应目录：<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">chmod +x ./<span class="keyword">test</span>.sh  <span class="comment">#使脚本具有执行权限</span></span><br><span class="line">./<span class="keyword">test</span>.sh  <span class="comment">#执行脚本</span></span><br></pre></td></tr></table></figure>
注意，一定要写成 ./test.sh，而不是 test.sh，运行其它二进制的程序也一样，直接写 test.sh，linux 系统会去 PATH 里寻找有没有叫 test.sh 的，而只有 /bin, /sbin, /usr/bin，/usr/sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 test.sh 是会找不到命令的，要用 ./test.sh 告诉系统说，就在当前目录找。<br>2、作为解释器参数<br>这种运行方式是，直接运行解释器，其参数就是 shell 脚本的文件名，如：<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/bin/</span>sh test.sh</span><br><span class="line"><span class="regexp">/bin/</span>php test.php</span><br></pre></td></tr></table></figure>
<h2 id="shell变量"><a href="#shell变量" class="headerlink" title="shell变量"></a>shell变量</h2>定义变量时，变量名不加美元符号（$，PHP语言中变量需要）使用一个定义过的变量，只要在变量名前面加美元符号即可<br>变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界<br>只读变量<br>使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。<br>下面的例子尝试更改只读变量，结果报错：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">myUrl=<span class="string">&quot;https://www.google.com&quot;</span></span><br><span class="line"><span class="built_in">readonly</span> myUrl</span><br><span class="line">myUrl=<span class="string">&quot;https://www.runoob.com&quot;</span></span><br></pre></td></tr></table></figure>
变量类型<br>运行shell时，会同时存在三种变量：</li>
</ol>
<ol>
<li>局部变量 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。</li>
<li>环境变量 所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。</li>
<li>shell变量 shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行<h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2>字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号。<br>单引号<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">str</span>=<span class="string">&#x27;this is a string&#x27;</span></span><br></pre></td></tr></table></figure>
单引号字符串的限制：<br>单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；<br>单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。<br>双引号<figure class="highlight smalltalk"><table><tr><td class="code"><pre><span class="line">your_name=<span class="string">&#x27;runoob&#x27;</span></span><br><span class="line">str=<span class="comment">&quot;Hello, I know you are \&quot;</span><span class="string">$y</span>our_name\<span class="comment">&quot;! \n&quot;</span></span><br><span class="line">echo -e <span class="string">$s</span>tr</span><br></pre></td></tr></table></figure>
输出结果为：<br>Hello, I know you are “runoob”!<br>双引号的优点：<br>双引号里可以有变量<br>双引号里可以出现转义字符<br>拼接字符串<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="attribute">your_name</span>=<span class="string">&quot;runoob&quot;</span></span><br><span class="line"><span class="comment"># 使用双引号拼接</span></span><br><span class="line"><span class="attribute">greeting</span>=<span class="string">&quot;hello, &quot;</span><span class="variable">$your_name</span><span class="string">&quot; !&quot;</span></span><br><span class="line"><span class="attribute">greeting_1</span>=<span class="string">&quot;hello, <span class="variable">$&#123;your_name&#125;</span> !&quot;</span></span><br><span class="line">echo <span class="variable">$greeting</span>  <span class="variable">$greeting_1</span></span><br><span class="line"><span class="comment"># 使用单引号拼接</span></span><br><span class="line"><span class="attribute">greeting_2</span>=<span class="string">&#x27;hello, &#x27;</span><span class="variable">$your_name</span><span class="string">&#x27; !&#x27;</span></span><br><span class="line"><span class="attribute">greeting_3</span>=<span class="string">&#x27;hello, $&#123;your_name&#125; !&#x27;</span></span><br><span class="line">echo <span class="variable">$greeting_2</span>  <span class="variable">$greeting_3</span></span><br></pre></td></tr></table></figure>
输出结果为：<br>hello, runoob ! hello, runoob !<br>hello, runoob ! hello, ${your_name} !<br>获取字符串长度<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">string=<span class="string">&quot;abcd&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#string&#125;</span> <span class="comment">#输出 4</span></span><br></pre></td></tr></table></figure>
提取子字符串<br>以下实例从字符串第 2 个字符开始截取 4 个字符：<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">string</span>=<span class="string">&quot;runoob is a great site&quot;</span></span><br><span class="line"><span class="keyword">echo</span> $&#123;<span class="keyword">string</span>:<span class="number">1</span>:<span class="number">4</span>&#125; <span class="comment"># 输出 unoo</span></span><br></pre></td></tr></table></figure>
注意：第一个字符的索引值为 0。<br>查找子字符串<br>查找字符 i 或 o 的位置(哪个字母先出现就计算哪个)：<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">string</span>=<span class="string">&quot;runoob is a great site&quot;</span></span><br><span class="line"><span class="keyword">echo</span> `expr index <span class="string">&quot;<span class="subst">$string</span>&quot;</span> io`  <span class="comment"># 输出 4</span></span><br></pre></td></tr></table></figure>
注意： 以上脚本中 ` 是反引号，而不是单引号 ‘，不要看错了哦。<h2 id="Shell-数组"><a href="#Shell-数组" class="headerlink" title="Shell 数组"></a>Shell 数组</h2>bash支持一维数组（不支持多维数组），并且没有限定数组的大小。<br>类似于 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。<br>定义数组<br>在 Shell 中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为：<br>数组名=(值1 值2 … 值n)<br>例如：<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">array_name</span>=(value<span class="number">0</span> value<span class="number">1</span> value<span class="number">2</span> value<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
或者<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">array</span>_name=(</span><br><span class="line">value0</span><br><span class="line">value1</span><br><span class="line">value2</span><br><span class="line">value3</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
还可以单独定义数组的各个分量：<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">array_name</span>[<span class="number">0</span>]=value<span class="number">0</span></span><br><span class="line"><span class="attribute">array_name</span>[<span class="number">1</span>]=value<span class="number">1</span></span><br><span class="line"><span class="attribute">array_name</span>[n]=valuen</span><br></pre></td></tr></table></figure>
可以不使用连续的下标，而且下标的范围没有限制。<br>读取数组<br>读取数组元素值的一般格式是：<br>${数组名[下标]}<br>例如：<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">valuen</span>=<span class="variable">$&#123;array_name[n]&#125;</span></span><br></pre></td></tr></table></figure>
使用 @ 符号可以获取数组中的所有元素，例如：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;array_name[@]&#125;</span></span><br></pre></td></tr></table></figure>
获取数组的长度<br>获取数组长度的方法与获取字符串长度的方法相同，例如：<br>取得数组元素的个数<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">length</span>=<span class="variable">$&#123;#array_name[@]&#125;</span></span><br></pre></td></tr></table></figure>
或者<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">length</span>=<span class="variable">$&#123;#array_name[*]&#125;</span></span><br></pre></td></tr></table></figure>
取得数组单个元素的长度<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">lengthn</span>=<span class="variable">$&#123;#array_name[n]&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Shell-注释"><a href="#Shell-注释" class="headerlink" title="Shell 注释"></a>Shell 注释</h2>以 # 开头的行就是注释，会被解释器忽略。<br>多行注释<br>多行注释还可以使用以下格式：<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line">:&lt;&lt;EOF</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">EOF</span><br><span class="line">EOF 也可以使用其他符号:</span><br><span class="line"></span><br><span class="line">:&lt;&lt;&#x27;</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">&#x27;</span><br><span class="line"></span><br><span class="line">:&lt;&lt;!</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">注释内容...</span><br><span class="line">!</span><br></pre></td></tr></table></figure>
<h2 id="Shell-传递参数"><a href="#Shell-传递参数" class="headerlink" title="Shell 传递参数"></a>Shell 传递参数</h2>我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n。<br>n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……<br>实例<br>以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名（包含文件路径）：<br>$#    传递到脚本的参数个数<br>$*    以一个单字符串显示所有向脚本传递的参数。<br>如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。<br>$$    脚本运行的当前进程ID号<br>$!    后台运行的最后一个进程的ID号<br>$@    与$*相同，但是使用时加引号，并在引号中返回每个参数。<br>如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。<br>$-    显示Shell使用的当前选项，与set命令功能相同。<br>$?    显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。<h2 id="Shell-基本运算符"><a href="#Shell-基本运算符" class="headerlink" title="Shell 基本运算符"></a>Shell 基本运算符</h2>Shell 和其他编程语言一样，支持多种运算符，包括：</li>
</ol>
<p>算数运算符<br>关系运算符<br>布尔运算符<br>字符串运算符<br>文件测试运算符<br>原生bash不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。<br>expr 是一款表达式计算工具，使用它能完成表达式的求值操作。<br>例如，两个数相加(注意使用的是反引号 ` 而不是单引号 ‘)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">val=`expr 2 + 2`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;两数之和为 : <span class="variable">$val</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。<br>完整的表达式要被 <code> </code> 包含，注意这个字符不是常用的单引号，在 Esc 键下边。</p>
<ul>
<li>   加法    <code>expr $a + $b</code> 结果为 30。</li>
</ul>
<ul>
<li>   减法    <code>expr $a - $b</code> 结果为 -10。</li>
</ul>
<ul>
<li>   乘法    <code>expr $a \* $b</code> 结果为  200。<br>/    除法    <code>expr $b / $a</code> 结果为 2。<br>%    取余    <code>expr $b % $a</code> 结果为 0。<br>=    赋值    a=$b 将把变量 b 的值赋给 a。<br>==    相等。用于比较两个数字，相同则返回 true。    [ $a == $b ] 返回 false。<br>!=    不相等。用于比较两个数字，不相同则返回 true。    [ $a != $b ] 返回 true。<br>注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。<br>关系运算符</li>
</ul>
<p>-eq    检测两个数是否相等，相等返回 true。    [ $a -eq $b ] 返回 false。<br>-ne    检测两个数是否不相等，不相等返回 true。    [ $a -ne $b ] 返回 true。<br>-gt    检测左边的数是否大于右边的，如果是，则返回 true。    [ $a -gt $b ] 返回 false。<br>-lt    检测左边的数是否小于右边的，如果是，则返回 true。    [ $a -lt $b ] 返回 true。<br>-ge    检测左边的数是否大于等于右边的，如果是，则返回 true。    [ $a -ge $b ] 返回 false。<br>-le    检测左边的数是否小于等于右边的，如果是，则返回 true。    [ $a -le $b ] 返回 true。<br>布尔运算符<br>!    非运算，表达式为 true 则返回 false，否则返回 true。    [ ! false ] 返回 true。<br>-o    或运算，有一个表达式为 true 则返回 true。    [ $a -lt 20 -o $b -gt 100 ] 返回 true。<br>-a    与运算，两个表达式都为 true 才返回 true。    [ $a -lt 20 -a $b -gt 100 ] 返回 false。<br>逻辑运算符<br>&amp;&amp;    逻辑的 AND    <code>[[ $a -lt 100 &amp;&amp; $b -gt 100 ]] </code>返回 false<br>||    逻辑的 OR    <code>[[ $a -lt 100 || $b -gt 100 ]]</code> 返回 true<br>字符串运算符<br>=    检测两个字符串是否相等，相等返回 true。    [ $a = $b ] 返回 false。<br>!=    检测两个字符串是否不相等，不相等返回 true。    [ $a != $b ] 返回 true。<br>-z    检测字符串长度是否为0，为0返回 true。    [ -z $a ] 返回 false。<br>-n    检测字符串长度是否不为 0，不为 0 返回 true。    [ -n “$a” ] 返回 true。<br>$    检测字符串是否为空，不为空返回 true。    [ $a ] 返回 true。<br>文件测试运算符<br>文件测试运算符用于检测 Unix 文件的各种属性。<br>-b file    检测文件是否是块设备文件，如果是，则返回 true。    [ -b $file ] 返回 false。<br>-c file    检测文件是否是字符设备文件，如果是，则返回 true。    [ -c $file ] 返回 false。<br>-d file    检测文件是否是目录，如果是，则返回 true。    [ -d $file ] 返回 false。<br>-f file    检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。    [ -f $file ] 返回 true。<br>-g file    检测文件是否设置了 SGID 位，如果是，则返回 true。    [ -g $file ] 返回 false。<br>-k file    检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。    [ -k $file ] 返回 false。<br>-p file    检测文件是否是有名管道，如果是，则返回 true。    [ -p $file ] 返回 false。<br>-u file    检测文件是否设置了 SUID 位，如果是，则返回 true。    [ -u $file ] 返回 false。<br>-r file    检测文件是否可读，如果是，则返回 true。    [ -r $file ] 返回 true。<br>-w file    检测文件是否可写，如果是，则返回 true。    [ -w $file ] 返回 true。<br>-x file    检测文件是否可执行，如果是，则返回 true。    [ -x $file ] 返回 true。<br>-s file    检测文件是否为空（文件大小是否大于0），不为空返回 true。    [ -s $file ] 返回 true。<br>-e file    检测文件（包括目录）是否存在，如果是，则返回 true。    [ -e $file ] 返回 true。<br>Shell echo命令<br>Shell 的 echo 指令与 PHP 的 echo 指令类似，都是用于字符串的输出。命令格式：</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">echo</span> <span class="keyword">string</span></span><br></pre></td></tr></table></figure>
<p>您可以使用echo实现更复杂的输出格式控制。<br>1.显示普通字符串:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;It is a test&quot;</span></span><br></pre></td></tr></table></figure>
<p>这里的双引号完全可以省略，以下命令与上面实例效果一致：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> It is a <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>2.显示转义字符</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">echo <span class="string">&quot;\&quot;</span>It <span class="keyword">is</span> a test\<span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>结果将是:<br>3.显示变量<br>read 命令从标准输入中读取一行,并把输入行的每个字段的值指定给 shell 变量</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">read</span> name </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$name</span> It is a test&quot;</span></span><br></pre></td></tr></table></figure>
<p>以上代码保存为 test.sh，name 接收标准输入的变量，结果将是:<br>[root@www ~]# sh test.sh<br>OK                     #标准输入<br>OK It is a test        #输出<br>4.显示换行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;OK! \n&quot;</span> <span class="comment"># -e 开启转义</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;It is a test&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出结果：<br>OK!</p>
<p>It is a test<br>5.显示不换行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;OK! \c&quot;</span> <span class="comment"># -e 开启转义 \c 不换行</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;It is a test&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<p>OK! It is a test<br>6.显示结果定向至文件<br>echo “It is a test” &gt; myfile<br>7.原样输出字符串，不进行转义或取变量(用单引号)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;$name\&quot;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<p>$name&quot;<br>8.显示命令执行结果</p>
<figure class="highlight dos"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> `<span class="built_in">date</span>`</span><br></pre></td></tr></table></figure>
<p>注意： 这里使用的是反引号 `, 而不是单引号 ‘。</p>
<p>结果将显示当前日期</p>
<p>Thu Jul 24 10:08:46 CST 2014</p>
<h2 id="Shell-printf-命令"><a href="#Shell-printf-命令" class="headerlink" title="Shell printf 命令"></a>Shell printf 命令</h2><p>printf 命令的语法：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>  format-<span class="built_in">string</span>  [arguments...]</span><br></pre></td></tr></table></figure>
<p>参数说明：<br>format-string: 为格式控制字符串<br>arguments: 为参数列表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br><span class="line"> </span><br><span class="line"><span class="built_in">printf</span> <span class="string">&quot;%-10s %-8s %-4s\n&quot;</span> 姓名 性别 体重kg  </span><br><span class="line"><span class="built_in">printf</span> <span class="string">&quot;%-10s %-8s %-4.2f\n&quot;</span> 郭靖 男 66.1234 </span><br><span class="line"><span class="built_in">printf</span> <span class="string">&quot;%-10s %-8s %-4.2f\n&quot;</span> 杨过 男 48.6543 </span><br><span class="line"><span class="built_in">printf</span> <span class="string">&quot;%-10s %-8s %-4.2f\n&quot;</span> 郭芙 女 47.9876</span><br></pre></td></tr></table></figure>
<p>执行脚本，输出结果如下所示：</p>
<p>姓名     性别   体重kg<br>郭靖     男      66.12<br>杨过     男      48.65<br>郭芙     女      47.99<br>%s %c %d %f 都是格式替代符，％s 输出一个字符串，％d 整型输出，％c 输出一个字符，％f 输出实数，以小数形式输出。</p>
<p>%-10s 指一个宽度为 10 个字符（- 表示左对齐，没有则表示右对齐），任何字符都会被显示在 10 个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。</p>
<p>%-4.2f 指格式化为小数，其中 .2 指保留2位小数。</p>
<h2 id="Shell-test-命令"><a href="#Shell-test-命令" class="headerlink" title="Shell test 命令"></a>Shell test 命令</h2><p>Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。</p>
<h2 id="Shell-流程控制"><a href="#Shell-流程控制" class="headerlink" title="Shell 流程控制"></a>Shell 流程控制</h2><figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> condition</span><br><span class="line">then</span><br><span class="line">    <span class="keyword">command</span>1 </span><br><span class="line">    <span class="keyword">command</span>2</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="keyword">command</span>N </span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ $(ps -ef | grep -c <span class="string">&quot;ssh&quot;</span>) -gt 1 ]; <span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&quot;true&quot;</span>; <span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> condition</span><br><span class="line">then</span><br><span class="line">    <span class="keyword">command</span>1 </span><br><span class="line">    <span class="keyword">command</span>2</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="keyword">command</span>N</span><br><span class="line">else</span><br><span class="line">    <span class="keyword">command</span></span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> condition1</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    command1</span><br><span class="line"><span class="keyword">elif</span> condition2 </span><br><span class="line"><span class="keyword">then</span> </span><br><span class="line">    command2</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    commandN</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>for 循环</p>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">for var in item1 item2 <span class="string">...</span> itemN</span><br><span class="line">do</span><br><span class="line">    <span class="keyword">command</span>1</span><br><span class="line">    <span class="keyword">command</span>2</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="keyword">command</span>N</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">for</span> var in item<span class="number">1</span> item<span class="number">2</span> ... itemN; do command<span class="number">1</span>; command<span class="number">2</span>… done;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> condition</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">command</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line"><span class="keyword">until</span> condition</span><br><span class="line"><span class="built_in">do</span></span><br><span class="line">    <span class="keyword">command</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">case 值 in</span><br><span class="line">模式1)</span><br><span class="line">    <span class="keyword">command</span>1</span><br><span class="line">    <span class="keyword">command</span>2</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="keyword">command</span>N</span><br><span class="line">    ;;</span><br><span class="line">模式2）</span><br><span class="line">    <span class="keyword">command</span>1</span><br><span class="line">    <span class="keyword">command</span>2</span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="keyword">command</span>N</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;输入 1 到 4 之间的数字:&#x27;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;你输入的数字为:&#x27;</span></span><br><span class="line"><span class="built_in">read</span> aNum</span><br><span class="line"><span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span></span><br><span class="line">    1)  <span class="built_in">echo</span> <span class="string">&#x27;你选择了 1&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line">    2)  <span class="built_in">echo</span> <span class="string">&#x27;你选择了 2&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line">    3)  <span class="built_in">echo</span> <span class="string">&#x27;你选择了 3&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line">    4)  <span class="built_in">echo</span> <span class="string">&#x27;你选择了 4&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line">    *)  <span class="built_in">echo</span> <span class="string">&#x27;你没有输入 1 到 4 之间的数字&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">while</span> :</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">&quot;输入 1 到 5 之间的数字:&quot;</span></span><br><span class="line">    <span class="built_in">read</span> aNum</span><br><span class="line">    <span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span></span><br><span class="line">        1|2|3|4|5) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字为 <span class="variable">$aNum</span>!&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">        *) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字不是 1 到 5 之间的! 游戏结束&quot;</span></span><br><span class="line">            <span class="built_in">break</span></span><br><span class="line">        ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">while</span> :</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> -n <span class="string">&quot;输入 1 到 5 之间的数字: &quot;</span></span><br><span class="line">    <span class="built_in">read</span> aNum</span><br><span class="line">    <span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span></span><br><span class="line">        1|2|3|4|5) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字为 <span class="variable">$aNum</span>!&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">        *) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字不是 1 到 5 之间的!&quot;</span></span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;游戏结束&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h2 id="Shell-函数"><a href="#Shell-函数" class="headerlink" title="Shell 函数"></a>Shell 函数</h2><p>shell中函数的定义格式如下：</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">[ <span class="keyword">function</span> <span class="title">]</span> funname [()]</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    action;</span><br><span class="line"></span><br><span class="line">    [<span class="keyword">return</span> <span class="type">int</span>;]</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">demoFun</span></span>()&#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;这是我的第一个 shell 函数!&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-----函数开始执行-----&quot;</span></span><br><span class="line">demoFun</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-----函数执行完毕-----&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">funWithReturn</span></span>()&#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;这个函数会对输入的两个数字进行相加运算...&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;输入第一个数字: &quot;</span></span><br><span class="line">    <span class="built_in">read</span> aNum</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;输入第二个数字: &quot;</span></span><br><span class="line">    <span class="built_in">read</span> anotherNum</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;两个数字分别为 <span class="variable">$aNum</span> 和 <span class="variable">$anotherNum</span> !&quot;</span></span><br><span class="line">    <span class="built_in">return</span> $((<span class="variable">$aNum</span>+<span class="variable">$anotherNum</span>))</span><br><span class="line">&#125;</span><br><span class="line">funWithReturn</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;输入的两个数字之和为 $? !&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">funWithParam</span></span>()&#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;第一个参数为 <span class="variable">$1</span> !&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;第二个参数为 <span class="variable">$2</span> !&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;第十个参数为 <span class="variable">$10</span> !&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;第十个参数为 <span class="variable">$&#123;10&#125;</span> !&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;第十一个参数为 <span class="variable">$&#123;11&#125;</span> !&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;参数总数有 <span class="variable">$#</span> 个!&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;作为一个字符串输出所有参数 $* !&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">funWithParam 1 2 3 4 5 6 7 8 9 34 73</span><br></pre></td></tr></table></figure>
<p>注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数。<br>另外，还有几个特殊字符用来处理参数：<br>参数处理    说明<br>$#    传递到脚本或函数的参数个数<br>$*    以一个单字符串显示所有向脚本传递的参数<br>$$    脚本运行的当前进程ID号<br>$!    后台运行的最后一个进程的ID号<br>$@    与$*相同，但是使用时加引号，并在引号中返回每个参数。<br>$-    显示Shell使用的当前选项，与set命令功能相同。<br>$?    显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。</p>
<h2 id="Shell-输入-输出重定向"><a href="#Shell-输入-输出重定向" class="headerlink" title="Shell 输入/输出重定向"></a>Shell 输入/输出重定向</h2><p>大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回​​到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端。</p>
<p>重定向命令列表如下：</p>
<p>命令    说明<br>command &gt; file    将输出重定向到 file。<br>command &lt; file    将输入重定向到 file。<br>command &gt;&gt; file    将输出以追加的方式重定向到 file。<br>n &gt; file    将文件描述符为 n 的文件重定向到 file。<br>n &gt;&gt; file    将文件描述符为 n 的文件以追加的方式重定向到 file。<br>n &gt;&amp; m    将输出文件 m 和 n 合并。<br>n &lt;&amp; m    将输入文件 m 和 n 合并。<br>&lt;&lt; tag    将开始标记 tag 和结束标记 tag 之间的内容作为输入。<br>输出重定向<br>重定向一般通过在命令间插入特定的符号来实现。特别的，这些符号的语法如下所示:</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">$ wc -l users</span><br><span class="line">       2 users</span><br><span class="line">也可以将输入重定向到<span class="built_in"> users </span>文件：</span><br><span class="line"></span><br><span class="line">$  wc -l &lt; users</span><br><span class="line">       2 </span><br></pre></td></tr></table></figure>
<p>注意：上面两个例子的结果不同：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。<br>     <figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">command1 &lt; <span class="keyword">infile</span> &gt; <span class="keyword">outfile</span></span><br></pre></td></tr></table></figure><br>同时替换输入和输出，执行command1，从文件infile读取内容，然后将输出写入到outfile中。<br>重定向深入讲解<br>一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：<br>标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。<br>标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。<br>标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。<br>默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。<br>如果希望 stderr 重定向到 file，可以这样写：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">command</span> <span class="number">2</span>&gt;<span class="keyword">file</span></span><br></pre></td></tr></table></figure>
<p>如果希望 stderr 追加到 file 文件末尾，可以这样写：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">command</span> <span class="number">2</span>&gt;&gt;<span class="keyword">file</span></span><br></pre></td></tr></table></figure>
<p>2 表示标准错误文件(stderr)。<br>如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">command</span> &gt; <span class="keyword">file</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">command</span> &gt;&gt; <span class="keyword">file</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>如果希望对 stdin 和 stdout 都重定向，可以这样写：</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">command</span> &lt; <span class="title">file1</span> &gt;<span class="title">file2</span></span><br></pre></td></tr></table></figure>
<p>command 命令将 stdin 重定向到 file1，将 stdout 重定向到 file2。<br>Here Document<br>Here Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。<br>它的基本的形式如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">command</span> &lt;&lt; <span class="string">delimiter</span></span><br><span class="line"><span class="string">    document</span></span><br><span class="line"><span class="string">delimiter</span></span><br></pre></td></tr></table></figure>
<p>它的作用是将两个 delimiter 之间的内容(document) 作为输入传递给 command。<br>注意：<br>结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。<br>开始的delimiter前后的空格会被忽略掉。<br>实例<br>在命令行中通过 wc -l 命令计算 Here Document 的行数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ wc -l &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">    欢迎来到</span></span><br><span class="line"><span class="string">    菜鸟教程</span></span><br><span class="line"><span class="string">    www.runoob.com</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>
<p>/dev/null 文件<br>如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null：</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">$ command &gt; <span class="regexp">/dev/</span><span class="literal">null</span></span><br></pre></td></tr></table></figure>
<p>/dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到”禁止输出”的效果。<br>如果希望屏蔽 stdout 和 stderr，可以这样写：</p>
<figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">$ command &gt; <span class="regexp">/dev/</span><span class="literal">null</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>注意：0 是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。<br>这里的 2 和 &gt; 之间不可以有空格，2&gt; 是一体的时候才表示错误输出<br>和其他语言一样，Shell 也可以包含外部脚本。这样可以很方便的封装一些公用的代码作为一个独立的文件。</p>
<p>Shell 文件包含的语法格式如下：</p>
<p>. filename   # 注意点号(.)和文件名中间有一空格</p>
<p>或</p>
<p>source filename<br>实例<br>创建两个 shell 脚本文件。</p>
<p>test1.sh 代码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;http://www.runoob.com&quot;</span></span><br></pre></td></tr></table></figure>
<p>test2.sh 代码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># author:菜鸟教程</span></span><br><span class="line"><span class="comment"># url:www.runoob.com</span></span><br></pre></td></tr></table></figure>
<p>使用 . 号来引用test1.sh 文件</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="bullet">. </span>./test1.sh</span><br></pre></td></tr></table></figure>
<p>或者使用以下包含文件代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ./test1.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;菜鸟教程官网地址：<span class="variable">$url</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>接下来，我们为 test2.sh 添加可执行权限并执行：</p>
<figure class="highlight gams"><table><tr><td class="code"><pre><span class="line"><span class="symbol">$</span> chmod +x test2.sh </span><br><span class="line"><span class="symbol">$</span> ./test2.sh </span><br><span class="line">菜鸟教程官网地址：http:<span class="comment">//www.runoob.com</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Lookalike 与 PU-learning</title>
    <url>/2021/02/20/Lookalike-%E4%B8%8E-PU-learning/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://www.ichdata.com/lookalike.html">https://www.ichdata.com/lookalike.html</a><br><a href="https://www.ichdata.com/ad-tech/ca">https://www.ichdata.com/ad-tech/ca</a><br><a href="https://zhuanlan.zhihu.com/p/42435966">https://zhuanlan.zhihu.com/p/42435966</a><br><a href="https://yan_liu.gitbooks.io/algorithm/content/lookalikepu-learning.html">https://yan_liu.gitbooks.io/algorithm/content/lookalikepu-learning.html</a></p>
</blockquote>
<p>扩大投放人群<br>基于现有人群，通过数据分析，找到这一批与现有人群最类似，最有可能转化的人群去扩大投放。<br>方法：</p>
<ol>
<li>显示定位</li>
<li>隐式定位</li>
</ol>
<h2 id="显示定位"><a href="#显示定位" class="headerlink" title="显示定位"></a>显示定位</h2><p>显示定位其实就是根据规则或标签进行人群选择、<br>标签本质是利用用户画像/标签体系，基于种子用户的标签，利用相同标签的方式找目标人群。<br>这是最简单、高效、粗暴的一种方式。这种适合收集有大量用户数据能构建完整用户画像的公司做。<br>系统会根据种子用户的标签与腾讯用户标签做匹配，会从上百万个维度对种子人群进行分析，从中筛选出最具代表性的共有特征。根据这些特征再从全量活跃用户中筛选出另一批与种子人群最相似的用户。</p>
<h2 id="隐式定位"><a href="#隐式定位" class="headerlink" title="隐式定位"></a>隐式定位</h2><ol>
<li>基于相似度模型</li>
<li>基于标签/用户协同过滤</li>
<li>基于分类模型<br>将look-alike看成是分类问题，很多的分类算法都可能适用。</li>
</ol>
<p>1)LR算法<br>值的范围在0到1之间，通过阈值就可以判断是否符合目标用户<br>这种方法的优势在于种子用户的所有特征都使用到，易于解释。<br>随着广告的增加，索引存储、离线训练和预测的机器会难以支撑。<br>2)RF模型<br>随机森林模型的实验效果并不理想，在相同的样本和特征上Precision和AUC指标均比LR低，且特征重要性结果只能到特征粒度不能到特征值粒度，因此不再使用。<br>3)PS-SMART算法<br>PS架构的GBDT算法模型，决策树弱分类器加上GBM算法，具有较强的非线性拟合能力，在应用中相比其它两种算法模型效果更好。因此选择PS-SMART作为最终的算法模型，并对损失函数、树的个数深度、正则系数进行调优。<br>4. 基于聚类<br>根据用户标签，采用层次聚类算法（如BIRCH或CURE算法）对人群进行聚类，再从中找出与种子人群相似的机会人群，再通过Top-N排序算法得到用户。<br>5. 基于社交关系<br>6. 基于图模型<br>A Sub-linear, Massive-scale Look-alike Audience Extension System<br>7. 基于Attention深度模型<br>RALM算法：全名Real-time Attention based Look-alike Model<br>8. 其它<br>Adobe的用的是TraitWeight algorithm，<br>百度用深度神经网络相似排序模型<br>由于性能的因素，部分厂家会使用两级模型，就是第一级别是基于标签的，因为基于标签的方式简单，能够做初步筛选，其实就是做粗排，第二级别的是基于算法的，做精选。</p>
<h2 id="PU-learning"><a href="#PU-learning" class="headerlink" title="PU-learning"></a>PU-learning</h2><p>PU learning (positive unlabeled learning)是半监督学习的一个重要分支，其中唯一可用的标记数据是正样本（喜欢的物品）。</p>
<ol>
<li>直接利用标准分类方法</li>
<li>PU bagging<br>A bagging SVM to learn from positive and unlabeled examples<br>a)、通过将所有正样本和未标记样本进行随机组合来创建训练集。<br>b)、利用这个“bootstrap”样本来构建分类器，分别将正样本和未标记样本视为positive和negative。<br>c)、将分类器应用于不在训练集中的未标记样本 - OOB（“out of bag”）- 并记录其分数。<br>d)、重复上述三个步骤，最后为每个样本的分数为OOB分数的平均值。</li>
<li>Two-step approaches<br>An Evaluation of Two-Step Techniques for Positive-Unlabeled Learning in Text Classification<br>a)、识别可以百分之百标记为negative的未标记样本子集（上述论文的作者称这些样本为“reliable negatives”。）<br>b)、使用正负样本来训练标准分类器并将其应用于剩余的未标记样本。<br>通常，会将第二步的结果返回到第一步并重复上述步骤。</li>
<li>Positive unlabeled random forest<br>Towards Positive Unlabeled Learning for Parallel Data Mining: A Random Forest Framework </li>
</ol>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>Lookalike</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow入门 - 官方</title>
    <url>/2021/02/12/Tensorflow%E5%85%A5%E9%97%A8-%E5%AE%98%E6%96%B9/</url>
    <content><![CDATA[<h2 id="quick-start"><a href="#quick-start" class="headerlink" title="quick-start"></a>quick-start</h2><details>
 <summary> 针对专业人员的tensorflow 2.0 入门</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten, Conv2D</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a channels dimension</span></span><br><span class="line">x_train = x_train[..., tf.newaxis].astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">x_test = x_test[..., tf.newaxis].astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_ds = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    (x_train, y_train)).shuffle(<span class="number">10000</span>).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">	<span class="comment"># 定义自己需要的层</span></span><br><span class="line">    self.conv1 = Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.flatten = Flatten()</span><br><span class="line">    self.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.d2 = Dense(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">  <span class="comment">#定义前向传播</span></span><br><span class="line">    x = self.conv1(x)</span><br><span class="line">    x = self.flatten(x)</span><br><span class="line">    x = self.d1(x)</span><br><span class="line">    <span class="keyword">return</span> self.d2(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an instance of the model</span></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line">train_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;train_loss&#x27;</span>)</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;train_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">test_loss = tf.keras.metrics.Mean(name=<span class="string">&#x27;test_loss&#x27;</span>)</span><br><span class="line">test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;test_accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">images, labels</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    <span class="comment"># training=True is only needed if there are layers with different</span></span><br><span class="line">    <span class="comment"># behavior during training versus inference (e.g. Dropout).</span></span><br><span class="line">    predictions = model(images, training=<span class="literal">True</span>)</span><br><span class="line">    loss = loss_object(labels, predictions)</span><br><span class="line">  <span class="comment"># 计算梯度 https://zhuanlan.zhihu.com/p/146016883</span></span><br><span class="line">  gradients = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">  <span class="comment"># 把计算的梯度更新到变量上去</span></span><br><span class="line">  optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">  train_loss(loss)</span><br><span class="line">  train_accuracy(labels, predictions)</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_step</span>(<span class="params">images, labels</span>):</span></span><br><span class="line">  <span class="comment"># training=False is only needed if there are layers with different</span></span><br><span class="line">  <span class="comment"># behavior during training versus inference (e.g. Dropout).</span></span><br><span class="line">  predictions = model(images, training=<span class="literal">False</span>)</span><br><span class="line">  t_loss = loss_object(labels, predictions)</span><br><span class="line"></span><br><span class="line">  test_loss(t_loss)</span><br><span class="line">  test_accuracy(labels, predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">  <span class="comment"># Reset the metrics at the start of the next epoch</span></span><br><span class="line">  train_loss.reset_states()</span><br><span class="line">  train_accuracy.reset_states()</span><br><span class="line">  test_loss.reset_states()</span><br><span class="line">  test_accuracy.reset_states()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds:</span><br><span class="line">    train_step(images, labels)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> test_images, test_labels <span class="keyword">in</span> test_ds:</span><br><span class="line">    test_step(test_images, test_labels)</span><br><span class="line"></span><br><span class="line">  print(</span><br><span class="line">    <span class="string">f&#x27;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, &#x27;</span></span><br><span class="line">    <span class="string">f&#x27;Loss: <span class="subst">&#123;train_loss.result()&#125;</span>, &#x27;</span></span><br><span class="line">    <span class="string">f&#x27;Accuracy: <span class="subst">&#123;train_accuracy.result() * <span class="number">100</span>&#125;</span>, &#x27;</span></span><br><span class="line">    <span class="string">f&#x27;Test Loss: <span class="subst">&#123;test_loss.result()&#125;</span>, &#x27;</span></span><br><span class="line">    <span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;test_accuracy.result() * <span class="number">100</span>&#125;</span>&#x27;</span></span><br><span class="line">  ) </span><br></pre></td></tr></table></figure>
</details> ]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>nlp相关经典论文</title>
    <url>/2021/02/22/nlp%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="attention-is-all-you-need"><a href="#attention-is-all-you-need" class="headerlink" title="attention is all you need"></a>attention is all you need</h1><h2 id="序列模型简介"><a href="#序列模型简介" class="headerlink" title="序列模型简介"></a>序列模型简介</h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN :"></a>RNN :</h3><ol>
<li>Sequential computations inhibits parallelization </li>
<li>No explicit modeling of long and short range dependencies </li>
<li>Transmitting local and global information through one bottleneck<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/28054589">https://zhuanlan.zhihu.com/p/28054589</a><br><a href="https://zhuanlan.zhihu.com/p/47063917">https://zhuanlan.zhihu.com/p/47063917</a><br><a href="https://zhuanlan.zhihu.com/p/47282410">https://zhuanlan.zhihu.com/p/47282410</a></p>
</blockquote>
</li>
</ol>
<h3 id="CNN-Neural-GPU-ByteNet-ConvS2S"><a href="#CNN-Neural-GPU-ByteNet-ConvS2S" class="headerlink" title="CNN: Neural GPU; ByteNet; ConvS2S"></a>CNN: Neural GPU; ByteNet; ConvS2S</h3><ol>
<li>Trivial to parallelize </li>
<li>Exploits local dependencies</li>
<li>interaction distance between positions linear or logarithmic</li>
<li>long-distance dependencies require many layers<br>Encoder-Decoder Stacking<br>Dynamic Unfolding<br>Input Embedding Tensor<br>Masked One-dimensional Convolutions<br>Dilation<br>Residual Blocks</li>
</ol>
<h3 id="RNNs-With-Attention"><a href="#RNNs-With-Attention" class="headerlink" title="RNNs With Attention"></a>RNNs With Attention</h3><ol>
<li>Removes bottleneck of Encoder-Decoder Model</li>
<li>Provides context for given decoder step<br>Use “query” vector(decoder state) and “key” vector(all encoder states)<br>For each query-key pair,calculate weight<br>Normalize to add to one using softmax</li>
</ol>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Encoder: 6 identical layers<br>Layer:</p>
<ol>
<li>multi-head self-attention</li>
<li>fully connected feed-forward<br>Residual Connections:<br>LayerNorm(x+Sublayer(x))</li>
</ol>
<p>Decoder: 6 identical layers<br>Layer:</p>
<ol>
<li>masked multi-head self-attention</li>
<li>multi-head self-attention</li>
<li>fully connected feed-forward<br>Residual Connections:<br>LayerNorm(x+Sublayer(x))</li>
</ol>
<p>注意力机制</p>
<ol>
<li><p>Function mapping a query and a set of key-values pairs to output each weight</p>
</li>
<li><p>Weighted sum of the values<br>scaled dot-product attention<br>$A(Q,V,K)=softmax(\frac{QK^{T}}{ \sqrt{d_{k}} })V$</p>
<p>attention and self-attention<br>attention :query来自外部序列<br>$h_{i}= attention((k,v),q_{i})<br>= \sum_{j=1}^{N}a_{ij}v_{j}<br>= \sum_{j=1}^{N}softmax(s(k_{j},q_{i}))v_{j}$</p>
</li>
</ol>
<p>self-attention:query来自于原本的序列<br>$H=softmax(\frac{QK^{T}}{ \sqrt{d_{k}} })V$</p>
<p>自注意力机制与卷积网络的对比<br>self-attention:variable-sized perceptive field,multi-head(parrallel attention heads)<br>convolution:local dependency,multi-channel</p>
<p>feed-forward network<br>$FFN(x)=max(0,xW_{1}+b_{1})W_{2}+b_{2}$<br>increase non-linear property</p>
<p>Positional Encoding</p>
<ol>
<li>Positional encoding provides relative or absolute position of given token</li>
<li>Many options to select positional encoding,in this work<br>$PE(pos,2i) = sin(\frac{pos}{10000^{2i/d}model})$<br>$PE(pos,2i+1) = cos(\frac{pos}{10000^{2i/d}model})$</li>
</ol>
<p>why residual connections<br>Residuals carry positional information to higher layer,among other information</p>
<p>Training </p>
<ol>
<li>ADAM optimizer with a learning rate warmup ()</li>
<li>Dropout during training at every layer just before adding residual </li>
<li>Layer-Normalization(help ensure that layer remain in reasonable range)</li>
<li>Attention dropout (for some experiments)</li>
<li>Checkoutpoint -averaging</li>
<li>Label smoothing(insert some uncertainty in the training process)</li>
<li>Auto-regressive decoding with beam search and length biasing</li>
</ol>
<p>conclusion:<br>新的序列模型：完全基于注意力<br>在标准的WMT翻译数据集上达到了state-of-the-art的结果<br>模型很快：并行的矩阵乘法</p>
<blockquote>
<p><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">http://nlp.seas.harvard.edu/2018/04/03/attention.html</a><br><a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a></p>
</blockquote>
<p>代码实现<br>pytorch <a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch">https://github.com/jadore801120/attention-is-all-you-need-pytorch</a><br>模型整体框架：<br>编码器解码器<br>输入输出词嵌入<br>生成器<br>编码序列<br>解码序列<br>编解码的mask</p>
<details>
 <summary> 代码实现</summary>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pytorch dynamic graph</span><br><span class="line"><span class="comment"># 克隆多层</span></span><br><span class="line">copy.deepcopy(module)</span><br><span class="line">LayerNorm: layernormalization</span><br><span class="line">dropout </span><br><span class="line">sublayerConnection</span><br><span class="line">torch.triu</span><br><span class="line">torch.matmul(auery,key.transpose(-<span class="number">2</span>,-<span class="number">1</span>))/math.sqrt(d_k)</span><br><span class="line">.view</span><br></pre></td></tr></table></figure>
</details> 

<h1 id="Convolution-Neural-Networks-for-Sentence-Classification"><a href="#Convolution-Neural-Networks-for-Sentence-Classification" class="headerlink" title="Convolution Neural Networks for Sentence Classification"></a>Convolution Neural Networks for Sentence Classification</h1><h2 id="Text-Representation"><a href="#Text-Representation" class="headerlink" title="Text Representation"></a>Text Representation</h2><p>词袋，词嵌入</p>
<ol>
<li>基于规则</li>
<li>基于特征：tf-idf加权求和得到文本表示，训练分类器进行文本分类</li>
<li>基于神经网络<br>分词，句子中的单词转化为低维的词表示，使用编码器得到句子表示，最终得到类别</li>
</ol>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>池化：降采样，降低特征维度并保留有效信息</p>
<ol>
<li>减少模型参数，避免过拟合，提高训练速度</li>
<li>保持特征的位旋转、伸缩不变性(CV)</li>
<li>将变长的输入转换为固定长度(NLP)</li>
</ol>
<h2 id="模型结构："><a href="#模型结构：" class="headerlink" title="模型结构："></a>模型结构：</h2><ol>
<li>输入层：</li>
<li>卷积层：<br>上述公式表示使用窗口大小为h的滤波器<br>得到特征图<br>$c_{i}=f(w\cdot x_{i:i+h-1}+b)$<br>$c=[c_{1},c_{2},\cdots ,c_{n-h+1}]$<br>使用多个滤波器来捕获多种特征</li>
<li>全连接层<br>$y = w\cdot z+b$<br>将句子向量转化为一个维度和类别数相同的向量<br>随机失活<br>$y = w\cdot (z\circ r)+b$<br>r是失活向量，以一定概率取值为1，否则为0</li>
</ol>
<h2 id="related-paper"><a href="#related-paper" class="headerlink" title="related paper"></a>related paper</h2><p>A Sensitivity Analysis of (and Practitioners’ Guide to)<br>Convolutional Neural Networks for Sentence Classification</p>
<details>
 <summary> TextCNN</summary>
词向量分别使用预训练固定、预训练微调和随机初始化三种方案
https://github.com/yoonkim/CNN_sentence
https://github.com/galsang/CNN-sentence-classification-pytorch
http://code.google.com/archive/p/word2vec/
https://github.com/AcademiaSinicaNLPLab/sentiment_dataset

<p>数据目录<br>模型存储目录<br>模型文件：模型初始化<br>程序入口文件：加载词向量，处理UNK和PAD<br>工具文件：数据预处理</p>
<p>交叉熵损失，不需要再在输出softmax<br>根据验证集来选择模型<br>early_stopping :如果准确率在验证集上有下降</p>
<p>LSTM,GRU做文本分类<br><a href="http://github.com/bamtercelboo/cnn-lstm-bilstm-deepcnn-clstm-in-pytorch">http://github.com/bamtercelboo/cnn-lstm-bilstm-deepcnn-clstm-in-pytorch</a> </p>
</details> 





<h1 id="Glove-Gloval-Vectors-for-Word-Representation"><a href="#Glove-Gloval-Vectors-for-Word-Representation" class="headerlink" title="Glove:Gloval Vectors for Word Representation"></a>Glove:Gloval Vectors for Word Representation</h1><p>基于共现矩阵的词表示<br>词共现矩阵</p>
<h2 id="SVD-NMF-CCA"><a href="#SVD-NMF-CCA" class="headerlink" title="SVD\NMF\CCA"></a>SVD\NMF\CCA</h2><p>SVD-&gt;降噪、降维<br>$X=USV^{T}$<br>S除了对角线，其它位置都是0，从U中取前k列作为词向量</p>
<ol>
<li>语义相近的词在向量空间相近，可以一定程度反映word间的线性关系</li>
<li>矩阵维度经常变动，比如新词频繁加入</li>
<li>绝大部分词不会共现，矩阵过于稀疏</li>
<li>矩阵维度很高</li>
<li>训练时复杂度$O(|v|^{3})$</li>
</ol>
<h2 id="基于神经网络的词表示"><a href="#基于神经网络的词表示" class="headerlink" title="基于神经网络的词表示"></a>基于神经网络的词表示</h2><h3 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h3><p>CBOW(Continuous Bag-of-Words Model)<br>Skip-gram (Continuous Skip-gram Model)<br>$L=-\frac{1}{T}\sum_{t=1}^{T}\sum_{-m\leqslant j\leqslant m,j\neq 0}^{}logp(w_{t+j}|w_{t})$<br>$p(w_{t+j}|w_{t})=\frac{exp(v_{w_{t}}^{T}v_{w_{t+j}})}{\sum_{i=1}^{|V|}exp(v_{w_{t}}^{T}v_{w_{i}})}$<br>效果较好、速度快<br>没有充分利用全局统计信息、过度重视共现词频高的单词对</p>
<h3 id="Glove-取长补短，结合两种方法的优点学习词表示"><a href="#Glove-取长补短，结合两种方法的优点学习词表示" class="headerlink" title="Glove:取长补短，结合两种方法的优点学习词表示"></a>Glove:取长补短，结合两种方法的优点学习词表示</h3><p>motivation<br>建模$Ratio = \frac{P_{ik}}{P_{jk}}$,而不是$P_{ik}$<br>$F(w_{i},w_{j},w_{k})=\frac{P_{ik}}{P_{jk}}$<br>测试<br>word analogies<br>word similarity<br>ner<br>和skip-gram的联系</p>
<ol>
<li>提出一种新的词表示方法<br>考虑全局信息，理论可解释</li>
<li>加入了一种权重函数来衡量高频词</li>
<li>对后续工作有很大启发</li>
</ol>
<h1 id="Skip-Thought-Vector"><a href="#Skip-Thought-Vector" class="headerlink" title="Skip-Thought Vector"></a>Skip-Thought Vector</h1><p>跳跃思维句表示<br>句表示<br>一次表示，多领域应用<br>预先训练，应用微调</p>
<p>趋势：让句子的语义更准确编码到有限维的向量中<br>在向量子空间中保持句子的语义关系<br>更好地利用语言模型以及无监督上下文信息</p>
<h2 id="基于词袋模型的句表示"><a href="#基于词袋模型的句表示" class="headerlink" title="基于词袋模型的句表示"></a>基于词袋模型的句表示</h2><p>one-hot,<br>词向量加权：tf-idf，SIF<br>基于上下文、有监督、无监督的句表示<br>基于上下文、语言模型、无监督的句表示</p>
<h2 id="基于神经网络的句表示"><a href="#基于神经网络的句表示" class="headerlink" title="基于神经网络的句表示"></a>基于神经网络的句表示</h2><h3 id="基于语言模型的句表示"><a href="#基于语言模型的句表示" class="headerlink" title="基于语言模型的句表示"></a>基于语言模型的句表示</h3><ol>
<li>利用无监督预料，成本低，语言模型学习语言知识</li>
<li>忽略句子之间隐藏的语义联系<h3 id="基于复述句匹配的句表示"><a href="#基于复述句匹配的句表示" class="headerlink" title="基于复述句匹配的句表示"></a>基于复述句匹配的句表示</h3></li>
<li>建模了句对之间的相似与不相似关系</li>
<li>仅仅建模了相关性，忽略了句子间复杂的语义关系<h3 id="跳跃思维句表示"><a href="#跳跃思维句表示" class="headerlink" title="跳跃思维句表示"></a>跳跃思维句表示</h3>在一段话，能否通过一个句子预测出他上下文的句子？</li>
</ol>
<p>测试<br>语义相似性度量<br>复述句检测<br>句子分类</p>
<p>创新点</p>
<ol>
<li>提出一种新的句表示方法</li>
<li>证明了依次训练多次使用的可行性</li>
<li>对后续工作有很大启发</li>
</ol>
<p>后续改进<br>Quick Thought:根据一句话的语义，通过分类器找到几句话中真正的上下文句</p>
<p><a href="https://github.com/sanyam5/skip-thoughts">https://github.com/sanyam5/skip-thoughts</a></p>
<details>
 <summary> Skip-Thought Vector</summary>
推荐adam
last_best_loss :连续几轮都下降，保存停止  细看
之后用sgd进一步调参
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">	        <span class="comment"># mask the predictions, so that loss for beyond-EOS word predictions is cancelled.</span></span><br><span class="line">        prev_mask = self.create_mask(prev_pred, lengths[:-<span class="number">1</span>])</span><br><span class="line">        next_mask = self.create_mask(next_pred, lengths[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.prev_lstm = nn.LSTM(Encoder.thought_size + self.word_size, self.word_size)</span><br><span class="line">        self.next_lstm = nn.LSTM(Encoder.thought_size + self.word_size, self.word_size)</span><br><span class="line">        self.worder = nn.Linear(self.word_size, VOCAB_SIZE)</span><br><span class="line"></span><br><span class="line">transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">view</span><br></pre></td></tr></table></figure>
</details> 
后续考虑看
改成quickthought            
>https://yknzhu.wixsite.com/mbweb
Doc2vec及有监督句表示

]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>nlp</tag>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>presto即时查询</title>
    <url>/2021/02/23/presto%E5%8D%B3%E6%97%B6%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://www.jianshu.com/p/fddb2f32daf9">https://www.jianshu.com/p/fddb2f32daf9</a><br><a href="https://my.oschina.net/u/4273516/blog/4550114">https://my.oschina.net/u/4273516/blog/4550114</a><br><a href="http://armsword.com/2019/03/31/presto-compatible-hive-syntax/">http://armsword.com/2019/03/31/presto-compatible-hive-syntax/</a><br><a href="https://segmentfault.com/a/1190000013615017">https://segmentfault.com/a/1190000013615017</a><br><a href="https://www.geek-share.com/detail/2751395795.html">https://www.geek-share.com/detail/2751395795.html</a></p>
</blockquote>
<h1 id="Presto介绍"><a href="#Presto介绍" class="headerlink" title="Presto介绍"></a>Presto介绍</h1><p>Presto是一个分布式SQL查询引擎， 它被设计为用来专门进行高速、实时的数据分析。它支持标准的ANSI SQL，<br>包括复杂查询、聚合（aggregation）、连接（join）和窗口函数（window functions)。Presto的运行模型和Hive或MapReduce有着本质的区别。<br>Hive将查询翻译成多阶段的MapReduce任务， 一个接着一个地运行。 每一个任务从磁盘上读取输入数据并且将中间结果输出到磁盘上。<br>然而Presto引擎没有使用MapReduce。它使用了一个定制的查询和执行引擎和响应的操作符来支持SQL的语法。除了改进的调度算法之外，<br>所有的数据处理都是在内存中进行的。 不同的处理端通过网络组成处理的流水线。 这样会避免不必要的磁盘读写和额外的延迟。<br>这种流水线式的执行模型会在同一时间运行多个数据处理段， 一旦数据可用的时候就会将数据从一个处理段传入到下一个处理段。<br> 这样的方式会大大的减少各种查询的端到端响应时间。</p>
<h1 id="Presto-SQL与Hive-SQL区别"><a href="#Presto-SQL与Hive-SQL区别" class="headerlink" title="Presto-SQL与Hive-SQL区别"></a>Presto-SQL与Hive-SQL区别</h1><ol>
<li>presto处理map，若key不存在，会报错，而hive会返回null</li>
<li>由于presto中并没有名为string的类型，出现若进行cast as string这样的转换，或者表定义中有string类型会出现Unknown type 的错误。<code> CAST(x AS varchar)</code>  </li>
<li>整数相除：presto中为整数 <code>SELECT CAST(5 AS DOUBLE) / 2</code></li>
<li>类型隐式转换:presto中 int与varchar无法比较</li>
<li>Array Functions：presto中 array index从0开始</li>
<li>presto中 substr下标从1开始</li>
<li>presto <code>insert into tablename </code>,不可以使用<code>insert overwrite</code></li>
<li>presto <code>regexp_like()</code></li>
</ol>
<h1 id="常用语句"><a href="#常用语句" class="headerlink" title="常用语句"></a>常用语句</h1><ol>
<li>导出csv<br><code>presto --server 10.10.10.100:8081 --catalog hive --schema tmp  --execute &quot;sql&quot;  --output-format CSV &gt; a.csv</code></li>
<li>使用WITH表示复杂的表达式或查询<figure class="highlight oxygene"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> a <span class="keyword">AS</span> (  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">SELECT</span> substr(name, <span class="number">1</span>, <span class="number">3</span>) x  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">FROM</span> ...  </span><br><span class="line">  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">SELECT</span> *  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">FROM</span> a  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">WHERE</span> x = <span class="string">&#x27;foo&#x27;</span> </span><br></pre></td></tr></table></figure></li>
<li>UNNEST扩展数组和映射<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- hive</span></span><br><span class="line"><span class="keyword">SELECT</span> student, score  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">FROM</span> tests  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> explode(scores) t <span class="keyword">AS</span> score;  </span><br><span class="line"></span><br><span class="line"><span class="comment">-- presto</span></span><br><span class="line"><span class="keyword">SELECT</span> student, score  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">FROM</span> tests  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">CROSS</span> <span class="keyword">JOIN</span> UNNEST(scores) <span class="keyword">AS</span> t (score);  </span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h1><ol>
<li><p>避免单节点处理<br>考虑用<code>approx_distinct(x)</code>代替<code>count(distinct x)</code>  2.3%的标准误差<br><code>uinion</code> ,不考虑去重使用<code>union all</code></p>
</li>
<li><p>用大表取JOIN小表<br>Presto 会默认执行广播式的JOIN操作,它会将左表拆分到几个工作节点上, 然后发送整个右表分别到已拆分好的处理左表的工作节点上. 如果右表非常大就会超出工作节点的内存限制,进而出错.<br><code>set session distributed_join = &#39;true&#39;</code><br>核心点就是使用distributed join. Presto的这种配置类型会将左表和右表同时以join key的hash value为分区字段进行分区. 所以即使右表也是大表,也会被拆分.</p>
</li>
</ol>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>presto</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark - Spark MLlib</title>
    <url>/2021/02/07/pyspark-Spark-MLlib/</url>
    <content><![CDATA[<h2 id="Spark-MLlib-简介"><a href="#Spark-MLlib-简介" class="headerlink" title="Spark MLlib 简介"></a>Spark MLlib 简介</h2><ul>
<li>使用MapReduce对机器学习的算法进行编写： 反复读写磁盘开销，磁盘IO开销比较大</li>
<li>Spark适合大量迭代计算</li>
<li>MLlib只包含能够在集群上运行良好的并行算法<br>算法工具：分类，回归，聚类，协同过滤<br>特征化工具：特征提取，转化，降维，选择工具<br>流水线：构建、评估、调整机器学习工作流<br>持久性：保存算法，加载算法，模型，管道</li>
<li>Spark.mllib 基于RDD的数据抽象</li>
<li>Spark.ml 基于DataFrame的数据抽象</li>
</ul>
<h2 id="机器学习流水线"><a href="#机器学习流水线" class="headerlink" title="机器学习流水线"></a>机器学习流水线</h2><p>DataFrame<br>Transformer:通过附加一个或多个列将一个DataFrame转换为另一个DataFrame<br>Estimator:学习算法或在训练数据上的训练方法的概念抽象。被用来操作DataFrame并生成Transformer<br>Pipeline:将多个工作流阶段连接到一起形成机器学习工作流并获得输出结果(PipelineStage:Transformer,Estimator)<br><code>pipeline = Pipeline(stages = [stage1,stage2,stage3])</code><br>流水线本身也可以看作估计器。在流水线的fit()方法运行后，它产生一个PipelineModel,是一个Transformer</p>
<ul>
<li><p>LogisticRegression</p>
<figure class="highlight nix"><table><tr><td class="code"><pre><span class="line">from pyspark.sql <span class="built_in">import</span> SparkSession</span><br><span class="line"><span class="attr">spark</span> = SparkSession.builder.master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;WordCount&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">from pyspark.ml <span class="built_in">import</span> Pipeline</span><br><span class="line">from pyspark.ml.classification <span class="built_in">import</span> LogisticRegression</span><br><span class="line">from pyspark.ml.feature <span class="built_in">import</span> HashingTF,Tokenizer</span><br><span class="line"></span><br><span class="line"><span class="attr">training</span> = spark.createDataFrame([(<span class="number">0</span>,<span class="string">&quot;a b c d e spark&quot;</span>,<span class="number">1.0</span>),(<span class="number">1</span>,<span class="string">&quot;b c&quot;</span>,<span class="number">0.0</span>),(<span class="number">2</span>,<span class="string">&quot;spark f g h&quot;</span>,<span class="number">1.0</span>),(<span class="number">3</span>,<span class="string">&quot;&quot;</span>,<span class="number">0.0</span>)],[<span class="string">&quot;id&quot;</span>,<span class="string">&quot;text&quot;</span>,<span class="string">&quot;label&quot;</span>])</span><br><span class="line"><span class="attr">tokenizer</span> = Tokenizer(<span class="attr">inputCol</span> = <span class="string">&quot;text&quot;</span>,<span class="attr">outputCol</span> = <span class="string">&quot;words&quot;</span>)</span><br><span class="line"><span class="attr">hashingTF</span> = HashingTF(<span class="attr">inputCol</span> = tokenizer.getOutoutCol(),<span class="attr">outputCol</span> = <span class="string">&quot;features&quot;</span>)</span><br><span class="line"><span class="attr">lr</span> = LogisticRegression(<span class="attr">maxIter</span> = <span class="number">10</span>,<span class="attr">reParam</span> = <span class="number">0.001</span>)</span><br><span class="line"><span class="attr">pipeline</span> = Pipeline(<span class="attr">stages</span> = [tokenizer,hashingTF,lr]</span><br><span class="line"><span class="attr">model</span> = pipeline.fit(training)</span><br><span class="line"><span class="attr">training</span> = spark.createDataFrame([(<span class="number">4</span>,<span class="string">&quot;spark i j k&quot;</span> ),(<span class="number">5</span>,<span class="string">&quot;l m n&quot;</span>),(<span class="number">6</span>,<span class="string">&quot;spark hadoop spark&quot;</span>),(<span class="number">7</span>,<span class="string">&quot;apache hadoop&quot;</span>)],[<span class="string">&quot;id&quot;</span>,<span class="string">&quot;text&quot;</span> ])</span><br><span class="line"><span class="attr">prediction</span> = model.transform(text)</span><br><span class="line"><span class="attr">selected</span> = predicition.select(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;text&quot;</span>,<span class="string">&quot;probability&quot;</span>,<span class="string">&quot;prediction&quot;</span>)</span><br><span class="line">for row <span class="keyword">in</span> selected.collect():</span><br><span class="line">	rid,text,prob,<span class="attr">prediction</span> = row </span><br><span class="line">	print(<span class="string">&quot;(%d,%s)--&gt;prob=%s,prediction=%f&quot;</span> %(rid,text,str(probability),predicition))</span><br></pre></td></tr></table></figure>
<h2 id="特征抽取、转化和选择"><a href="#特征抽取、转化和选择" class="headerlink" title="特征抽取、转化和选择"></a>特征抽取、转化和选择</h2></li>
<li><p>特征抽取 TF-IDF<br>$IDF(t,D)=log\frac{\left |  D\right |+1}{DF(t,D)+1}$<br>$TFIDF(t,d,D)=TF(t,d)IDF(t,D)$</p>
<p>HashingTF是transform<br>IDF是</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashinTF,IDF,Tokenizer</span><br><span class="line">sentenceData = spark.createDataFrame([(<span class="number">0</span>,&quot;I heard about Spark and I love Spark&quot;),(<span class="number">0</span>,&quot;I wish Java could use case classes&quot;),(<span class="number">1</span>,&quot;LogisticRegression models are neat&quot;)]).toDF(&quot;label&quot;,&quot;setence&quot;)</span><br><span class="line">tokenizer = Tokenizer(inputCol=&quot;setence&quot;,outputCol=&quot;words&quot;)</span><br><span class="line">wordsData = tokenizer.<span class="keyword">transform</span>(setenceData)</span><br><span class="line">wordsData.<span class="keyword">show</span>()</span><br><span class="line"># 设置哈希表的桶数<span class="number">2000</span></span><br><span class="line">hashingTF = HashinTF(inputCol=&quot;words&quot;,outputCol=&quot;rawFeatures&quot;,numFeatures=<span class="number">2000</span>)</span><br><span class="line"># 使用HashingTF的<span class="keyword">transform</span>()方法把句子哈希成特征向量</span><br><span class="line">featurizedData = hashingTF.<span class="keyword">transform</span>(wordsData)</span><br><span class="line">featurizedData.<span class="keyword">select</span>(&quot;words&quot;,&quot;rawFeatures&quot;).<span class="keyword">show</span>(<span class="keyword">truncate</span>=<span class="keyword">False</span>)</span><br><span class="line"># 使用IDF对单纯的词频特征向量进行构造</span><br><span class="line">idf =IDF(inputCol =&quot;rawFeatures&quot;,outputCol=&quot;features&quot;)</span><br><span class="line">idfModel = idf.fit(featurizedData)</span><br><span class="line"># 调用IDFModel的<span class="keyword">transform</span>()方法来调权重</span><br><span class="line">recaledData = idfModel.<span class="keyword">transform</span>(featurizedData)</span><br><span class="line">recaledData.<span class="keyword">select</span>(&quot;feature&quot;,&quot;label&quot;).<span class="keyword">show</span>(<span class="keyword">truncate</span>=Fales)</span><br></pre></td></tr></table></figure></li>
<li><p>特征转换：标签和索引的转化<br>把标签数据转化为整数索引<br>计算之后把索引还原成标签</p>
</li>
<li><p>StringIndexer :StringIndexer转换器把类别型的特征数值化，索引从0(频率最高)开始；输入时数值型先转化为字符型，再编码</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">from</span> pyspark.ml.feature import StringIndexer</span><br><span class="line"><span class="attribute">df</span> = spark.createDataFrame([(<span class="number">0</span>,<span class="string">&quot;a&quot;</span>),(<span class="number">1</span>,<span class="string">&quot;b&quot;</span>),(<span class="number">2</span>,<span class="string">&quot;c&quot;</span>),(<span class="number">3</span>,<span class="string">&quot;d&quot;</span>),(<span class="number">4</span>,<span class="string">&quot;a&quot;</span>),(<span class="number">5</span>,<span class="string">&quot;c&quot;</span>)],[<span class="string">&quot;id&quot;</span>,<span class="string">&quot;category&quot;</span>])</span><br><span class="line"><span class="attribute">indexer</span> = StringIndexer(inputCol = <span class="string">&quot;category&quot;</span>,outputCol=<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line"><span class="attribute">model</span> = indexer.fit(df)</span><br><span class="line"><span class="attribute">indexed</span> = model.transform(df)</span><br><span class="line"><span class="attribute">indexed</span>.show()</span><br></pre></td></tr></table></figure></li>
<li><p>IndexToString ：与StringIndexer相对应</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString,StringIndexer</span><br><span class="line">toString = IndexToString(inputCol=&quot;categoryIndex&quot;,outputCol=&quot;originalCategory&quot;)</span><br><span class="line">indexString = toString.<span class="keyword">transform</span>(indexed)</span><br><span class="line">indexString.<span class="keyword">select</span>(&quot;id&quot;,&quot;originalCategory&quot;).<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure></li>
<li><p>VectorIndexer :所有特征都已经被组织在一个向量中，又想对其中某些单个分量进行处理<br>maxCategories自动识别类别型特征</p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vector,Vectors</span><br><span class="line">df = spark.createDataFrame([<span class="string">\</span></span><br><span class="line">(Vectors.dense(-<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>),),<span class="string">\</span></span><br><span class="line">(Vectors.dense(-<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">1.0</span>),),<span class="string">\</span></span><br><span class="line">(Vectors.dense(<span class="number">0.0</span>,<span class="number">5.0</span>,<span class="number">1.0</span>),)],[<span class="string">&quot;features&quot;</span>])</span><br><span class="line"><span class="comment">#构建VectorIndexer转换器</span></span><br><span class="line">indexer = VectorIndexer(inputCol=<span class="string">&quot;features&quot;</span>,outputCol=<span class="string">&quot;indexed&quot;</span>,maxCategories=<span class="number">2</span>)</span><br><span class="line">indexerModel = indexer.fit(df)</span><br><span class="line"><span class="comment"># 通过categoriesMaps成员来获得被转换的特征及其映射</span></span><br><span class="line">categoriesFeatures = indexerModel.categoryMaps.keys()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Choose&quot;</span>+str(len(categoriesFeatures))+<span class="string">\</span></span><br><span class="line"><span class="string">&quot;categories features:&quot;</span>+str(categoriesFeatures))</span><br><span class="line">indexed = indexerModel.transform(df)</span><br><span class="line">indexed.show()</span><br></pre></td></tr></table></figure>
<h2 id="分类与回归"><a href="#分类与回归" class="headerlink" title="分类与回归"></a>分类与回归</h2></li>
<li><p>logistic regression</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line">from pyspark.ml.linalg <span class="keyword">import</span> Vector,Vectors</span><br><span class="line">from pyspark.sql <span class="keyword">import</span> Row,functions</span><br><span class="line">from pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line">from pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line">from pyspark.ml.feature <span class="keyword">import</span> IndexToString,StringIndexer,VectorIndexer,HashinTF,Tokenizer</span><br><span class="line">from pyspark.ml.classification <span class="keyword">import</span> LogisticRegression,\</span><br><span class="line">LogisticRegressionModel,BinaryLogisticRegressionSummary,LogisticRegression</span><br><span class="line">def f(x):</span><br><span class="line">	rel = &#123;&#125;</span><br><span class="line">	rel[<span class="string">&#x27;features&#x27;</span>]=Vectors.\</span><br><span class="line">	dense(<span class="built_in">float</span>(x[<span class="number">0</span>]),<span class="built_in">float</span>(x[<span class="number">1</span>]),<span class="built_in">float</span>(x[<span class="number">2</span>]),<span class="built_in">float</span>(x[<span class="number">3</span>]))</span><br><span class="line">	rel[<span class="string">&#x27;label&#x27;</span>] = <span class="built_in">str</span>(x[<span class="number">4</span>])</span><br><span class="line">	<span class="keyword">return</span> rel</span><br><span class="line"></span><br><span class="line">data =spark.sparkContext.\</span><br><span class="line">textFile(<span class="string">&#x27;&#x27;</span>file:<span class="comment">///usr/local/spark/iris.txt&quot;).\</span></span><br><span class="line"><span class="built_in">map</span>(lambda <span class="built_in">line</span>:<span class="built_in">line</span>.<span class="built_in">split</span>(<span class="string">&#x27;,&#x27;</span>)).\</span><br><span class="line"><span class="built_in">map</span>(lambda p:Row(**f(p))).\</span><br><span class="line">toDF()</span><br><span class="line">data.show()</span><br><span class="line"></span><br><span class="line">labelIndexer = StringIndexer().\</span><br><span class="line">setInputCol(<span class="string">&quot;label&quot;</span>).\</span><br><span class="line">setOutputCol(<span class="string">&quot;indexedLabel&quot;</span>).\</span><br><span class="line">fit(data)</span><br><span class="line">featureIndexer = VectorIndexer().\</span><br><span class="line">setInputCol(<span class="string">&quot;features&quot;</span>).\</span><br><span class="line">setOutputCol(<span class="string">&quot;indexedFeatures&quot;</span>).\</span><br><span class="line">fit(data)</span><br><span class="line"></span><br><span class="line">lr =LogisticRegression().\</span><br><span class="line">setLabelCol(<span class="string">&quot;indexedLabel&quot;</span>).\</span><br><span class="line">setFeaturesCol(<span class="string">&quot;indexedFeatures&quot;</span>).\</span><br><span class="line">setMaxIter(<span class="number">100</span>).\</span><br><span class="line">setRegParam(<span class="number">0.3</span>).\</span><br><span class="line">setElasticNetParam(<span class="number">0.8</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;LogisticRegression parameters:\n&quot;</span> + lr.explainParams())</span><br><span class="line"></span><br><span class="line">labelConverter = IndexToString().\</span><br><span class="line">setInputCol(<span class="string">&quot;predicition&quot;</span>).\</span><br><span class="line">setOutputCol(<span class="string">&quot;predictedLabel&quot;</span>).\</span><br><span class="line">setLabels(labelIndexer.labels)</span><br><span class="line"># pipeline是个评估器</span><br><span class="line">lrPipeline = Pipeline().\</span><br><span class="line">setStages([labelIndexer,featureIndexer,lr,labelConverter])</span><br><span class="line"></span><br><span class="line">trainingData,testData = data.randomSplit([<span class="number">0.7</span>,<span class="number">0.3</span>])</span><br><span class="line">lrPipelineModel = lrPipeline.fit(trainingData)</span><br><span class="line">lrPredictions = lrPipelineModel.transform(testData)</span><br><span class="line"></span><br><span class="line">preRel = lrPredictions.select(\</span><br><span class="line"><span class="string">&quot;predictedLabel&quot;</span>,\</span><br><span class="line"><span class="string">&quot;label&quot;</span>,\</span><br><span class="line"><span class="string">&quot;features&quot;</span>,\</span><br><span class="line"><span class="string">&quot;probability&quot;</span>).\</span><br><span class="line">collect()</span><br><span class="line"><span class="keyword">for</span> item in preRel:</span><br><span class="line">	<span class="built_in">print</span>(<span class="built_in">str</span>(item[<span class="string">&#x27;label&#x27;</span>])+<span class="string">&#x27;,&#x27;</span>+\</span><br><span class="line">	<span class="built_in">str</span>(item[<span class="string">&#x27;features&#x27;</span>])+<span class="string">&#x27;--&gt;prob=&#x27;</span>+\</span><br><span class="line">	<span class="built_in">str</span>(item[<span class="string">&#x27;probability&#x27;</span>])+<span class="string">&#x27;,predictedLabel&#x27;</span>+\</span><br><span class="line">	<span class="built_in">str</span>(item[<span class="string">&#x27;predictedLabel&#x27;</span>]))</span><br><span class="line">	</span><br><span class="line">evaluator = MulticlassClassificationEvaluator().\</span><br><span class="line">setLabelCol(<span class="string">&quot;indexedLabel&quot;</span>).\</span><br><span class="line">setPredictionCol(<span class="string">&quot;predicition&quot;</span>)</span><br><span class="line">lrAccuracy = evaluator.evaluate(lrPredictions)</span><br><span class="line"></span><br><span class="line">lrModel = lrPipelineModel.stages[<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficients:\n&quot;</span>+<span class="built_in">str</span>(lrModel.coefficientMatrix)+\</span><br><span class="line"><span class="string">&quot;\n Intercept:&quot;</span>+<span class="built_in">str</span>(lrModel.interceptVector)+\</span><br><span class="line"><span class="string">&quot;\n numClasses:&quot;</span>+<span class="built_in">str</span>(lrModel.numClasses)+\</span><br><span class="line"><span class="string">&quot;\n numFeatures:&quot;</span>+<span class="built_in">str</span>(lrModel.numFeatures))</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>决策树分类器</p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassificationModel</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline,PipelineModel</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vector,Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString,StringIndexer,VectorIndexer</span><br><span class="line"></span><br><span class="line">def f(x):</span><br><span class="line">	rel = &#123;&#125;</span><br><span class="line">	rel[<span class="string">&#x27;features&#x27;</span>]=Vectors. <span class="string">\</span></span><br><span class="line">	dense(float(x[<span class="number">0</span>]),float(x[<span class="number">1</span>]),float(x[<span class="number">2</span>]),float(x[<span class="number">3</span>]))</span><br><span class="line">	rel[<span class="string">&#x27;label&#x27;</span>] = str(x[<span class="number">4</span>])</span><br><span class="line">	<span class="keyword">return</span> rel</span><br><span class="line">data = spark.sparkContext. <span class="string">\</span></span><br><span class="line">textFile(<span class="string">&quot;file:///usr/local/spark/iris.txt&quot;</span>). <span class="string">\</span></span><br><span class="line"><span class="keyword">map</span>(lambda line: line.split(<span class="string">&#x27;,&#x27;</span>)). <span class="string">\</span></span><br><span class="line"><span class="keyword">map</span>(lambda p: Row(**f(p))). <span class="string">\</span></span><br><span class="line">toDF()</span><br><span class="line"></span><br><span class="line">labelIndexer = StringIndexer(). <span class="string">\</span></span><br><span class="line">setInputCol(<span class="string">&quot;label&quot;</span>). <span class="string">\</span></span><br><span class="line">setOutputCol(<span class="string">&quot;indexedLabel&quot;</span>). <span class="string">\</span></span><br><span class="line">fit(data)</span><br><span class="line">featureIndexer = VectorIndexer(). <span class="string">\</span></span><br><span class="line">setInputCol(<span class="string">&quot;features&quot;</span>). <span class="string">\</span></span><br><span class="line">setOutputCol(<span class="string">&quot;indexedFeatures&quot;</span>). <span class="string">\</span></span><br><span class="line">setMaxCategories(<span class="number">4</span>). <span class="string">\</span></span><br><span class="line">fit(data)</span><br><span class="line">labelConverter = IndexToString(). <span class="string">\</span></span><br><span class="line">setInputCol(<span class="string">&quot;prediction&quot;</span>). <span class="string">\</span></span><br><span class="line">setOutputCol(<span class="string">&quot;predictedLabel&quot;</span>). <span class="string">\</span></span><br><span class="line">setLabels(labelIndexer.labels)</span><br><span class="line">trainingData, testData = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">dtClassifier = DecisionTreeClassifier(). <span class="string">\</span></span><br><span class="line">setLabelCol(<span class="string">&quot;indexedLabel&quot;</span>). <span class="string">\</span></span><br><span class="line">setFeaturesCol(<span class="string">&quot;indexedFeatures&quot;</span>)</span><br><span class="line"></span><br><span class="line">dtPipeline = Pipeline(). <span class="string">\</span></span><br><span class="line">setStages([labelIndexer, featureIndexer, dtClassifier, labelConverter])</span><br><span class="line">dtPipelineModel = dtPipeline.fit(trainingData)</span><br><span class="line">dtPredictions = dtPipelineModel.transform(testData)</span><br><span class="line">dtPredictions.select(<span class="string">&quot;predictedLabel&quot;</span>, <span class="string">&quot;label&quot;</span>, <span class="string">&quot;features&quot;</span>).show(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">evaluator = MulticlassClassificationEvaluator().<span class="string">\</span></span><br><span class="line">setLabelCol(<span class="string">&quot;indexedLabel&quot;</span>).<span class="string">\</span></span><br><span class="line">setPredictionCol(<span class="string">&quot;predicition&quot;</span>)</span><br><span class="line">dtAccuracy = evaluator.evaluate(dtPredictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过调用DecisionTreeClassificationModel的toDebugString方法， 查看训练的决策树模型结构 。</span></span><br><span class="line">treeModelClassifier = dtPipelineModel.stages[<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Learned classification tree model:\n&quot;</span> + <span class="string">\</span></span><br><span class="line">str(treeModelClassifier.toDebugString))</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>MLlib</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark-Spark SQL</title>
    <url>/2021/02/07/pyspark-Spark-SQL/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hive： sql on hadoop (将sql语句转换为底层的MapReduce作业)<br>Shark : hive on spark (基本照搬Hive)</p>
<ul>
<li><p>问题<br>不方便添加新的优化策略<br>Spark线程级并行，MapReduce进程级并行。<br>Spark在兼容Hive的实现上存在线程安全问题，导致Shark不得不使用另外一套独立维护的打了补丁的Hive源码分支</p>
</li>
<li><p>Spark SQL 不再受限于Hive,只是兼容Hive</p>
</li>
<li><p>Hive on spark 计划将spark作为Hive的底层引擎之一。(可以采用MapReduce,Tez,spark等引擎)<br>DataFrame<br>带有Schema信息的RDD<br>能够融合各种数据源</p>
<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2></li>
<li><p>DataFrame与RDD的区别<br>RDD是分布式Java对象的集合，但是对象内部结构对于RDD而言是不可知的<br>DataFrame是一种以RDD为基础的分布式数据集，提供了详细的结构信息<br>DataFrame让Spark具备了处理大数据结构化数据的能力，比RDD更简单易用，有更高的计算性能<br>Spark能轻松实现Mysql到DataFrame的转化，并且支持sql查询</p>
</li>
<li><p>DataFrame创建<br>SparkSession接口替代SQLContext、HiveContext<br>支持不同来源的数据，并支持把DataFrame转换成SQLContext自身中的表</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext,SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span> <span class="keyword">import</span> SparkSession </span><br><span class="line">spark=SparkSession.builder.config(conf = SparkConf()).getOrCreate()</span><br></pre></td></tr></table></figure>
<p>在启动进入pyspark,默认提供SparkContext对象(名称sc)和SparkSession对象(名称spark)<br>创建DataFrame</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">spark.<span class="keyword">read</span>.text(&quot;people.txt&quot;)</span><br><span class="line">spark.<span class="keyword">read</span>.json(&quot;people.json&quot;)</span><br><span class="line">spark.<span class="keyword">read</span>.parquet(&quot;people.parquet&quot;)</span><br><span class="line">df =spark.<span class="keyword">read</span>.json(&quot;people.json&quot;)</span><br><span class="line">df.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure></li>
<li><p>DataFrame保存</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">df.<span class="keyword">write</span>.txt(&quot;people.txt&quot;)</span><br><span class="line">df.<span class="keyword">write</span>.format(&quot;txt&quot;).save(&quot;people.txt&quot;)</span><br><span class="line">df.<span class="keyword">write</span>.json(&quot;people.json&quot;)</span><br><span class="line">df.<span class="keyword">write</span>.format(&quot;json&quot;).save(&quot;people.json&quot;)</span><br><span class="line">df.<span class="keyword">write</span>.parquet(&quot;people.parquet&quot;)</span><br><span class="line">df.<span class="keyword">write</span>.format(&quot;parquet&quot;).save(&quot;people.parquet&quot;)</span><br><span class="line">peopleDF = spark.<span class="keyword">read</span>.format(&quot;json&quot;).\</span><br><span class="line"><span class="keyword">load</span>(&quot;file:///usr/local/spark/examples/src/main/resources/people.json&quot;)</span><br><span class="line"># 生成目录而不是文件</span><br><span class="line">peopleDF.<span class="keyword">select</span>(&quot;name&quot;,&quot;age&quot;).<span class="keyword">write</span>.format(&quot;json&quot;).save(&quot;file:///usr/local/spark/mycode/sparksql/newpeople.json&quot;)</span><br><span class="line">peopleDF.<span class="keyword">select</span>(&quot;name&quot;).<span class="keyword">write</span>.format(&quot;txt&quot;).save(&quot;file:///usr/local/spark/mycode/sparksql/newpeople.txt&quot;)</span><br><span class="line"># 存hive</span><br><span class="line">df.<span class="keyword">write</span>.format(<span class="string">&#x27;hive&#x27;</span>).saveAsTable(target_dwb_table,  mode=<span class="string">&#x27;append&#x27;</span>, partitionBy=[<span class="string">&#x27;the_date&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>DataFrame常用操作</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.printSchema</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.select</span>(<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;name&quot;</span>]</span>,<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;people&quot;</span>]</span>)<span class="selector-class">.show</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.filter</span>(<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;age&quot;</span>]</span>&gt;20)<span class="selector-class">.show</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.groupBy</span>(&quot;<span class="selector-tag">age</span>&quot;)<span class="selector-class">.count</span>()<span class="selector-class">.show</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.sort</span>(<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;age&quot;</span>]</span><span class="selector-class">.desc</span>())<span class="selector-class">.show</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.sort</span>(<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;age&quot;</span>]</span><span class="selector-class">.desc</span>(),<span class="selector-tag">df</span><span class="selector-attr">[<span class="string">&quot;name&quot;</span>]</span><span class="selector-class">.asc</span>())<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<h2 id="RDD转换为DataFrame"><a href="#RDD转换为DataFrame" class="headerlink" title="RDD转换为DataFrame"></a>RDD转换为DataFrame</h2></li>
<li><p>利用反射机制推断RDD模式</p>
<figure class="highlight nix"><table><tr><td class="code"><pre><span class="line">from pyspark.sql <span class="built_in">import</span> Row</span><br><span class="line"><span class="comment"># 加载生成RDD</span></span><br><span class="line"><span class="attr">people</span> = spark.sparkContext\</span><br><span class="line">.textFile(<span class="string">&quot;file:///usr/local/spark/examples/src/main/resources/people.txt&quot;</span>)\</span><br><span class="line">.<span class="built_in">map</span>(line:line.split(<span class="string">&quot;,&quot;</span>))\</span><br><span class="line">.<span class="built_in">map</span>(p:ROW(<span class="attr">name</span> = p[<span class="number">0</span>],<span class="attr">age</span> = int(p[<span class="number">1</span>])))</span><br><span class="line"><span class="attr">schemaPeople</span> = spark.createDataFrame(people)</span><br><span class="line"><span class="comment"># 必须注册为临时表才能供下面的查询使用</span></span><br><span class="line">schemaPeople.createOrReplaceTemplateView(<span class="string">&quot;people&quot;</span>)</span><br><span class="line"><span class="attr">personDF</span> = 	spark.sql(<span class="string">&quot;select name,age from people where age&gt;20&quot;</span>)</span><br><span class="line"><span class="attr">personRDD</span> = personDF.rdd.<span class="built_in">map</span>(lambda p: <span class="string">&quot;Name: &quot;</span>+p.name+<span class="string">&quot;Age: &quot;</span>+str(p.age))</span><br><span class="line">personRDD.foreach(print)</span><br></pre></td></tr></table></figure></li>
<li><p>使用编程方式定义RDD模式</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span>.<span class="keyword">types</span> <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span> <span class="keyword">import</span> <span class="keyword">Row</span></span><br><span class="line"># 生成表头</span><br><span class="line">schemaString = &quot;name age&quot;</span><br><span class="line">fields = [StructField(field_name,StringType(),<span class="keyword">True</span>) <span class="keyword">for</span> field_name <span class="keyword">in</span> schemaString.split(&quot; &quot;)] </span><br><span class="line">schema = StructType(fields)</span><br><span class="line"># 生成表中记录</span><br><span class="line">people = spark.sparkContext\</span><br><span class="line">.textFile(&quot;file:///usr/local/spark/examples/src/main/resources/people.txt&quot;)\</span><br><span class="line">.map(<span class="type">line</span>:<span class="type">line</span>.split(&quot;,&quot;))\</span><br><span class="line">.map(p:<span class="keyword">ROW</span>(p[<span class="number">0</span>],p[<span class="number">1</span>].strip())))</span><br><span class="line"># 拼装</span><br><span class="line">schemaPeople = spark.createDataFrame(people,<span class="keyword">schema</span>)</span><br><span class="line">schemaPeople.createOrReplaceTemplateView(&quot;people&quot;)</span><br><span class="line"># 必须注册为临时表才能供下面的查询使用</span><br><span class="line">personDF = 	spark.<span class="keyword">sql</span>(&quot;select name,age from people where age&gt;20&quot;)</span><br><span class="line">personDF.<span class="keyword">show</span>()</span><br></pre></td></tr></table></figure>
<h2 id="SparkSQL读写数据库"><a href="#SparkSQL读写数据库" class="headerlink" title="SparkSQL读写数据库"></a>SparkSQL读写数据库</h2><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"># 读</span><br><span class="line">jdbcDF=spark.<span class="keyword">read</span>.format(&quot;jdbc&quot;)</span><br><span class="line">.<span class="keyword">option</span>(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)</span><br><span class="line">.<span class="keyword">option</span>(&quot;url&quot;,&quot;jdbc:mysql://localhost:3306/spark&quot;)</span><br><span class="line">.<span class="keyword">option</span>(&quot;dbtable&quot;,&quot;student&quot;)</span><br><span class="line">.<span class="keyword">option</span>(&quot;user&quot;,&quot;root&quot;)</span><br><span class="line">.<span class="keyword">option</span>(&quot;password&quot;,&quot;123456&quot;)</span><br><span class="line">.<span class="keyword">load</span>()</span><br><span class="line">jdbcDF.<span class="keyword">show</span>()</span><br><span class="line"># 写</span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span> <span class="keyword">import</span> <span class="keyword">Row</span></span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span>.<span class="keyword">types</span> <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext,SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span> <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.config(conf = SparkConf()).getOrCreate()</span><br><span class="line"># 模式</span><br><span class="line">schema = StructType([StructField(&quot;id&quot;,IntegerType(),<span class="keyword">True</span>),\</span><br><span class="line">StructField(&quot;name&quot;,StringType(),<span class="keyword">True</span>),\</span><br><span class="line">StructField(&quot;gender&quot;,StringType(),<span class="keyword">True</span>),\</span><br><span class="line">StructField(&quot;age&quot;,IntegerType(),<span class="keyword">True</span>)])</span><br><span class="line">studentRDD = spark\</span><br><span class="line">.sparkContext\</span><br><span class="line">.parallelize([&quot;3 Rongcheng M 26&quot;,&quot;4 Guanhua M 27&quot;])\</span><br><span class="line">.map(lambda x:x.split(&quot; &quot;))</span><br><span class="line">rowRDD = studentRDD.map(lambda p:<span class="keyword">Row</span>(<span class="type">int</span>(p[<span class="number">0</span>].strip()),p[<span class="number">1</span>].strip(),p[<span class="number">2</span>].strip(),<span class="type">int</span>(p[<span class="number">3</span>].strip())))</span><br><span class="line">studentDF = spark.createDataFrame(rowRDD,<span class="keyword">schema</span>)</span><br><span class="line"># 写入数据库</span><br><span class="line">prop=&#123;&#125;</span><br><span class="line">prop[<span class="string">&#x27;user&#x27;</span>] = <span class="string">&#x27;root&#x27;</span></span><br><span class="line">prop[<span class="string">&#x27;password&#x27;</span>] = <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">prop[<span class="string">&#x27;driver&#x27;</span>] = <span class="string">&#x27;com.mysql.jdbc.Driver&#x27;</span></span><br><span class="line">studentDF.<span class="keyword">write</span>.jdbc(&quot;jdbc:mysql://localhost:3306/spark&quot;,<span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;append&#x27;</span>,<span class="string">&#x27;pop&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>SparkSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark udf &amp; hive udf</title>
    <url>/2021/02/09/pyspark-udf-hive-udf/</url>
    <content><![CDATA[<h2 id="pyspark-user-defined-functions"><a href="#pyspark-user-defined-functions" class="headerlink" title="pyspark user defined functions"></a>pyspark user defined functions</h2><blockquote>
<p><a href="https://www.bmc.com/blogs/how-to-write-spark-udf-python/">https://www.bmc.com/blogs/how-to-write-spark-udf-python/</a></p>
</blockquote>
<ul>
<li><p>register functions</p>
</li>
<li><p>three ways to create UDFs</p>
<figure class="highlight nix"><table><tr><td class="code"><pre><span class="line"><span class="attr">df</span> = df.withColumn</span><br><span class="line"><span class="attr">df</span> = sqlContext.sql(<span class="string">&quot;&quot;</span>)</span><br><span class="line">rdd.<span class="built_in">map</span>(customFunction())</span><br></pre></td></tr></table></figure>

</li>
</ul>
<details>
  <summary>withColumn</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pyspark</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SQLContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType, StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conf = pyspark.SparkConf() </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">sc = pyspark.SparkContext.getOrCreate(conf=conf)</span><br><span class="line">spark = SQLContext(sc)</span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;sales&quot;</span>, FloatType(),<span class="literal">True</span>),    </span><br><span class="line">    StructField(<span class="string">&quot;employee&quot;</span>, StringType(),<span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;ID&quot;</span>, IntegerType(),<span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">data = [[ <span class="number">10.2</span>, <span class="string">&quot;Fred&quot;</span>,<span class="number">123</span>]]</span><br><span class="line"></span><br><span class="line">df = spark.createDataFrame(data,schema=schema)</span><br><span class="line"></span><br><span class="line">colsInt = udf(<span class="keyword">lambda</span> z: toInt(z), IntegerType())</span><br><span class="line">spark.udf.register(<span class="string">&quot;colsInt&quot;</span>, colsInt)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toInt</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(s, <span class="built_in">str</span>) == <span class="literal">True</span>:</span><br><span class="line">        st = [<span class="built_in">str</span>(<span class="built_in">ord</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> s]</span><br><span class="line">        <span class="keyword">return</span>(<span class="built_in">int</span>(<span class="string">&#x27;&#x27;</span>.join(st)))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">         <span class="keyword">return</span> Null</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df2 = df.withColumn( <span class="string">&#x27;semployee&#x27;</span>,colsInt(<span class="string">&#x27;employee&#x27;</span>))</span><br></pre></td></tr></table></figure>
</details>


<details>
  <summary>sparkSQL</summary>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">spark.register<span class="constructor">DataFrameAsTable(<span class="params">df</span>, <span class="string">&quot;dftab&quot;</span>)</span></span><br><span class="line">df3 = spark.sql(<span class="string">&quot;select sales, employee, ID, colsInt(employee) as iemployee from dftab&quot;</span>)</span><br></pre></td></tr></table></figure>
</details>

<details>
  <summary>RDD</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = df.rdd.<span class="built_in">map</span>(toIntEmployee)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toIntEmployee</span>(<span class="params">rdd</span>):</span></span><br><span class="line">    s = rdd[<span class="string">&quot;employee&quot;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(s, <span class="built_in">str</span>) == <span class="literal">True</span>:</span><br><span class="line">        st = [<span class="built_in">str</span>(<span class="built_in">ord</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> s]</span><br><span class="line">        e = <span class="built_in">int</span>(<span class="string">&#x27;&#x27;</span>.join(st)) </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        e = s</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> Row(rdd[<span class="string">&quot;sales&quot;</span>],rdd[<span class="string">&quot;employee&quot;</span>],rdd[<span class="string">&quot;ID&quot;</span>],e)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> rdd.collect():</span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>传参 <details>
<summary>传参</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">template_result_schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;col1&quot;</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">&quot;col2&quot;</span>, StringType())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun1</span>(<span class="params">x,y,a</span>):</span></span><br><span class="line">	<span class="keyword">return</span> x+a,y+a</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun1_udf</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;传参udf</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> udf(<span class="keyword">lambda</span> x, y: product_cate(x, y, fun1), returnType=template_result_schema)</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>udf</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark-RDD</title>
    <url>/2021/02/06/pyspark%E7%AC%94%E8%AE%B01-RDD/</url>
    <content><![CDATA[<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><ul>
<li>转换：<code>filter(func) map(func) flatMap(func) groupByKey() reduceByKey(func)</code></li>
<li>行动：<code>count() collect() first() take(n) reduce() foreach(func)</code><br>惰性机制</li>
<li>持久化：持久化后的RDD将会被保留在计算节点的内存被后面的行动重复使用<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">persist</span><span class="params">()</span>标记持久化</span></span><br><span class="line"><span class="function"><span class="title">memory_only</span></span></span><br><span class="line"><span class="function"><span class="title">memory_and_disk</span></span></span><br><span class="line"><span class="function">.<span class="title">cache</span><span class="params">()</span> <span class="title">persist</span><span class="params">(memory_only)</span></span></span><br></pre></td></tr></table></figure></li>
<li>分块：hdfs </li>
<li>分区:</li>
<li><ul>
<li>并行</li>
</ul>
</li>
<li><ul>
<li>减少通信开销<br>分区个数 = 集群中cpu核心数目<br>yarn:默认集群中cpu核心数目 和2 的最大值<pre><code> `--conf spark.default.parallelism=400`
</code></pre>
设置分区个数<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sc.text<span class="constructor">File(<span class="params">path</span>,<span class="params">partitionNum</span>)</span></span><br><span class="line">sc.parallelize(<span class="built_in">list</span>,partitionNum)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><ul>
<li>写数据库时，减少读写开销，减少分区个数<figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line"><span class="title">len</span>(<span class="class"><span class="keyword">data</span>.glom().collect())</span></span><br><span class="line"><span class="title">rdd</span> = <span class="class"><span class="keyword">data</span>.repatition(<span class="title">partitionNum</span>)</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><ul>
<li>HashPartitioner</li>
</ul>
</li>
<li><ul>
<li>RangePartitioner</li>
</ul>
</li>
<li>自定义分区<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"><span class="meta">from</span> pyspark import SparkContext,SparkConf</span><br><span class="line">def MyPartitioner(<span class="meta">key</span>)</span><br><span class="line">	p<span class="meta">rint(</span><span class="string">&quot;My Partitoiner is running&quot;</span>)</span><br><span class="line">	p<span class="meta">rint(</span><span class="string">&quot;The key is %d&quot;</span><span class="name">%key</span>)</span><br><span class="line">	<span class="meta">return</span> <span class="meta">key</span>%10</span><br><span class="line">def ma<span class="meta">in(</span>):</span><br><span class="line">	p<span class="meta">rint(</span><span class="string">&quot;The main function is running&quot;</span>)</span><br><span class="line">	conf = SparkConf().setMaster(<span class="string">&quot;Local&quot;</span>).setAppName(<span class="string">&quot;MyApp&quot;</span>)</span><br><span class="line">	sc = SparkContext(conf = conf)</span><br><span class="line"><span class="keyword">	data </span>=sc.parallelize<span class="meta">(range(</span>10),5)</span><br><span class="line">	data.map(lambda a:(a,1))\</span><br><span class="line">	.partitionBy(10,MyPartitioner)</span><br></pre></td></tr></table></figure>
一个分区会启动一个线程<h2 id="示例wordcount"><a href="#示例wordcount" class="headerlink" title="示例wordcount"></a>示例wordcount</h2><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">line = sc.text<span class="constructor">File(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span></span><br><span class="line">wordCount = line.flat<span class="constructor">Map(<span class="params">lambda</span> <span class="params">line</span>:<span class="params">line</span>.<span class="params">split</span>(<span class="string">&quot; &quot;</span>)</span>.\</span><br><span class="line">map(lambda word:(word,<span class="number">1</span>)).reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span></span><br><span class="line">print(wordCount.collect<span class="literal">()</span>)</span><br></pre></td></tr></table></figure>
<h2 id="键值对RDD"><a href="#键值对RDD" class="headerlink" title="键值对RDD"></a>键值对RDD</h2></li>
<li>reduceByKey：使用func合并具有相同键的值</li>
<li>groupByKey:对具有相同的值进行分组 <code>&lt;pyspark.resultiterable.ResultIterable object at .....&gt;</code></li>
<li>用两者分别进行wordcount<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">wordPairsRDD = sc.parallelize(words).map(lambda word:(word,<span class="number">1</span>))</span><br><span class="line">wordCountsWithReduce = wordPairsRDD.reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span></span><br><span class="line">wordCountsWithGroup = wordPairsRDD.group<span class="constructor">ByKey()</span>.map(t: (t<span class="literal">[<span class="number">0</span>]</span>,sum(t<span class="literal">[<span class="number">1</span>]</span>)))</span><br></pre></td></tr></table></figure></li>
<li>常见操作<br><code>keys,values,sortBykey,mapValues,join</code></li>
</ul>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">pairRDD.sortBykey.foreach(print)</span><br><span class="line">pairRDD.map<span class="constructor">Values(<span class="params">lambda</span> <span class="params">x</span>:<span class="params">x</span>+1)</span></span><br><span class="line">pairRDD3 = pairRDD1.join(pairRDD2)</span><br></pre></td></tr></table></figure>
<ul>
<li>sortBykey和sortBy区别<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">d1.reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span>.sort<span class="constructor">Bykey(False)</span>.collect<span class="literal">()</span></span><br><span class="line">d1.reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span>.sort<span class="constructor">By(<span class="params">lambda</span> <span class="params">x</span>:<span class="params">x</span>,False)</span>.collect<span class="literal">()</span></span><br><span class="line">d1.reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span>.sort<span class="constructor">By(<span class="params">lambda</span> <span class="params">x</span>:<span class="params">x</span>[0],False)</span>.collect<span class="literal">()</span></span><br><span class="line">d1.reduce<span class="constructor">ByKey(<span class="params">lambda</span> <span class="params">a</span>,<span class="params">b</span>:<span class="params">a</span>+<span class="params">b</span>)</span>.sort<span class="constructor">By(<span class="params">lambda</span> <span class="params">x</span>:<span class="params">x</span>[1],False)</span>.collect<span class="literal">()</span></span><br></pre></td></tr></table></figure>
<h2 id="图书销量"><a href="#图书销量" class="headerlink" title="图书销量"></a>图书销量</h2><pre><code class="python">rdd = sc.parallelize([(&quot;spark&quot;,2),(&quot;hadoop&quot;,6),(&quot;spark&quot;,6),(&quot;hadoop&quot;,4)])
rdd.mapValues(lambda x:(x,1)).\
reduceByKey(lambda x,y :(x[0]+y[0],x[1]+y[1])).\
mapValues(lambda x:x[0]/x[1]).collect()
</code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>RDD</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark-文件数据读写及案例</title>
    <url>/2021/02/06/pyspark%E7%AC%94%E8%AE%B02%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</url>
    <content><![CDATA[<h2 id="文件数据读写"><a href="#文件数据读写" class="headerlink" title="文件数据读写"></a>文件数据读写</h2><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">textFile =sc.text<span class="constructor">File(<span class="string">&quot;hdfs:///localhost:9000/user/hadoop/word.txt&quot;</span>)</span></span><br><span class="line">textFile =sc.text<span class="constructor">File(<span class="string">&quot;/user/hadoop/word.txt&quot;</span>)</span></span><br><span class="line">textFile =sc.text<span class="constructor">File(<span class="string">&quot;word.txt&quot;</span>)</span></span><br><span class="line">textFile.save<span class="constructor">AsTextFile(<span class="string">&quot;writeback&quot;</span>)</span></span><br></pre></td></tr></table></figure>
<h2 id="读写HBase数据"><a href="#读写HBase数据" class="headerlink" title="读写HBase数据"></a>读写HBase数据</h2><h2 id="求TOP值"><a href="#求TOP值" class="headerlink" title="求TOP值"></a>求TOP值</h2><figure class="highlight nix"><table><tr><td class="code"><pre><span class="line">from pyspark <span class="built_in">import</span> SparkContext,SparkConf</span><br><span class="line"><span class="attr">conf</span> = SparkConf().setMaster(<span class="string">&quot;Local&quot;</span>).setAppName(<span class="string">&quot;ReadHbase&quot;</span>)</span><br><span class="line"><span class="attr">sc</span> = SparkContext(<span class="attr">conf</span> = conf)</span><br><span class="line"><span class="attr">lines</span> =sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/file&quot;</span>)</span><br><span class="line"><span class="attr">result1</span> = lines.filter(lambda line:(len(line.strip())&gt;<span class="number">0</span>) <span class="literal">and</span>(len(line.split(<span class="string">&quot;,&quot;</span>) == <span class="number">4</span> )</span><br><span class="line"><span class="attr">result2</span> = result1.<span class="built_in">map</span>(lambda x:x.split(<span class="string">&quot;,&quot;</span>)[<span class="number">2</span>])</span><br><span class="line"><span class="attr">result3</span> = result2.<span class="built_in">map</span>(lambda x:(int(x),<span class="string">&quot;&quot;</span>))</span><br><span class="line"><span class="attr">result4</span> = result3.repartition(<span class="number">1</span>)</span><br><span class="line"><span class="attr">result5</span> = result4.reduceByKey(False)</span><br><span class="line"><span class="attr">result6</span> = result5.<span class="built_in">map</span>(lambda x:x[<span class="number">0</span>])</span><br><span class="line"><span class="attr">result7</span> = result6.take(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h2 id="文件排序"><a href="#文件排序" class="headerlink" title="文件排序"></a>文件排序</h2><p>(读取文件所有整数进行排序)</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"><span class="meta">from</span> pyspark import SparkContext,SparkConf</span><br><span class="line"></span><br><span class="line"><span class="meta">index</span> = 0</span><br><span class="line">def ge<span class="meta">tindex(</span>):</span><br><span class="line">	global <span class="meta">index</span></span><br><span class="line">	<span class="meta">index</span>+=1</span><br><span class="line">	<span class="meta">return</span> <span class="meta">index</span></span><br><span class="line"></span><br><span class="line">def ma<span class="meta">in(</span>)</span><br><span class="line">	conf = SparkConf().setMaster(<span class="string">&quot;Local&quot;</span>).setAppName(<span class="string">&quot;FileSort&quot;</span>)</span><br><span class="line">	sc = SparkContext(conf = conf)</span><br><span class="line">	lines =sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/file&quot;</span>)</span><br><span class="line">	<span class="meta">index</span> = 0 </span><br><span class="line">	result1 = lines.filter(lambda line:(l<span class="meta">en(</span>line.strip())&gt;0)</span><br><span class="line">	result2 = result1.map(lambda <span class="meta">x</span> <span class="meta">:int(</span><span class="meta">x</span>.strip()),<span class="string">&quot;&quot;</span>)</span><br><span class="line">	# 确保全局有序</span><br><span class="line">	result3 = result2.repartiti<span class="meta">on(</span>1)</span><br><span class="line">	result4 = result3.sortByKey(True)</span><br><span class="line">	result5 = result4.map(lambda <span class="meta">x</span>:<span class="meta">x</span>[0])</span><br><span class="line">	result6 = result5.map(lambda <span class="meta">x</span>:(ge<span class="meta">tindex(</span>),<span class="meta">x</span>))</span><br><span class="line">	result6.saveAsTextFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/filesort/sortresult&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="二次排序"><a href="#二次排序" class="headerlink" title="二次排序"></a>二次排序</h2><p>(首先根据第一列排序，如相等根据第二列排序）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> gt</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext,SparkConf</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SecondarySortKey</span>():</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,k</span>):</span></span><br><span class="line">		self.column1 = k[<span class="number">0</span>]</span><br><span class="line">		self.column2 = k[<span class="number">1</span>]</span><br><span class="line">	<span class="comment"># 重写比较函数</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__gt__</span>(<span class="params">self.other</span>):</span></span><br><span class="line">		<span class="keyword">if</span> other.column1 == self.column1:</span><br><span class="line">			<span class="keyword">return</span> gt(self.column2,other.column2)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			<span class="keyword">return</span> gt(self.column1,other.column1)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">	conf = SparkConf().setMaster(<span class="string">&quot;Local&quot;</span>).setAppName(<span class="string">&quot;spark_sort&quot;</span>)</span><br><span class="line">	sc = SparkContext(conf = conf)</span><br><span class="line">	file = <span class="string">&quot;file:///usr/local/spark/mycode/rdd/secondarysort/file4.txt&quot;</span> </span><br><span class="line">	rdd1 = sc.textFile(file)</span><br><span class="line">	rdd2 = rdd1.<span class="built_in">filter</span>(<span class="keyword">lambda</span> line:(<span class="built_in">len</span>(line.strip())&gt;<span class="number">0</span>)</span><br><span class="line">	rdd3 = rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:((<span class="built_in">int</span>(x.split(<span class="string">&quot; &quot;</span>).[<span class="number">0</span>]),<span class="built_in">int</span>(x.split(<span class="string">&quot; &quot;</span>).[<span class="number">1</span>])),x))</span><br><span class="line">	rdd4 = rdd3.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(SecondarySortKey(x[<span class="number">0</span>]),x[<span class="number">1</span>]))</span><br><span class="line">	rdd5 = rdd4.sortByKey(<span class="literal">False</span>)</span><br><span class="line">	rdd6 = rdd5.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">	rdd6.foreach(<span class="built_in">print</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__=<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	main()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title>spark实现PageRank</title>
    <url>/2021/02/13/spark%E5%AE%9E%E7%8E%B0PageRank/</url>
    <content><![CDATA[<h2 id="PageRank算法"><a href="#PageRank算法" class="headerlink" title="PageRank算法"></a>PageRank算法</h2><p>$PR(A)=(\frac{PR(B)}{L(B)}+\frac{PR(C)}{L(C)}+\frac{PR(D)}{L(D)})d+\frac{(1-d)}{N}$<br>给随机值，迭代收敛</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><details>
 <summary> PageRank算法简单实现</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;JAVA_HOME&quot;</span>] = <span class="string">&quot;/usr/lib/jvm/java-8-openjdk-amd64&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = <span class="string">&quot;/content/spark-2.4.7-bin-hadoop2.7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> findspark</span><br><span class="line">findspark.init()</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeContribs</span>(<span class="params">urls, rank</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Calculates URL contributions to the rank of other URLs.&quot;&quot;&quot;</span></span><br><span class="line">    num_urls = <span class="built_in">len</span>(urls)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        <span class="keyword">yield</span> (url, rank / num_urls)</span><br><span class="line">		</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseNeighbors</span>(<span class="params">urls</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parses a urls pair string into urls pair.&quot;&quot;&quot;</span></span><br><span class="line">    parts = re.split(<span class="string">r&#x27;\s+&#x27;</span>, urls)</span><br><span class="line">    <span class="keyword">return</span> parts[<span class="number">0</span>], parts[<span class="number">1</span>]</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loads in input file. It should be in format of:</span></span><br><span class="line"><span class="comment">#     URL         neighbor URL</span></span><br><span class="line"><span class="comment">#     URL         neighbor URL</span></span><br><span class="line"><span class="comment">#     URL         neighbor URL</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment"># text_file = sc.textFile(&quot;hdfs://...&quot;)</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line">files.upload()</span><br><span class="line"></span><br><span class="line">text_file = sc.textFile(<span class="string">&quot;pagerank_data.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loads all URLs from input file and initialize their neighbors.</span></span><br><span class="line">links = text_file.<span class="built_in">map</span>(<span class="keyword">lambda</span> urls: parseNeighbors(urls)).distinct().groupByKey().cache()</span><br><span class="line"><span class="built_in">print</span> (links.collect())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loads all URLs with other URL(s) link to from input file and initialize ranks of them to one.</span></span><br><span class="line">ranks = links.<span class="built_in">map</span>(<span class="keyword">lambda</span> url_neighbors: (url_neighbors[<span class="number">0</span>], <span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line"><span class="comment"># Calculates and updates URL ranks continuously using PageRank algorithm.</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="comment"># Calculates URL contributions to the rank of other URLs.</span></span><br><span class="line">    contribs = links.join(ranks).flatMap(</span><br><span class="line">        <span class="keyword">lambda</span> url_urls_rank: computeContribs(url_urls_rank[<span class="number">1</span>][<span class="number">0</span>], url_urls_rank[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Re-calculates URL ranks based on neighbor contributions.</span></span><br><span class="line">    ranks = contribs.reduceByKey(add).mapValues(<span class="keyword">lambda</span> rank: rank * <span class="number">0.85</span> + <span class="number">0.15</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># Collects all URL ranks and dump them to console.</span></span><br><span class="line"><span class="keyword">for</span> (link, rank) <span class="keyword">in</span> ranks.collect():</span><br><span class="line">    print(<span class="string">&quot;%s has rank: %s.&quot;</span> % (link, rank))</span><br><span class="line"> </span><br><span class="line"> </span><br></pre></td></tr></table></figure>
</details> ]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>pagerank</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据概述</title>
    <url>/2021/02/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>MapReduce：离线处理，磁盘<br>spark：内存处理，比mapreduce快一个数量级<br>hive：数据仓库，把sql转换为一堆mapreduce<br>pig：一种轻量级脚本语言，简单易用，类似于sql，执行得到结果<br>Oozie:多个工作的执行顺序，工作流管理<br>yarn：负责资源调度<br>hdfs：分布式存储<br>Tez：构建有向无环图<br>zookeeper：分布式应用程序协调服务<br>Hbase：支持实时随机读写。<br>flume：流式数据日志实时收集<br>sqoop：数据导入导出。将数据导入到hdfs，hbase，hive里面，或者从这些里面导出到关系型数据库。</p>
<h3 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h3><ul>
<li>hdfs-site.xml：</li>
</ul>
<ol>
<li>dfs.replication表示副本的数量，伪分布式要设置为1</li>
<li>dfs.namenode.name.dir表示本地磁盘目录，是存储fsimage文件的地方</li>
<li>dfs.datanode.data.dir表示本地磁盘目录，HDFS数据存放block的地方</li>
</ol>
<ul>
<li>三种Shell命令方式区别：</li>
</ul>
<ol>
<li>hadoop fs：适用于任何不同的文件系统</li>
<li>hadoop dfs：只适用于hdfs文件系统</li>
<li>hdfs dfs：一样只适用于hdfs文件系统</li>
</ol>
<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><ul>
<li>计算机集群<br>master/slave结构</li>
<li>设计目标：</li>
</ul>
<ol>
<li>兼容廉价的硬件设备</li>
<li>流数据读写（传统以块为单位），全部读取</li>
<li>支持大数据集</li>
<li>支持简单文件模型，对文件进行简化，只能读写，不能修改</li>
<li>跨平台兼容性</li>
</ol>
<ul>
<li>局限性</li>
</ul>
<ol>
<li>不适合低延迟数据的访问，实时性不高（HBase支持）</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入及任意修改文件</li>
</ol>
<ul>
<li>HDFS默认一个块64MB</li>
</ul>
<ol>
<li>最小化寻址开销<br>块受到MapReduce的影响，MapReduce一般是以块为单位来处理数据，如果块过大就会牺牲MapReduce的并行度，发挥不了分布式并行处理的效果。</li>
</ol>
<ul>
<li>块的好处</li>
</ul>
<ol>
<li>支持大规模文件存储</li>
<li>简化系统设计（块固定）</li>
<li>适合数据备份</li>
</ol>
<ul>
<li>名称数据结构，核心元数据</li>
</ul>
<ol>
<li>FsImage</li>
<li>EditLog</li>
</ol>
<ul>
<li>冗余数据保存<br>以块为单位，会将其冗余保存，一般保存3份，伪分布式：冗余度：1<br>冗余存储会加快数据传输速度、容易检查数据错误、保证数据可靠性。</li>
<li>数据存取策略<br>数据存放：第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太慢、CPU不太忙的节点；<br>第二个副本：放置在与第一个副本不同的机架的节点上<br>第三个副本：与第一个副本相同机架的其他节点上<br>更多副本：随机节点。</li>
<li>数据读取：就近读取，HDFS提供API可以确定一个数据节点所属机架ID，客户端读取数据时，优先选去取机架ID相同的</li>
<li>数据错误与恢复<br>名称节点出错：1.0，需要暂停一段服务时间，使用第二名称节点，2.0直接热备份<br>数据节点出错：<br>定期向名称节点发送心跳信息，一旦但发生故障，即名称节点无法在接受数据节点的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上的所有数据会被标记为“不可读”。会将故障机上的数据重新复制分发到其他可用的机器上去。<br>数据出错：网络传输或磁盘错误等因素。<br>文件在创建保存时会有对应的校验码，可以通过，储存前后的校验码比对，来检查文件块的数据错误情况。<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">hadoop fs适用任何不同的文件系统,比如本地文件系统和HDFS文件系统</span><br><span class="line">hadoop dfs只能适用HDFS文件系统</span><br><span class="line">hdfs dfs也只能适用HDFS文件系统</span><br><span class="line">hadoop fs -ls <span class="params">&lt;path&gt;</span>:显示<span class="params">&lt;path&gt;</span>指定的文件的详细信息</span><br><span class="line">hadoop fs -mkdir <span class="params">&lt;path&gt;</span>：创建<span class="params">&lt;path&gt;</span>指定的文件夹		</span><br><span class="line">hadoop fs -cat <span class="params">&lt;path&gt;</span>：将<span class="params">&lt;path&gt;</span>指定的文件的内容输出到标准输出（stdout）		</span><br><span class="line">hadoop fs -copyFromLocal <span class="params">&lt;localsrc&gt;</span><span class="params">&lt;dst&gt;</span>:将本地源文件<span class="params">&lt;localsrc&gt;</span>复制到路径<span class="params">&lt;dst&gt;</span>指定的文件或文件夹中</span><br><span class="line">hadoop fs -put file.txt <span class="meta-keyword">/user/</span>hive<span class="meta-keyword">/warehouse/</span>tmp.db/table</span><br><span class="line">hdfs dfs -du -s -h <span class="meta-keyword">/user/</span>hive<span class="meta-keyword">/warehouse/</span>tmp.db<span class="meta-keyword">/table/</span></span><br><span class="line">hadoop fs -cat <span class="meta-keyword">/user/</span>hive<span class="meta-keyword">/warehouse/</span>tmp.db<span class="meta-keyword">/table/</span>*  &gt; file.txt</span><br></pre></td></tr></table></figure>
hdfs:存储非结构化数据<br>hbase:存储非结构和半结构化的松散数据，处理非常大的表<br>hadoop:解决大规模数据离线批量处理问题。受限于hadoop mapreduce高延迟。</li>
</ul>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法python版 - 图及算法</title>
    <url>/2021/02/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95python%E7%89%88-%E5%9B%BE%E5%8F%8A%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p>G = (V,E)<br>顶点Vertex，节点Node<br>边Edge，弧Arc<br>权重Weight<br>Cycle ，DAG(directed acyclic graph)</p>
<h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><p>邻接矩阵：简单，sparse<br>邻接表: 紧凑高效</p>
<details>
  <summary>ADT Graph </summary>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vertex</span> :</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>.key)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">self</span>.id = key </span><br><span class="line">		<span class="keyword">self</span>.connectedTo = &#123;&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">addNeighbor</span><span class="params">(<span class="keyword">self</span>,nbr,weight = <span class="number">0</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">self</span>.connectedTo[nbr] = weight </span><br><span class="line">		</span><br><span class="line">	<span class="keyword">if</span> __str__(<span class="keyword">self</span>)<span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> str(<span class="keyword">self</span>.id) + <span class="string">&#x27; connectedTo: &#x27;</span>\</span><br><span class="line">			+ str(x.id <span class="keyword">for</span> x <span class="keyword">in</span> <span class="keyword">self</span>.connectedTo)</span><br><span class="line">			</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getConnections</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.connectedTo.keys()</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getId</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.id</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getWeight</span><span class="params">(<span class="keyword">self</span>,nbr)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.connectedTo[nbr]</span><br><span class="line">		</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">self</span>.vertList = &#123;&#125;</span><br><span class="line">		<span class="keyword">self</span>.numVertices = <span class="number">0</span> </span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">addVertex</span><span class="params">(<span class="keyword">self</span>,key)</span></span>；</span><br><span class="line">		<span class="keyword">self</span>.numVertices = <span class="keyword">self</span>.numVertices</span><br><span class="line">		newVertex = Vertex(key)</span><br><span class="line">		<span class="keyword">self</span>.vertList[key] = newVertex</span><br><span class="line">		<span class="keyword">return</span> newVertex</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getVertex</span><span class="params">(<span class="keyword">self</span>,n)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">if</span> n <span class="keyword">in</span> <span class="keyword">self</span>.vertList <span class="symbol">:</span></span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">self</span>.vertList[n]</span><br><span class="line">		<span class="keyword">else</span> : </span><br><span class="line">			<span class="keyword">return</span> None </span><br><span class="line">			</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__contains__</span><span class="params">(<span class="keyword">self</span>,n)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> n <span class="keyword">in</span> <span class="keyword">self</span>.vertList</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">addEdge</span><span class="params">(<span class="keyword">self</span>,f,t,cost=<span class="number">0</span>)</span></span></span><br><span class="line">		<span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">self</span>.<span class="symbol">vertList:</span></span><br><span class="line">			nv = <span class="keyword">self</span>.addVertex(f)</span><br><span class="line">		<span class="keyword">if</span> t <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">self</span>.<span class="symbol">vertList:</span></span><br><span class="line">			nv = <span class="keyword">self</span>.addVertex(t)</span><br><span class="line">		<span class="keyword">self</span>.vertList[f].addNeighbor(<span class="keyword">self</span>.vertList[t],cost)</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getVertices</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.vertList.keys()</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> iter(<span class="keyword">self</span>.vertList.values())		</span><br></pre></td></tr></table></figure>
</details>

<h2 id="图的应用"><a href="#图的应用" class="headerlink" title="图的应用"></a>图的应用</h2><h3 id="词梯"><a href="#词梯" class="headerlink" title="词梯"></a>词梯</h3><p>找到最短的单词变换序列<br>将可能的单词之间的演变关系表达为图，采用”广度优先搜索BFS”,来搜索从开始单词到结束单词之间的所有有效路径<br>选择其中最快到达目标的单词的路径</p>
<details>
  <summary>采用字典构建桶 </summary>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">buildGraph</span><span class="params">(wordFile)</span>:</span></span><br><span class="line"><span class="function">	d</span>=&#123;&#125;</span><br><span class="line">	g = Graph()</span><br><span class="line">	wfile = <span class="built_in">open</span>(wordFile,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">	<span class="meta"># create buckets of words that differ by one letter</span></span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">line</span> in wfile:</span><br><span class="line">		<span class="keyword">word</span> = <span class="built_in">line</span>[:<span class="number">-1</span>]</span><br><span class="line">		<span class="keyword">for</span> i in range(len(<span class="keyword">word</span>)):</span><br><span class="line">			bucket = <span class="keyword">word</span>[:i] + <span class="string">&#x27;_&#x27;</span> +<span class="keyword">word</span>[i+<span class="number">1</span>]</span><br><span class="line">			<span class="keyword">if</span> bucket in d:</span><br><span class="line">				d[bucket].append(<span class="keyword">word</span>)</span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				d[bucket] = [<span class="keyword">word</span>]</span><br><span class="line">	<span class="meta"># add vertices and edges for words</span></span><br><span class="line">	<span class="keyword">for</span> bucket in d.keys():</span><br><span class="line">		<span class="keyword">for</span> word1 in d[bucket]:</span><br><span class="line">			<span class="keyword">for</span> words in d[bucket]:</span><br><span class="line">				<span class="keyword">if</span> word1 != word2:</span><br><span class="line">					g.addEdge(word1,word2)</span><br><span class="line">	<span class="keyword">return</span> g 	</span><br></pre></td></tr></table></figure>
</details>

<p>BFS算法过程</p>
<ul>
<li>为了跟踪顶点的加入过程，并避免重复顶点，要为顶点增加3个属性<br>距离 distance：从起始顶点到此顶点路径长度<br>前驱顶点 predecessor：可反向追溯到起点<br>颜色 color：标识了此顶点是尚未发现(白色)、已经发现(灰色)、还是已经完成探索(黑色)</li>
<li>还需要一个队列来对已发现的顶点进行排列<details>
<summary>BFS算法 </summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span>(<span class="params">g,start</span>):</span></span><br><span class="line">	start.setDistance(<span class="number">0</span>)</span><br><span class="line">	start.setPred(<span class="literal">None</span>)</span><br><span class="line">	vertQueue = Queue()</span><br><span class="line">	vertQueue.enqueue(start)</span><br><span class="line">	<span class="keyword">while</span> (vertQueue.size()&gt;<span class="number">0</span>):</span><br><span class="line">		currentVert = vertQueue.dequeue()</span><br><span class="line">		<span class="keyword">for</span> nbr <span class="keyword">in</span> currentVert.getConnections():</span><br><span class="line">			<span class="keyword">if</span>(nbr.getColor()==<span class="string">&#x27;white&#x27;</span>):</span><br><span class="line">				nbr.setColor(<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">				nbr.setDistance(currentVert.getDistance()+<span class="number">1</span>)</span><br><span class="line">				nbr.setPred(currentVert)</span><br><span class="line">				vertQueue.enqueue(nbr)</span><br><span class="line">		currentVert.setColor(<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">traverse</span>(<span class="params">y</span>):</span></span><br><span class="line">	x = y </span><br><span class="line">	<span class="keyword">while</span> ( x.getPred()):</span><br><span class="line">		print(x.getId())</span><br><span class="line">		x = x.getPred()</span><br><span class="line">	print(x.getId())</span><br><span class="line">	</span><br><span class="line">wordgraph = buildGraph(<span class="string">&#x27;fourletterwords.txt&#x27;</span>)</span><br><span class="line">bfs(wordgraph,wordgraph.getVertex(<span class="string">&#x27;Fool&#x27;</span>))</span><br><span class="line">traverse(wordgraph.getVertex(<span class="string">&#x27;STAGE&#x27;</span>))</span><br></pre></td></tr></table></figure>
</details>

</li>
</ul>
<h3 id="骑士周游问题"><a href="#骑士周游问题" class="headerlink" title="骑士周游问题"></a>骑士周游问题</h3><ul>
<li><p>深度优先搜索</p>
</li>
<li><p>引入一个栈来记录路径</p>
</li>
<li><p>启发式规则：减少搜索范围，更快得到目标</p>
<details>
<summary> 骑士周游问题</summary>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">def gen<span class="constructor">LegalMoves(<span class="params">x</span>,<span class="params">y</span>,<span class="params">bdSize</span>)</span>:</span><br><span class="line">	newMoves = <span class="literal">[]</span></span><br><span class="line">	moveOffsets = <span class="literal">[(-<span class="number">1</span>,-<span class="number">2</span>),(-<span class="number">1</span>,<span class="number">2</span>),(-<span class="number">2</span>,-<span class="number">1</span>),(-<span class="number">2</span>,<span class="number">1</span>),</span></span><br><span class="line"><span class="literal">	(<span class="number">1</span>,-<span class="number">2</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,-<span class="number">1</span>),(<span class="number">2</span>,<span class="number">1</span>)]</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> moveOffsets:</span><br><span class="line">		newX = x +i<span class="literal">[<span class="number">0</span>]</span></span><br><span class="line">		newY = y +i<span class="literal">[<span class="number">1</span>]</span></span><br><span class="line">		<span class="keyword">if</span> legal<span class="constructor">Coord(<span class="params">newX</span>,<span class="params">bdSize</span>)</span> <span class="keyword">and</span> legal<span class="constructor">Coord(<span class="params">newY</span>,<span class="params">bdSize</span>)</span> :</span><br><span class="line">			newMoves.append((newX,newY))</span><br><span class="line">	return newMoves</span><br><span class="line">	</span><br><span class="line">def legal<span class="constructor">Coord(<span class="params">x</span>,<span class="params">bdSize</span>)</span>:</span><br><span class="line">	<span class="keyword">if</span> x&gt;= <span class="number">0</span> <span class="keyword">and</span> x &lt; bdSize:</span><br><span class="line">		return True</span><br><span class="line">	<span class="keyword">else</span> :</span><br><span class="line">		return False</span><br><span class="line"># 构建走棋关系图</span><br><span class="line">def knight<span class="constructor">Graph(<span class="params">bdSize</span>)</span>:</span><br><span class="line">	ktGraph = <span class="constructor">Graph()</span></span><br><span class="line">	<span class="keyword">for</span> row <span class="keyword">in</span> range(bdSize):</span><br><span class="line">		<span class="keyword">for</span> col <span class="keyword">in</span> range(bdSize):</span><br><span class="line">			nodeId = pos<span class="constructor">ToNodeId(<span class="params">row</span>,<span class="params">col</span>,<span class="params">bdSize</span>)</span></span><br><span class="line">			newPositions = gen<span class="constructor">LegalMoves(<span class="params">row</span>,<span class="params">col</span>,<span class="params">bdSize</span>)</span></span><br><span class="line">			<span class="keyword">for</span> e <span class="keyword">in</span> newPositions:</span><br><span class="line">				nid = pos<span class="constructor">ToNodeId(<span class="params">e</span>[0],<span class="params">e</span>[1],<span class="params">bdSize</span>)</span></span><br><span class="line">				ktGraph.add<span class="constructor">Edge(<span class="params">nodeId</span>,<span class="params">nid</span>)</span></span><br><span class="line">	return ktGraph</span><br><span class="line">	</span><br><span class="line">def pos<span class="constructor">ToNodeId(<span class="params">row</span>,<span class="params">col</span>,<span class="params">bdSize</span>)</span>:</span><br><span class="line">	return row*bdSize+col</span><br><span class="line">	</span><br><span class="line">def knight<span class="constructor">Tour(<span class="params">n</span>,<span class="params">path</span>,<span class="params">u</span>,<span class="params">limit</span>)</span>:</span><br><span class="line">	u.set<span class="constructor">Color(&#x27;<span class="params">gray</span>&#x27;)</span>:</span><br><span class="line">	path.append(u)</span><br><span class="line">	<span class="keyword">if</span> n &lt; limit:</span><br><span class="line">		nbrList = <span class="built_in">list</span>(u.get<span class="constructor">Connections()</span>)</span><br><span class="line">		i = <span class="number">0</span> </span><br><span class="line">		<span class="keyword">done</span> = False</span><br><span class="line">		<span class="keyword">while</span> i &lt; len(nbrList) <span class="keyword">and</span> not <span class="keyword">done</span>:</span><br><span class="line">			<span class="keyword">if</span> nbrList<span class="literal">[<span class="identifier">i</span>]</span>.get<span class="constructor">Color()</span><span class="operator"> == </span>&#x27;white&#x27;:</span><br><span class="line">				<span class="keyword">done</span> = knight<span class="constructor">Tour(<span class="params">n</span>+1,<span class="params">path</span>,<span class="params">nbrList</span>[<span class="params">i</span>],<span class="params">limit</span>)</span></span><br><span class="line">			i = i+<span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> not <span class="keyword">done</span>:</span><br><span class="line">			path.pop<span class="literal">()</span></span><br><span class="line">			u.set<span class="constructor">Color(&#x27;<span class="params">white</span>&#x27;)</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">done</span> = True</span><br><span class="line">	return <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</details>
</li>
<li><p>骑士周游算法改进<br>将u的合法移动目标棋盘格排序为：具有最少合法移动目标的格子优先搜索</p>
</li>
</ul>
<details>
 <summary> 改进</summary>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">orderByAvail</span> (<span class="params">n</span>):</span></span><br><span class="line">	resList = []</span><br><span class="line">	<span class="keyword">for</span> v <span class="keyword">in</span> n.getConnections():</span><br><span class="line">		<span class="keyword">if</span> v.getColor() == <span class="string">&#x27;white&#x27;</span>:</span><br><span class="line">			c = <span class="number">0</span></span><br><span class="line">			<span class="keyword">for</span> w <span class="keyword">in</span> v.getConnections():</span><br><span class="line">				<span class="keyword">if</span> w.getColor() == <span class="string">&#x27;white&#x27;</span>:</span><br><span class="line">					c = c+<span class="number">1</span></span><br><span class="line">			resList.append((c,v))</span><br><span class="line">	resList.sort(key = <span class="keyword">lambda</span> x :x[<span class="number">0</span>])</span><br><span class="line">	<span class="keyword">return</span> [y[<span class="number">1</span>] <span class="keyword">for</span> y <span class="keyword">in</span> resList]</span><br></pre></td></tr></table></figure>
</details>

<h3 id="通用的深度优先搜索"><a href="#通用的深度优先搜索" class="headerlink" title="通用的深度优先搜索"></a>通用的深度优先搜索</h3><ul>
<li>一般的深度优先搜索目标是在图上进行尽量深的搜索，连接尽量多的顶点，必要时可以进行分支</li>
<li>深度优先搜索同样要用到顶点的前驱属性<br>另外要设置发现时间和结束时间。<br>带有DFS算法的图实现为Graph的子类<br>Vertex 增加了成员Discovery及Finish<br>Graph增加了成员time</li>
</ul>
<details>
 <summary> 改进</summary>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pythonds.graphs <span class="keyword">import</span> Graph </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DFSGraph</span> (<span class="params">Graph</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">		<span class="built_in">super</span>().__init__()</span><br><span class="line">		self.time = <span class="number">0</span></span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self</span>):</span></span><br><span class="line">		<span class="keyword">for</span> aVertex <span class="keyword">in</span> self:</span><br><span class="line">			aVertex.setColor(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">			aVertex.setPred(-<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">for</span> aVertex <span class="keyword">in</span> self:</span><br><span class="line">			<span class="keyword">if</span> aVertex.getColor() == <span class="string">&#x27;white&#x27;</span>:</span><br><span class="line">				self.dfsvisit(aVertex)</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">dfsvisit</span>(<span class="params">self,startVertex</span>):</span></span><br><span class="line">		startVertex.setColor(<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">		self.time += <span class="number">1</span></span><br><span class="line">		startVertex.setDiscovery(self.time)</span><br><span class="line">		<span class="keyword">for</span> nextVertex <span class="keyword">in</span> startVertex.getConnections():</span><br><span class="line">			<span class="keyword">if</span> nextVertext.getColor() == <span class="string">&#x27;white&#x27;</span>:</span><br><span class="line">				nextVertex.setPred(startVertex)</span><br><span class="line">				self.dfsvisit(nextVertex)</span><br><span class="line">		startVertex.setColor(<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">		self.time +=<span class="number">1</span></span><br></pre></td></tr></table></figure>
</details>


<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul>
<li>拓扑排序<br>对DAG图调用DFS算法，以得到每个顶点的结束时间</li>
<li>强连通分支</li>
</ul>
<ol>
<li>对G调用DFS算法，为每个顶点计算”结束时间”</li>
<li>将G转置得到$G^{T}$</li>
<li>再对$G^{T}$调用DFS，但要以之前顶点的结束时间倒序来搜索</li>
<li>深度优先森林中的每一棵树就是一个强连通分支</li>
</ol>
<ul>
<li>最短路径问题</li>
</ul>
<ol>
<li>BFS</li>
<li>顶点的dist用于记录从开始顶点到此的带权路径长度</li>
<li>顶点的访问次序由优先队列来实现</li>
<li>开始顶点dist=0,其它所有顶点dist设为sys.maxsize</li>
<li>随着队列中每一个最低dist顶点率先出队，并计算它与邻接顶点的权重，会引起其它顶点dist的减小和修改，引起堆重排</li>
<li>根据更新后的dist优先级再依次出队<details>
<summary> Dijkstra算法</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pythonds.graphs <span class="keyword">import</span> PriorityQueue,Graph,Vertex</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dijkstra</span>(<span class="params">aGraph,starg=t</span>):</span></span><br><span class="line">	pq = PriorityQueue()</span><br><span class="line">	start.setDistance(<span class="number">0</span>)</span><br><span class="line">	pq.buildHeap([v.getDistance(),v] <span class="keyword">for</span> v <span class="keyword">in</span> aGraph)</span><br><span class="line">	<span class="keyword">while</span> <span class="keyword">not</span> pq.isEmpty():</span><br><span class="line">		currentVert = pq.delMin()</span><br><span class="line">		<span class="keyword">for</span> nextVert  <span class="keyword">in</span> currentVert.getConnections():</span><br><span class="line">			newDist = currentVert.getDistance()\</span><br><span class="line">					+ currentVert.getWeight(nextVert)</span><br><span class="line">			<span class="keyword">if</span> newDist &lt; nextVert.getDistance():</span><br><span class="line">				nextVert.setDistance(newDist)</span><br><span class="line">				nextVert.setPred(currentVert)</span><br><span class="line">				pq.decreaseKey(nextVert,newDist)</span><br></pre></td></tr></table></figure>
</details>
</li>
</ol>
<ul>
<li>最小生成树：Prim算法<br>贪心算法<br>每步都沿着最小权重的边向前搜索，找到一条最小权重的可以安全添加的边<details>
<summary> Prim算法</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pythonds.graphs <span class="keyword">import</span> PriorityQueue,Graph,Vertex</span><br><span class="line"><span class="keyword">import</span> sys </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prim</span>(<span class="params">G,start</span>):</span></span><br><span class="line">	pq = PriorityQueue()</span><br><span class="line">	<span class="keyword">for</span> v <span class="keyword">in</span> G:</span><br><span class="line">		v.setDistance(sys.maxsize)</span><br><span class="line">		v.setPred(<span class="literal">None</span>)</span><br><span class="line">	start.setDistance(<span class="number">0</span>)</span><br><span class="line">	pq.buildHeap([(v.getDistance(),v) <span class="keyword">for</span> v <span class="keyword">in</span> G])</span><br><span class="line">	<span class="keyword">while</span> <span class="keyword">not</span> pq.isEmpty():</span><br><span class="line">		currentVert = pq.delMin()</span><br><span class="line">		<span class="keyword">for</span> nextVert <span class="keyword">in</span> currentVert.getConnections():</span><br><span class="line">			newCost = currentVert.getWeight(nextVert)</span><br><span class="line">			<span class="keyword">if</span> nextVert <span class="keyword">in</span> pq <span class="keyword">and</span> newCost &lt; nextVert.getDistance():</span><br><span class="line">				nextVert.setPred(currentVert)</span><br><span class="line">				nextVert.setDistance(newCost)</span><br><span class="line">				pq.decreaseKey(nextVert,newCost)</span><br></pre></td></tr></table></figure>
</details>

</li>
</ul>
<h2 id="leetcode"><a href="#leetcode" class="headerlink" title="leetcode"></a>leetcode</h2><ol>
<li>leetcode 207课程表<details>
<summary> 207课程表</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你这个学期必须选修 numCourses 门课程，记为 0 到 numCourses - 1 。</span></span><br><span class="line"><span class="string">在选修某些课程之前需要一些先修课程。 先修课程按数组 prerequisites 给出，其中 prerequisites[i] = [ai, bi] ，表示如果要学习课程 ai 则 必须 先学习课程  bi 。</span></span><br><span class="line"><span class="string">例如，先修课程对 [0, 1] 表示：想要学习课程 0 ，你需要先完成课程 1 。</span></span><br><span class="line"><span class="string">请你判断是否可能完成所有课程的学习？如果可以，返回 true ；否则，返回 false 。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canFinish</span>(<span class="params">self, numCourses: <span class="built_in">int</span>, prerequisites: List[List[<span class="built_in">int</span>]]</span>) -&gt; bool:</span></span><br><span class="line">        edges = collections.defaultdict(<span class="built_in">list</span>)</span><br><span class="line">        visited = [<span class="number">0</span>]*numCourses</span><br><span class="line">        valid = <span class="literal">True</span></span><br><span class="line">        result = <span class="built_in">list</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> info <span class="keyword">in</span> prerequisites:</span><br><span class="line">            <span class="comment">#后一个指向前一个点</span></span><br><span class="line">            edges[info[<span class="number">1</span>]].append(info[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">u</span>):</span></span><br><span class="line">            <span class="comment">#开始搜索</span></span><br><span class="line">            <span class="keyword">nonlocal</span> valid </span><br><span class="line">            visited[u]=<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> edges[u]:</span><br><span class="line">                <span class="keyword">if</span> visited[v] == <span class="number">0</span>:</span><br><span class="line">                    dfs(v)</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> valid:</span><br><span class="line">                        <span class="keyword">return</span> </span><br><span class="line">                <span class="keyword">elif</span> visited[v] == <span class="number">1</span>:</span><br><span class="line">                    valid = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">return</span> </span><br><span class="line">            <span class="comment"># 搜索完成</span></span><br><span class="line">            visited[u]=<span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numCourses):</span><br><span class="line">            <span class="keyword">if</span> visited[i]==<span class="number">0</span> <span class="keyword">and</span>  valid:</span><br><span class="line">                dfs(i)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> valid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


</li>
</ol>
<ol start="2">
<li>leetcode 399除法求值<details>
<summary> 399除法求值</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">给你一个变量对数组 equations 和一个实数值数组 values 作为已知条件，其中 equations[i] = [Ai, Bi] 和 values[i] 共同表示等式 Ai / Bi = values[i] 。每个 Ai 或 Bi 是一个表示单个变量的字符串。</span></span><br><span class="line"><span class="string">另有一些以数组 queries 表示的问题，其中 queries[j] = [Cj, Dj] 表示第 j 个问题，请你根据已知条件找出 Cj / Dj = ? 的结果作为答案。</span></span><br><span class="line"><span class="string">返回 所有问题的答案 。如果存在某个无法确定的答案，则用 -1.0 替代这个答案。如果问题中出现了给定的已知条件中没有出现的字符串，也需要用 -1.0 替代这个答案。</span></span><br><span class="line"><span class="string">注意：输入总是有效的。你可以假设除法运算中不会出现除数为 0 的情况，且不存在任何矛盾的结果。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details> </li>
</ol>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>DS&amp;A</tag>
        <tag>Graph</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法python版 - 排序与查找</title>
    <url>/2021/02/07/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95python%E7%89%88-%E6%8E%92%E5%BA%8F%E4%B8%8E%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h2 id="leetcode-排序"><a href="#leetcode-排序" class="headerlink" title="leetcode 排序"></a>leetcode 排序</h2><ol>
<li><p>leetcode 56合并区间</p>
<details>
<summary> 56合并区间</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。</span></span><br><span class="line"><span class="string">请你合并所有重叠的区间，并返回一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">self, intervals: List[List[<span class="built_in">int</span>]]</span>) -&gt; List[List[int]]:</span></span><br><span class="line">        intervals.sort(key= <span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">        result=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> intervals:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> result <span class="keyword">or</span> result[-<span class="number">1</span>][<span class="number">1</span>] &lt; i[<span class="number">0</span>]:</span><br><span class="line">                result.append(i)</span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                result[-<span class="number">1</span>][<span class="number">1</span>] = <span class="built_in">max</span>(i[<span class="number">1</span>],result[-<span class="number">1</span>][<span class="number">1</span>] )</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
</details> 
</li>
<li><p>leetcode 75颜色分类</p>
<details>
<summary> 75颜色分类</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。</span></span><br><span class="line"><span class="string">此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">self, nums, a,b</span>):</span></span><br><span class="line">        tmp = nums[a]</span><br><span class="line">        nums[a] = nums[b]</span><br><span class="line">        nums[b] = tmp </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortColors</span>(<span class="params">self, nums: List[<span class="built_in">int</span>]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">        all in [0,p0] == 0</span></span><br><span class="line"><span class="string">        all in [p0,i) == 1</span></span><br><span class="line"><span class="string">        all in [p2,len-1] == 2</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        length = <span class="built_in">len</span>(nums)</span><br><span class="line">        p0 = -<span class="number">1</span></span><br><span class="line">        p2 = length </span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> (i&lt;p2):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == <span class="number">0</span>:</span><br><span class="line">                p0 = p0+<span class="number">1</span></span><br><span class="line">                self.swap(nums,i,p0)</span><br><span class="line">                i = i+<span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">elif</span> nums[i] == <span class="number">1</span> :</span><br><span class="line">                i = i+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                p2 = p2-<span class="number">1</span></span><br><span class="line">                self.swap(nums,i,p2)</span><br><span class="line">                </span><br></pre></td></tr></table></figure>
</details> 

</li>
</ol>
<h2 id="leetcode-二分查找"><a href="#leetcode-二分查找" class="headerlink" title="leetcode 二分查找"></a>leetcode 二分查找</h2><ol>
<li>leetcode 287寻找重复数<details>
<summary> 56合并区间</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">给定一个包含 n + 1 个整数的数组 nums ，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。</span></span><br><span class="line"><span class="string">假设 nums 只有 一个重复的整数 ，找出 这个重复的数 。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findDuplicate</span>(<span class="params">self, nums: List[<span class="built_in">int</span>]</span>) -&gt; int:</span></span><br><span class="line">        left  = <span class="number">1</span></span><br><span class="line">        right = <span class="built_in">len</span>(nums) -<span class="number">1</span> </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(left &lt;right ):</span><br><span class="line">            mid = left +(right -left )//<span class="number">2</span></span><br><span class="line">            cnt = <span class="number">0</span> </span><br><span class="line">            <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">                <span class="keyword">if</span> num&lt;=mid:</span><br><span class="line">                    cnt = cnt+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> cnt &gt; mid:</span><br><span class="line">                right = mid  </span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                left = mid+<span class="number">1</span> </span><br><span class="line">        <span class="keyword">return</span> left </span><br></pre></td></tr></table></figure>
</details> </li>
</ol>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>DS&amp;A</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法python版 - 树及算法</title>
    <url>/2021/02/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95python%E7%89%88-%E6%A0%91%E5%8F%8A%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li>相关术语<br>Node,Edge,Root,Path,Children,Parent,Sibling,Subtree,Leaf,Level</li>
</ul>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><details>
  <summary>嵌套列表法</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BinaryTree</span>(<span class="params">r</span>):</span></span><br><span class="line">	<span class="keyword">return</span> [r,[],[]]</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertLeft</span>(<span class="params">root,newBranch</span>):</span></span><br><span class="line">	t = root.pop()</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(t)&gt;<span class="number">1</span>:</span><br><span class="line">		root.insert(<span class="number">1</span>,[newBranch,t,[]])</span><br><span class="line">	<span class="keyword">else</span> :</span><br><span class="line">		root.insert(<span class="number">1</span>,[newBranch,[],[]])</span><br><span class="line">	<span class="keyword">return</span> root </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertRight</span>(<span class="params">root,newBranch</span>):</span></span><br><span class="line">	t = root.pop(<span class="number">2</span>)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(t)&gt;<span class="number">1</span>:</span><br><span class="line">		root.insert(<span class="number">2</span>,[newBranch,[],t])</span><br><span class="line">	<span class="keyword">else</span> :</span><br><span class="line">		root.insert(<span class="number">2</span>,[newBranch,[],[]])</span><br><span class="line">	<span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getRootVal</span>(<span class="params">root</span>):</span></span><br><span class="line">	<span class="keyword">return</span> root[<span class="number">0</span>]</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setRootVal</span>(<span class="params">root,newVal</span>):</span></span><br><span class="line">	root[<span class="number">0</span>] = newVal</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLeftChild</span>(<span class="params">root</span>):</span></span><br><span class="line">	<span class="keyword">return</span> root[<span class="number">1</span>]</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getRightChild</span>(<span class="params">root</span>):</span></span><br><span class="line">	<span class="keyword">return</span> root[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
</details>

<details>
  <summary>节点链表法</summary>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>,rootObj)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">self</span>.key = rootObj</span><br><span class="line">		<span class="keyword">self</span>.leftChild = None</span><br><span class="line">		<span class="keyword">self</span>.rightChild = None</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">insertLeft</span><span class="params">(<span class="keyword">self</span>,newNode)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">self</span>.leftChild == <span class="symbol">None:</span></span><br><span class="line">			<span class="keyword">self</span>.leftChild = BinaryTree(newNode)</span><br><span class="line">		<span class="symbol">else:</span></span><br><span class="line">			t = BinaryTree(newNode)</span><br><span class="line">			t.leftChild = <span class="keyword">self</span>.leftChild</span><br><span class="line">			<span class="keyword">self</span>.leftChild = t</span><br><span class="line">			</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">insertRight</span><span class="params">(<span class="keyword">self</span>,newNode)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">self</span>.rightChild == <span class="symbol">None:</span></span><br><span class="line">			<span class="keyword">self</span>.rightChild = BinaryTree(newNode)</span><br><span class="line">		<span class="symbol">else:</span></span><br><span class="line">			t = BinaryTree(newNode)</span><br><span class="line">			t.rightChild = <span class="keyword">self</span>.rightChild</span><br><span class="line">			<span class="keyword">self</span>.rightChild = t		</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getRightChild</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.rightChild</span><br><span class="line">		</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getLeftChild</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.leftChild</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">setRootVal</span><span class="params">(<span class="keyword">self</span>,obj)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">self</span>.key = obj</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getRootVal</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">self</span>.key</span><br></pre></td></tr></table></figure>
</details>

<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><details>
  <summary>建立表达式解析树</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">用树来跟踪当前节点 (创建、设置、下降)</span></span><br><span class="line"><span class="string">用栈来来记录和跟踪父节点 (上升)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildParseTree</span>(<span class="params">fpexp_:</span></span></span><br><span class="line"><span class="function"><span class="params">	fplist = fpexp.split(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">	pStack = Stack(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">	eTree = BinaryTree(<span class="params"><span class="string">&#x27;&#x27;</span></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="comment"># 入栈下降</span></span></span></span><br><span class="line"><span class="function"><span class="params">	pStack.push(<span class="params">eTree</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">	currentTree = eTree</span></span></span><br><span class="line"><span class="function"><span class="params">	<span class="keyword">for</span> i <span class="keyword">in</span> fplist:</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">if</span> i == <span class="string">&#x27;(&#x27;</span>:</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree.insertLeft(<span class="params"><span class="string">&#x27;&#x27;</span></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			<span class="comment"># 入栈下降</span></span></span></span><br><span class="line"><span class="function"><span class="params">			pStack.push(<span class="params">currentTree</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree= currentTree.getLeftChild</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">elif</span> i <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;+&#x27;</span>,<span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;*&#x27;</span>,<span class="string">&#x27;/&#x27;</span>,<span class="string">&#x27;)&#x27;</span>]:</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree.setRootVal(<span class="params"><span class="built_in">int</span>(<span class="params">i</span>)</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			<span class="comment"># 出栈上升</span></span></span></span><br><span class="line"><span class="function"><span class="params">			parrent = pStack.pop(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree = parrent</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">elif</span> i <span class="keyword">in</span> [<span class="string">&#x27;+&#x27;</span>,<span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;*&#x27;</span>,<span class="string">&#x27;/&#x27;</span>]：</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree.setRootVal(<span class="params">i</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree.insertRight(<span class="params"><span class="string">&#x27;&#x27;</span></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			pstack.push(<span class="params">currentTree</span>)</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree = currentTree.getRightChild(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">elif</span> i == <span class="string">&#x27;)&#x27;</span>:</span></span></span><br><span class="line"><span class="function"><span class="params">			currentTree = pStack.pop(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">else</span> :</span></span></span><br><span class="line"><span class="function"><span class="params">			<span class="keyword">raise</span> ValueError</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">return</span> eTree</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">&quot;&quot;&quot;</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">求值</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">&quot;&quot;&quot;</span>	</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">import</span> operator</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">def</span> evaluate(<span class="params">parseTree</span>):</span></span></span><br><span class="line"><span class="function"><span class="params">		opers = &#123;<span class="string">&#x27;+&#x27;</span>:operator.add,<span class="string">&#x27;-&#x27;</span>:operator.sub\</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="string">&#x27;*&#x27;</span>:operator.mul,<span class="string">&#x27;/&#x27;</span>:operator.truediv&#125;</span></span></span><br><span class="line"><span class="function"><span class="params">		</span></span></span><br><span class="line"><span class="function"><span class="params">		leftC = parseTree.getLeftChild(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		rightC = parseTree.getRightChild(<span class="params"></span>)</span></span></span><br><span class="line"><span class="function"><span class="params">		</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">if</span> leftC <span class="keyword">and</span> rightC:</span></span></span><br><span class="line"><span class="function"><span class="params">			fn = opers[parseTree.getRootVal(<span class="params"></span>)]</span></span></span><br><span class="line"><span class="function"><span class="params">			<span class="keyword">return</span> fn(<span class="params">evaluate(<span class="params">leftC</span>),evaluate(<span class="params">rightC</span>)</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="params">		<span class="keyword">else</span> :</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="params">			<span class="keyword">return</span> parseTree.getRootVal(<span class="params"></span>)		</span></span></span></span><br></pre></td></tr></table></figure>
</details>

<h2 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h2><p>前序遍历：根节点-》左子树-》右子树；一本书的章节阅读<br>中序遍历：左子树-》根节点-》右子树<br>后序遍历：左子树-》右子树-》根节点</p>
<details>
  <summary>前序遍历</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">tree</span>):</span></span><br><span class="line">	<span class="keyword">if</span> tree:</span><br><span class="line">		print(tree.getRootVal())</span><br><span class="line">		preorder(tree.getLeftChild())</span><br><span class="line">		preorder(tree.getRightChild())</span><br><span class="line"><span class="comment">#在类中实现</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">self</span>):</span></span><br><span class="line">	print(self.key):</span><br><span class="line">	<span class="keyword">if</span> self.leftChild:</span><br><span class="line">		self.leftChild.preorder()</span><br><span class="line">	<span class="keyword">if</span> self.rightChild:</span><br><span class="line">		self.rightChild.preorder()</span><br></pre></td></tr></table></figure>
</details>

<details>
  <summary>后序遍历：表达式求值</summary>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postordereval</span><span class="params">(tree)</span></span><span class="symbol">:</span></span><br><span class="line">	opers = &#123;<span class="string">&#x27;+&#x27;</span><span class="symbol">:operator</span>.add,<span class="string">&#x27;-&#x27;</span><span class="symbol">:operator</span>.sub\</span><br><span class="line">		<span class="string">&#x27;*&#x27;</span><span class="symbol">:operator</span>.mul,<span class="string">&#x27;/&#x27;</span><span class="symbol">:operator</span>.truediv&#125;</span><br><span class="line">	</span><br><span class="line">	res1 = None</span><br><span class="line">	res2 = None</span><br><span class="line">	<span class="keyword">if</span> <span class="symbol">tree:</span></span><br><span class="line">		res1 = postordereval(tree.getLeftChild())</span><br><span class="line">		res2 = postordereval(tree.getRightChild())</span><br><span class="line">		<span class="keyword">if</span> res1 <span class="keyword">and</span> <span class="symbol">res2:</span></span><br><span class="line">			<span class="keyword">return</span> opers[tree.getRootVal()].(res1,res2)</span><br><span class="line">		<span class="keyword">else</span> </span><br><span class="line">			<span class="keyword">return</span> tree.getRootVal()</span><br></pre></td></tr></table></figure>
</details>

<details>
  <summary>中序遍历：生成全括号中缀表达式</summary>
<figure class="highlight isbl"><table><tr><td class="code"><pre><span class="line"><span class="variable">def</span> <span class="function"><span class="title">printexp</span>(<span class="variable">tree</span>):</span></span><br><span class="line"><span class="function">	<span class="variable">sVal</span> = <span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="function">	<span class="variable"><span class="keyword">if</span></span> <span class="variable">tree</span>:</span></span><br><span class="line"><span class="function">		<span class="variable">sVal</span> = <span class="string">&#x27;(&#x27;</span> + <span class="title">printexp</span>(<span class="variable">tree.getLeftChild</span>())</span></span><br><span class="line">		<span class="variable">sVal</span> = <span class="variable">sVal</span> + <span class="function"><span class="title">str</span>(<span class="variable">tree.getRootVal</span>())</span></span><br><span class="line">		<span class="variable">sVal</span> = <span class="variable">sVal</span> + <span class="function"><span class="title">printexp</span>(<span class="variable">tree.getRightChild</span>())+<span class="string">&#x27;)&#x27;</span></span></span><br><span class="line"><span class="function">	<span class="variable">return</span> <span class="variable">sVal</span></span></span><br></pre></td></tr></table></figure>
</details>

<h2 id="优先队列和二叉堆"><a href="#优先队列和二叉堆" class="headerlink" title="优先队列和二叉堆"></a>优先队列和二叉堆</h2><ul>
<li>优先队列<br>操作系统调度</li>
<li>二叉堆实现优先队列<br>采用完全二叉树来近似实现平衡（非嵌套列表）<br>堆次序：任何一条路径均是一个已排序数列</li>
</ul>
<details>
  <summary>二叉堆实现</summary>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">class BinHeap:</span><br><span class="line">	def __init__(<span class="built_in">self</span>):</span><br><span class="line">	#占位，无用。为了后面代码可以简单整数乘除方法实现</span><br><span class="line">		<span class="built_in">self</span>.heapList = [<span class="number">0</span>]</span><br><span class="line">		<span class="built_in">self</span>.currentSize = <span class="number">0</span></span><br><span class="line">	</span><br><span class="line">	def percUp(<span class="built_in">self</span>,i):</span><br><span class="line">		<span class="keyword">while</span> i//<span class="number">2</span> &gt;<span class="number">0</span>:</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">self</span>.heapList[i] &lt; <span class="built_in">self</span>.heapList(i//<span class="number">2</span>]:</span><br><span class="line">				tmp = <span class="built_in">self</span>.heapList[i//<span class="number">2</span>]</span><br><span class="line">				<span class="built_in">self</span>.heapList[i//<span class="number">2</span>] = <span class="built_in">self</span>.heapList[i]</span><br><span class="line">				<span class="built_in">self</span>.heapList[i] = tmp</span><br><span class="line">			i = i//<span class="number">2</span></span><br><span class="line">			</span><br><span class="line">	def <span class="built_in">insert</span>(<span class="built_in">self</span>,k):</span><br><span class="line">		<span class="built_in">self</span>.heapList.append(k)</span><br><span class="line">		<span class="built_in">self</span>.currentSize = <span class="built_in">self</span>.currentSize+<span class="number">1</span></span><br><span class="line">		<span class="built_in">self</span>.percUp(<span class="built_in">self</span>.currentSize)</span><br><span class="line">		</span><br><span class="line">	def percDown(<span class="built_in">self</span>,i_:</span><br><span class="line">		<span class="keyword">while</span> (i*<span class="number">2</span>)&lt;= <span class="built_in">self</span>.currentSize:</span><br><span class="line">			mc = <span class="built_in">self</span>.minChild(i)</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">self</span>.heapList[i] &gt; <span class="built_in">self</span>.heapList[mc]:</span><br><span class="line">				tmp = <span class="built_in">self</span>.heapList[i]</span><br><span class="line">				<span class="built_in">self</span>.heapList[i] = <span class="built_in">self</span>.heapList[mc]</span><br><span class="line">				<span class="built_in">self</span>.heapList[mc] = tmp</span><br><span class="line">			i = mc</span><br><span class="line">	</span><br><span class="line">	def minChild(<span class="built_in">self</span>,i):</span><br><span class="line">		<span class="keyword">if</span> i*<span class="number">2</span>+<span class="number">1</span> &gt; <span class="built_in">self</span>.currentSize:</span><br><span class="line">			<span class="keyword">return</span> i*<span class="number">2</span></span><br><span class="line">		<span class="keyword">else</span> :</span><br><span class="line">			<span class="keyword">if</span> <span class="built_in">self</span>.heapList[i*<span class="number">2</span>]&lt;<span class="built_in">self</span>.heapList[i*<span class="number">2</span>+<span class="number">1</span>]</span><br><span class="line">				<span class="keyword">return</span> i*<span class="number">2</span></span><br><span class="line">			<span class="keyword">else</span> :</span><br><span class="line">				<span class="keyword">return</span> i*<span class="number">2</span>+<span class="number">1</span></span><br><span class="line">	</span><br><span class="line">	def delMin(<span class="built_in">self</span>):</span><br><span class="line">		retval = <span class="built_in">self</span>.heapList[<span class="number">1</span>]</span><br><span class="line">		<span class="built_in">self</span>.heapList[<span class="number">1</span>] = <span class="built_in">self</span>.heapList[<span class="built_in">self</span>.currentSize]</span><br><span class="line">		<span class="built_in">self</span>.currentSize = <span class="built_in">self</span>.currentSize - <span class="number">1</span></span><br><span class="line">		<span class="built_in">self</span>.heapList.pop()</span><br><span class="line">		<span class="keyword">return</span> retval</span><br><span class="line">		</span><br><span class="line">	def buildHeap(<span class="built_in">self</span>,alist):</span><br><span class="line">		i = <span class="built_in">len</span>(alist)//<span class="number">2</span></span><br><span class="line">		<span class="built_in">self</span>.currentSize = <span class="built_in">len</span>(alist)</span><br><span class="line">		<span class="built_in">self</span>.heapList = [<span class="number">0</span>] +alist[:]</span><br><span class="line">		<span class="built_in">print</span> (<span class="built_in">len</span>(<span class="built_in">self</span>.heapList),i)</span><br><span class="line">		<span class="keyword">while</span>(i &gt;<span class="number">0</span>):</span><br><span class="line">			<span class="built_in">print</span>(<span class="built_in">self</span>.heapList,i)</span><br><span class="line">			<span class="built_in">self</span>.percDown(i)</span><br><span class="line">			i = i<span class="number">-1</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="built_in">self</span>.heapList,i)</span><br><span class="line">		</span><br></pre></td></tr></table></figure>
</details>

<h2 id="二叉查找树"><a href="#二叉查找树" class="headerlink" title="二叉查找树"></a>二叉查找树</h2><p>有序表数据结构+二分搜索算法<br>散列表数据结构+散列及重复解决算法<br>比父节点小的key都出现在左子树，比父节点大的key都出现在右子树</p>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>DS&amp;A</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法python版 - 递归、分治、动态规划</title>
    <url>/2021/02/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95python%E7%89%88-%E9%80%92%E5%BD%92%E3%80%81%E5%88%86%E6%B2%BB%E3%80%81%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<h2 id="分治策略"><a href="#分治策略" class="headerlink" title="分治策略"></a>分治策略</h2><p>分而治之</p>
<ol>
<li>将问题分为若干更小规模的部分</li>
<li>通过解决每一个小规模部分问题,并将结果汇总得到原问题的解</li>
</ol>
<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><ol>
<li>递归三定律<br>基本结束条件，解决最小规模问题<br>缩小规模，向基本结束条件演进<br>调用自身来解决已缩小规模的相同问题</li>
<li>体现了分治策略<br>问题解决依赖于若干缩小了规模的问题<br>汇总得到原问题的解</li>
<li>应用<br>排序、查找、遍历、求值等等</li>
</ol>
<h2 id="贪心策略"><a href="#贪心策略" class="headerlink" title="贪心策略"></a>贪心策略</h2><p>是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，<br>从而希望导致结果是最好或最优的算法。比如在旅行推销员问题中，如果旅行员每次都选择最近的城市，那这就是一种贪心算法。<br>贪心算法在有最优子结构的问题中尤为有效。最优子结构的意思是局部最优解能决定全局最优解。<br>简单地说，问题能够分解成子问题来解决，子问题的最优解能递推到最终问题的最优解。</p>
<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>动态规划其实和分治策略是类似的，也是将一个原问题分解为若干个规模较小的子问题，递归的求解这些子问题，然后合并子问题的解得到原问题的解。<br>区别在于这些子问题会有重叠，一个子问题在求解后，可能会再次求解，于是我们想到将这些子问题的解存储起来，当下次再次求解这个子问题时，直接拿过来就是<br>用动态规划能解决的问题分治策略肯定能解决，只是运行时间较长。<br>因此，分治策略一般用来解决子问题相互对立的问题，称为标准分治，而动态规划用来解决子问题重叠的问题</p>
]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>DS&amp;A</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow入门 - nlp</title>
    <url>/2021/02/09/Tensorflow%E5%85%A5%E9%97%A8-nlp/</url>
    <content><![CDATA[<h2 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h2><details>
<summary>文本生成-tensorflow</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, LSTM, Dense, Bidirectional</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(time.time())</span></span><br><span class="line">tokenizer = Tokenizer()</span><br><span class="line"></span><br><span class="line">data=<span class="string">&quot;In the town of Athy one Jeremy Lanigan \n Battered away til he hadnt a pound. \nHis father died and made him a man again \n Left him a farm and ten acres of ground. \nHe gave a grand party for friends and relations \nWho didnt forget him when come to the wall, \nAnd if youll but listen Ill make your eyes glisten \nOf the rows and the ructions of Lanigans Ball. \nMyself to be sure got free invitation, \nFor all the nice girls and boys I might ask, \nAnd just in a minute both friends and relations \nWere dancing round merry as bees round a cask. \nJudy ODaly, that nice little milliner, \nShe tipped me a wink for to give her a call, \nAnd I soon arrived with Peggy McGilligan \nJust in time for Lanigans Ball. \nThere were lashings of punch and wine for the ladies, \nPotatoes and cakes; there was bacon and tea, \nThere were the Nolans, Dolans, OGradys \nCourting the girls and dancing away. \nSongs they went round as plenty as water, \nThe harp that once sounded in Taras old hall,\nSweet Nelly Gray and The Rat Catchers Daughter,\nAll singing together at Lanigans Ball. \nThey were doing all kinds of nonsensical polkas \nAll round the room in a whirligig. \nJulia and I, we banished their nonsense \nAnd tipped them the twist of a reel and a jig. \nAch mavrone, how the girls got all mad at me \nDanced til youd think the ceiling would fall. \nFor I spent three weeks at Brooks Academy \nLearning new steps for Lanigans Ball. \nThree long weeks I spent up in Dublin, \nThree long weeks to learn nothing at all,\n Three long weeks I spent up in Dublin, \nLearning new steps for Lanigans Ball. \nShe stepped out and I stepped in again, \nI stepped out and she stepped in again, \nShe stepped out and I stepped in again, \nLearning new steps for Lanigans Ball. \nBoys were all merry and the girls they were hearty \nAnd danced all around in couples and groups, \nTil an accident happened, young Terrance McCarthy \nPut his right leg through miss Finnertys hoops. \nPoor creature fainted and cried Meelia murther, \nCalled for her brothers and gathered them all. \nCarmody swore that hed go no further \nTil he had satisfaction at Lanigans Ball. \nIn the midst of the row miss Kerrigan fainted, \nHer cheeks at the same time as red as a rose. \nSome of the lads declared she was painted, \nShe took a small drop too much, I suppose. \nHer sweetheart, Ned Morgan, so powerful and able, \nWhen he saw his fair colleen stretched out by the wall, \nTore the left leg from under the table \nAnd smashed all the Chaneys at Lanigans Ball. \nBoys, oh boys, twas then there were runctions. \nMyself got a lick from big Phelim McHugh. \nI soon replied to his introduction \nAnd kicked up a terrible hullabaloo. \nOld Casey, the piper, was near being strangled. \nThey squeezed up his pipes, bellows, chanters and all. \nThe girls, in their ribbons, they got all entangled \nAnd that put an end to Lanigans Ball.&quot;</span></span><br><span class="line"></span><br><span class="line">corpus = data.lower().split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">tokenizer.fit_on_texts(corpus)</span><br><span class="line">total_words = <span class="built_in">len</span>(tokenizer.word_index) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index)</span><br><span class="line">print(total_words)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_sequences = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> corpus:</span><br><span class="line">	token_list = tokenizer.texts_to_sequences([line])[<span class="number">0</span>]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(token_list)):</span><br><span class="line">		n_gram_sequence = token_list[:i+<span class="number">1</span>]</span><br><span class="line">		input_sequences.append(n_gram_sequence)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pad sequences </span></span><br><span class="line">max_sequence_len = <span class="built_in">max</span>([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> input_sequences])</span><br><span class="line">input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=<span class="string">&#x27;pre&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create predictors and label</span></span><br><span class="line">xs, labels = input_sequences[:,:-<span class="number">1</span>],input_sequences[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)</span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;in&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;the&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;town&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;of&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;athy&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;one&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;jeremy&#x27;</span>])</span><br><span class="line">print(tokenizer.word_index[<span class="string">&#x27;lanigan&#x27;</span>])</span><br><span class="line"></span><br><span class="line">print(xs[<span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">print(tokenizer.word_index)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(total_words, <span class="number">64</span>, input_length=max_sequence_len-<span class="number">1</span>))</span><br><span class="line">model.add(Bidirectional(LSTM(<span class="number">20</span>)))</span><br><span class="line">model.add(Dense(total_words, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">history = model.fit(xs, ys, epochs=<span class="number">500</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_graphs</span>(<span class="params">history, string</span>):</span></span><br><span class="line">  plt.plot(history.history[string])</span><br><span class="line">  plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">  plt.ylabel(string)</span><br><span class="line">  plt.show()</span><br><span class="line"> </span><br><span class="line">plot_graphs(history, <span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">seed_text = <span class="string">&quot;Laurence went to dublin&quot;</span></span><br><span class="line">next_words = <span class="number">100</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(next_words):</span><br><span class="line">	token_list = tokenizer.texts_to_sequences([seed_text])[<span class="number">0</span>]</span><br><span class="line">	token_list = pad_sequences([token_list], maxlen=max_sequence_len-<span class="number">1</span>, padding=<span class="string">&#x27;pre&#x27;</span>)</span><br><span class="line">	predicted = model.predict_classes(token_list, verbose=<span class="number">0</span>)</span><br><span class="line">	output_word = <span class="string">&quot;&quot;</span></span><br><span class="line">	<span class="keyword">for</span> word, index <span class="keyword">in</span> tokenizer.word_index.items():</span><br><span class="line">		<span class="keyword">if</span> index == predicted:</span><br><span class="line">			output_word = word</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">	seed_text += <span class="string">&quot; &quot;</span> + output_word</span><br><span class="line">print(seed_text) </span><br><span class="line"><span class="comment">#print(time.time())</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><details>
<summary>文本分类 - tensorflow</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">vocab_size = <span class="number">10000</span></span><br><span class="line">embedding_dim = <span class="number">16</span></span><br><span class="line">max_length = <span class="number">100</span></span><br><span class="line">trunc_type=<span class="string">&#x27;post&#x27;</span></span><br><span class="line">padding_type=<span class="string">&#x27;post&#x27;</span></span><br><span class="line">oov_tok = <span class="string">&quot;&lt;OOV&gt;&quot;</span></span><br><span class="line">training_size = <span class="number">20000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../../tensorflow_datasets/sarcasm.json&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    datastore = json.load(f)</span><br><span class="line"></span><br><span class="line">sentences = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> datastore:</span><br><span class="line">    sentences.append(item[<span class="string">&#x27;headline&#x27;</span>])</span><br><span class="line">    labels.append(item[<span class="string">&#x27;is_sarcastic&#x27;</span>])</span><br><span class="line"></span><br><span class="line">training_sentences = sentences[<span class="number">0</span>:training_size]</span><br><span class="line">testing_sentences = sentences[training_size:]</span><br><span class="line">training_labels = labels[<span class="number">0</span>:training_size]</span><br><span class="line">testing_labels = labels[training_size:]</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)</span><br><span class="line">tokenizer.fit_on_texts(training_sentences)</span><br><span class="line"></span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line"></span><br><span class="line">training_sequences = tokenizer.texts_to_sequences(training_sentences)</span><br><span class="line">training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line"></span><br><span class="line">testing_sequences = tokenizer.texts_to_sequences(testing_sentences)</span><br><span class="line">testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),</span><br><span class="line">    tf.keras.layers.GlobalAveragePooling1D(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">24</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,optimizer=<span class="string">&#x27;adam&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">30</span></span><br><span class="line">training_padded = np.array(training_padded)</span><br><span class="line">training_labels = np.array(training_labels)</span><br><span class="line">testing_padded = np.array(testing_padded)</span><br><span class="line">testing_labels = np.array(testing_labels)</span><br><span class="line">history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_graphs</span>(<span class="params">history, string</span>):</span></span><br><span class="line">  plt.plot(history.history[string])</span><br><span class="line">  plt.plot(history.history[<span class="string">&#x27;val_&#x27;</span>+string])</span><br><span class="line">  plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">  plt.ylabel(string)</span><br><span class="line">  plt.legend([string, <span class="string">&#x27;val_&#x27;</span>+string])</span><br><span class="line">  plt.show()</span><br><span class="line">  </span><br><span class="line">plot_graphs(history, <span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">plot_graphs(history, <span class="string">&quot;loss&quot;</span>)</span><br><span class="line"></span><br><span class="line">reverse_word_index = <span class="built_in">dict</span>([(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode_sentence</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join([reverse_word_index.get(i, <span class="string">&#x27;?&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> text])</span><br><span class="line"></span><br><span class="line">print(decode_sentence(training_padded[<span class="number">0</span>]))</span><br><span class="line">print(training_sentences[<span class="number">2</span>])</span><br><span class="line">print(labels[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">e = model.layers[<span class="number">0</span>]</span><br><span class="line">weights = e.get_weights()[<span class="number">0</span>]</span><br><span class="line">print(weights.shape) <span class="comment"># shape: (vocab_size, embedding_dim)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">out_v = io.<span class="built_in">open</span>(<span class="string">&#x27;vecs.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">out_m = io.<span class="built_in">open</span>(<span class="string">&#x27;meta.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> word_num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, vocab_size):</span><br><span class="line">  word = reverse_word_index[word_num]</span><br><span class="line">  embeddings = weights[word_num]</span><br><span class="line">  out_m.write(word + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">  out_v.write(<span class="string">&#x27;\t&#x27;</span>.join([<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> embeddings]) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">out_v.close()</span><br><span class="line">out_m.close()</span><br><span class="line"></span><br><span class="line">sentence = [<span class="string">&quot;granny starting to fear spiders in the garden might be real&quot;</span>, <span class="string">&quot;game of thrones season finale showing this sunday night&quot;</span>]</span><br><span class="line">sequences = tokenizer.texts_to_sequences(sentence)</span><br><span class="line">padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</span><br><span class="line">print(model.predict(padded))</span><br></pre></td></tr></table></figure>
</details>

<h2 id="时间序列和预测"><a href="#时间序列和预测" class="headerlink" title="时间序列和预测"></a>时间序列和预测</h2><h3 id="时序信号生成"><a href="#时序信号生成" class="headerlink" title="时序信号生成"></a>时序信号生成</h3><h3 id="时间序列预测方法"><a href="#时间序列预测方法" class="headerlink" title="时间序列预测方法"></a>时间序列预测方法</h3><p>传统：移动平均法</p>
<h3 id="RNN网络样本"><a href="#RNN网络样本" class="headerlink" title="RNN网络样本"></a>RNN网络样本</h3><ol>
<li>生成窗口数据并转化为列表</li>
</ol>
<details>
<summary>RNN网络样本</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="comment"># %tensorflow_version only exists in Colab.</span></span><br><span class="line">  %tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成序列数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> dataset:</span><br><span class="line">   print(val.numpy())</span><br><span class="line">   </span><br><span class="line"><span class="comment"># 获得窗口数据，窗口大小为5</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> window_dataset <span class="keyword">in</span> dataset:</span><br><span class="line">  <span class="keyword">for</span> val <span class="keyword">in</span> window_dataset:</span><br><span class="line">    print(val.numpy(), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">  print()</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 去掉不完整的数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> window_dataset <span class="keyword">in</span> dataset:</span><br><span class="line">  <span class="keyword">for</span> val <span class="keyword">in</span> window_dataset:</span><br><span class="line">    print(val.numpy(), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">  print()</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 转为numpy列表</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.batch(<span class="number">2</span>).perfetch(<span class="number">1</span>)	</span><br><span class="line"><span class="keyword">for</span> window <span class="keyword">in</span> dataset:</span><br><span class="line">  print(window.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打散数据</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(x.numpy(), y.numpy())</span><br><span class="line">  </span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(x.numpy(), y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据批量，每两个数据为一批次</span></span><br><span class="line">dataset = tf.data.Dataset.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">dataset = dataset.window(<span class="number">5</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(<span class="number">5</span>))</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>:]))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">  print(<span class="string">&quot;x = &quot;</span>, x.numpy())</span><br><span class="line">  print(<span class="string">&quot;y = &quot;</span>, y.numpy())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h3 id="RNN时间序列预测"><a href="#RNN时间序列预测" class="headerlink" title="RNN时间序列预测"></a>RNN时间序列预测</h3><details>
<summary>RNN时间序列预测</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="comment"># %tensorflow_version only exists in Colab.</span></span><br><span class="line">  %tensorflow_version <span class="number">2.</span>x</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_series</span>(<span class="params">time, series, <span class="built_in">format</span>=<span class="string">&quot;-&quot;</span>, start=<span class="number">0</span>, end=<span class="literal">None</span></span>):</span></span><br><span class="line">    plt.plot(time[start:end], series[start:end], <span class="built_in">format</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Value&quot;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trend</span>(<span class="params">time, slope=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> slope * time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonal_pattern</span>(<span class="params">season_time</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Just an arbitrary pattern, you can change it if you wish&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.where(season_time &lt; <span class="number">0.4</span>,</span><br><span class="line">                    np.cos(season_time * <span class="number">2</span> * np.pi),</span><br><span class="line">                    <span class="number">1</span> / np.exp(<span class="number">3</span> * season_time))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonality</span>(<span class="params">time, period, amplitude=<span class="number">1</span>, phase=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Repeats the same pattern at each period&quot;&quot;&quot;</span></span><br><span class="line">    season_time = ((time + phase) % period) / period</span><br><span class="line">    <span class="keyword">return</span> amplitude * seasonal_pattern(season_time)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise</span>(<span class="params">time, noise_level=<span class="number">1</span>, seed=<span class="literal">None</span></span>):</span></span><br><span class="line">    rnd = np.random.RandomState(seed)</span><br><span class="line">    <span class="keyword">return</span> rnd.randn(<span class="built_in">len</span>(time)) * noise_level</span><br><span class="line"></span><br><span class="line">time = np.arange(<span class="number">4</span> * <span class="number">365</span> + <span class="number">1</span>, dtype=<span class="string">&quot;float32&quot;</span>)  <span class="comment">#1461</span></span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">series = trend(time, <span class="number">0.1</span>)  </span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">amplitude = <span class="number">40</span></span><br><span class="line">slope = <span class="number">0.05</span></span><br><span class="line">noise_level = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the series</span></span><br><span class="line">series = baseline + trend(time, slope) + seasonality(time, period=<span class="number">365</span>, amplitude=amplitude)</span><br><span class="line"><span class="comment"># Update with noise</span></span><br><span class="line">series += noise(time, noise_level, seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">split_time = <span class="number">1000</span></span><br><span class="line">time_train = time[:split_time]</span><br><span class="line">x_train = series[:split_time]</span><br><span class="line">time_valid = time[split_time:]</span><br><span class="line">x_valid = series[split_time:]</span><br><span class="line"></span><br><span class="line">window_size = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">shuffle_buffer_size = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="comment">#参数说明： 序列数据（一维数组），窗口大小，批次大小，随机缓存大小</span></span><br><span class="line"><span class="comment">#输出： (特征， 标签)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">windowed_dataset</span>(<span class="params">series, window_size, batch_size, shuffle_buffer</span>):</span></span><br><span class="line">  dataset = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">  dataset = dataset.window(window_size + <span class="number">1</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(window_size + <span class="number">1</span>))</span><br><span class="line">  dataset = dataset.shuffle(shuffle_buffer).<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>]))</span><br><span class="line">  dataset = dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">for</span> x,y <span class="keyword">in</span> dataset:</span><br><span class="line">    print(<span class="string">&quot;x = &quot;</span>, x.numpy())</span><br><span class="line">    print(<span class="string">&quot;y = &quot;</span>, y.numpy())</span><br><span class="line">  <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建SimpleRNN神经网络，使用LR_scheduler机制调整学习率</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">train_set = windowed_dataset(x_train, window_size, batch_size=<span class="number">128</span>, shuffle_buffer=shuffle_buffer_size)</span><br><span class="line"><span class="comment">#神经网络的搭建</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment">#匿名层：处理输入参数，将输入</span></span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),  <span class="comment"># tf.expand_dims(x,axis=-1) x是input,-1代表最后一维，对应y=时间序列</span></span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>, return_sequences=<span class="literal">True</span>),<span class="comment">#RNN单元数量为40，返回输出序列中的完整序列</span></span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>), <span class="comment">#神经元个数为1</span></span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)<span class="comment">#x的规则</span></span><br><span class="line">])</span><br><span class="line"><span class="comment">#运用lrscheduler来进行学习率的调节 epoch=10的-8次 * 10^(epoch/20)</span></span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    <span class="keyword">lambda</span> epoch: <span class="number">1e-8</span> * <span class="number">10</span>**(epoch / <span class="number">20</span>))</span><br><span class="line"><span class="comment">#SGD随机梯度下降，lr=学习率，momentum：动量参数</span></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">1e-8</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment">#model.compile()方法用于在配置训练方法时候，告知训练时所用的优化器、损失函数和准确率评测</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),<span class="comment">#损失函数</span></span><br><span class="line">              optimizer=optimizer,<span class="comment">#优化器</span></span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])<span class="comment">#准确率评判</span></span><br><span class="line">history = model.fit(train_set, epochs=<span class="number">100</span>, callbacks=[lr_schedule])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.semilogx(history.history[<span class="string">&quot;lr&quot;</span>], history.history[<span class="string">&quot;loss&quot;</span>])</span><br><span class="line">plt.axis([<span class="number">1e-8</span>, <span class="number">1e-4</span>, <span class="number">0</span>, <span class="number">30</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建SimpleRNN神经网络，不调整学习率</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size=<span class="number">128</span>, shuffle_buffer=shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>, return_sequences=<span class="literal">True</span>),</span><br><span class="line">  tf.keras.layers.SimpleRNN(<span class="number">40</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">#在需要将隐层的结果作为下一层的输入时，选择return_sequences=True</span></span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">5e-5</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),</span><br><span class="line">              optimizer=optimizer,</span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">history = model.fit(dataset,epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">forecast=[]</span><br><span class="line"><span class="keyword">for</span> time <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(series) - window_size):</span><br><span class="line"><span class="comment">#增加一个轴</span></span><br><span class="line">  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))</span><br><span class="line"></span><br><span class="line">forecast = forecast[split_time-window_size:]</span><br><span class="line">results = np.array(forecast)[:, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plot_series(time_valid, x_valid)</span><br><span class="line">plot_series(time_valid, results)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line">tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从训练集和测试集上获取结果列表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.image  <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">mae=history.history[<span class="string">&#x27;mae&#x27;</span>]</span><br><span class="line">loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs=<span class="built_in">range</span>(<span class="built_in">len</span>(loss)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(ehs, mae, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">epochs_zoom = epochs[<span class="number">20</span>:]</span><br><span class="line">mae_zoom = mae[<span class="number">20</span>:]</span><br><span class="line">loss_zoom = loss[<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot Zoomed MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs_zoom, mae_zoom, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs_zoom, loss_zoom, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h3 id="双向LSTM时间序列预测"><a href="#双向LSTM时间序列预测" class="headerlink" title="双向LSTM时间序列预测"></a>双向LSTM时间序列预测</h3><details>
<summary>双向LSTM时间序列预测</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="comment"># 搭建两个LSTM神经网络，一个使用LR_scheduler机制调整学习率，另一个不做处理</span></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#@title Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># https://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line">!pip install tf-nightly-<span class="number">2.0</span>-preview</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成时间序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_series</span>(<span class="params">time, series, <span class="built_in">format</span>=<span class="string">&quot;-&quot;</span>, start=<span class="number">0</span>, end=<span class="literal">None</span></span>):</span></span><br><span class="line">    plt.plot(time[start:end], series[start:end], <span class="built_in">format</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;Time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;Value&quot;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trend</span>(<span class="params">time, slope=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> slope * time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonal_pattern</span>(<span class="params">season_time</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Just an arbitrary pattern, you can change it if you wish&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.where(season_time &lt; <span class="number">0.4</span>,</span><br><span class="line">                    np.cos(season_time * <span class="number">2</span> * np.pi),</span><br><span class="line">                    <span class="number">1</span> / np.exp(<span class="number">3</span> * season_time))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seasonality</span>(<span class="params">time, period, amplitude=<span class="number">1</span>, phase=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Repeats the same pattern at each period&quot;&quot;&quot;</span></span><br><span class="line">    season_time = ((time + phase) % period) / period</span><br><span class="line">    <span class="keyword">return</span> amplitude * seasonal_pattern(season_time)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noise</span>(<span class="params">time, noise_level=<span class="number">1</span>, seed=<span class="literal">None</span></span>):</span></span><br><span class="line">    rnd = np.random.RandomState(seed)</span><br><span class="line">    <span class="keyword">return</span> rnd.randn(<span class="built_in">len</span>(time)) * noise_level</span><br><span class="line"></span><br><span class="line">time = np.arange(<span class="number">4</span> * <span class="number">365</span> + <span class="number">1</span>, dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">series = trend(time, <span class="number">0.1</span>)  </span><br><span class="line">baseline = <span class="number">10</span></span><br><span class="line">amplitude = <span class="number">40</span></span><br><span class="line">slope = <span class="number">0.05</span></span><br><span class="line">noise_level = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the series</span></span><br><span class="line">series = baseline + trend(time, slope) + seasonality(time, period=<span class="number">365</span>, amplitude=amplitude)</span><br><span class="line"><span class="comment"># Update with noise</span></span><br><span class="line">series += noise(time, noise_level, seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">split_time = <span class="number">1000</span></span><br><span class="line">time_train = time[:split_time]</span><br><span class="line">x_train = series[:split_time]</span><br><span class="line">time_valid = time[split_time:]</span><br><span class="line">x_valid = series[split_time:]</span><br><span class="line"></span><br><span class="line">window_size = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">shuffle_buffer_size = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟生成数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">windowed_dataset</span>(<span class="params">series, window_size, batch_size, shuffle_buffer</span>):</span></span><br><span class="line">  dataset = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">  dataset = dataset.window(window_size + <span class="number">1</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  dataset = dataset.flat_map(<span class="keyword">lambda</span> window: window.batch(window_size + <span class="number">1</span>))</span><br><span class="line">  dataset = dataset.shuffle(shuffle_buffer).<span class="built_in">map</span>(<span class="keyword">lambda</span> window: (window[:-<span class="number">1</span>], window[-<span class="number">1</span>]))</span><br><span class="line">  dataset = dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">return</span> dataset</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 搭建双向LSTM神经网络，使用LR_scheduler机制调整学习率</span></span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    <span class="keyword">lambda</span> epoch: <span class="number">1e-8</span> * <span class="number">10</span>**(epoch / <span class="number">20</span>))</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(lr=<span class="number">1e-8</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.Huber(),</span><br><span class="line">              optimizer=optimizer,</span><br><span class="line">              metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line"><span class="comment"># 回调函数  使用LR_scheduler机制调整学习率</span></span><br><span class="line">history = model.fit(dataset, epochs=<span class="number">100</span>, callbacks=[lr_schedule])</span><br><span class="line"></span><br><span class="line">plt.semilogx(history.history[<span class="string">&quot;lr&quot;</span>], history.history[<span class="string">&quot;loss&quot;</span>])</span><br><span class="line">plt.axis([<span class="number">1e-8</span>, <span class="number">1e-4</span>, <span class="number">0</span>, <span class="number">30</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建双向LSTM神经网络，对学习率不作处理</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">tf.random.set_seed(<span class="number">51</span>)</span><br><span class="line">np.random.seed(<span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-5</span>, momentum=<span class="number">0.9</span>),metrics=[<span class="string">&quot;mae&quot;</span>])</span><br><span class="line">history = model.fit(dataset,epochs=<span class="number">100</span>,verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">forecast = []</span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> time <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(series) - window_size):</span><br><span class="line">  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))</span><br><span class="line"></span><br><span class="line">forecast = forecast[split_time-window_size:]</span><br><span class="line">results = np.array(forecast)[:, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plot_series(time_valid, x_valid)</span><br><span class="line">plot_series(time_valid, results)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果对比，计算误差loss和平均绝对误差MAE</span></span><br><span class="line">tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image  <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">mae=history.history[<span class="string">&#x27;mae&#x27;</span>]</span><br><span class="line">loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs=<span class="built_in">range</span>(<span class="built_in">len</span>(loss)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs, mae, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">epochs_zoom = epochs[<span class="number">20</span>:]</span><br><span class="line">mae_zoom = mae[<span class="number">20</span>:]</span><br><span class="line">loss_zoom = loss[<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot Zoomed MAE and Loss</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs_zoom, mae_zoom, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.plot(epochs_zoom, loss_zoom, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MAE and Loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Accuracy&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;MAE&quot;</span>, <span class="string">&quot;Loss&quot;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整不同的学习率和神经网络层数来训练</span></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>))</span><br><span class="line">model.fit(dataset,epochs=<span class="number">100</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.keras.backend.clear_session()</span><br><span class="line">dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.expand_dims(x, axis=-<span class="number">1</span>),</span><br><span class="line">                      input_shape=[<span class="literal">None</span>]),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>)),</span><br><span class="line">  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="number">32</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100.0</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mse&quot;</span>, optimizer=tf.keras.optimizers.SGD(lr=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>))</span><br><span class="line">model.fit(dataset,epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</details>]]></content>
      <categories>
        <category>notes</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱及应用案例</title>
    <url>/2021/03/02/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8F%8A%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<blockquote>
<p><a href="http://reader.epubee.com/books/mobile/cc/cc219bda88f77cd8612c76540dd98cef/text00014.html">http://reader.epubee.com/books/mobile/cc/cc219bda88f77cd8612c76540dd98cef/text00014.html</a></p>
</blockquote>
<h1 id="知识图谱基础概念"><a href="#知识图谱基础概念" class="headerlink" title="知识图谱基础概念"></a>知识图谱基础概念</h1><ol>
<li>知识建模<br>自上而下、自下而上</li>
<li>知识存储<br>单一式存储和混合式存储<br>单一式存储中，可以通过三元组、属性表或者垂直分割等方式进行知识的存储<br>其中，三元组的存储方式较为直观，但在进行连接查询时开销巨大<br>属性表指基于主语的类型划分数据表，其缺点是不利于缺失属性的查询<br>垂直分割指基于谓词进行数据的划分，其缺点是数据表过多，且写操作的代价比较大<br>对于知识存储介质的选择，可以分为原生（Neo4j、AllegroGraph 等）和基于现有数据库（MySQL、Mongo 等）两类。<br>原生存储的优点是其本身已经提供了较为完善的图查询语言或算法的支持，但不支持定制，灵活程度不高，对于复杂节点等极端数据情况的表现非常差。<br>因此，有了基于现有数据库的自定义方案，这样做的好处是自由程度高，可以根据数据特点进行知识的划分、索引的构建等，但增加了开发和维护成本。</li>
<li>知识抽取<br>知识抽取是指从不同来源、不同数据中进行知识提取，形成知识并存入知识图谱的过程。<br>由于真实世界中的数据类型及介质多种多样，所以如何高效、稳定地从不同的数据源进行数据接入至关重要，其会直接影响到知识图谱中数据的规模、实时性及有效性。<br>在现有的数据源中，数据大致可分为三类：一类是结构化的数据，这类数据包括以关系数据库（MySQL、Oracle 等）为介质的关系型数据，以及开放链接数据，如 Yago、Freebase 等；<br>第二类为半结构化数据，如百科数据（Wikipedia、百度百科等），或是垂直网站中的数据，如IMDB、丁香园等；<br>第三类是以文本为代表的非结构化数据。</li>
<li>知识融合<br>知识融合指将不同来源的知识进行对齐、合并的工作，形成全局统一的知识标识和关联。<br>知识融合是知识图谱构建中不可缺少的一环，知识融合体现了开放链接数据中互联的思想。<br>良好的融合方法能有效地避免信息孤岛，使得知识的连接更加稠密，提升知识应用价值，因此知识融合是构建知识图谱过程中的核心工作与重点研究方向。<br>知识图谱中的知识融合包含两个方面，即数据模式层的融合和数据层的融合。<br>数据模式层的融合包含概念合并、概念上下位关系合并以及概念的属性定义合并，通常依靠专家人工构建或从可靠的结构化数据中映射生成。在映射的过程中，<br>一般会通过设置融合规则确保数据的统一。<br>数据层的融合包括实体合并、实体属性融合以及冲突检测与解决。<br>进行知识融合时需要考虑使用什么方式实现不同来源、不同形态知识的融合；<br>如何对海量知识进行高效融合[7] ；如何对新增知识进行实时融合以及如何进行多语言融合</li>
<li>知识计算<br>知识计算是领域知识图谱能力输出的主要方式，通过知识图谱本身能力为传统的应用形态赋能，提升服务质量和效率。<br>其中，图挖掘计算和知识推理是最具代表性的两种能力，如何将这两种能力与传统应用相结合是需要解决的一个关键问题。</li>
<li>知识应用<br>知识应用是指将知识图谱特有的应用形态与领域数据和业务场景相结合，助力领域业务转型。<br>知识图谱的典型应用包括语义搜索、智能问答以及可视化决策支持。如何针对业务需求设计实现知识图谱应用，<br>并基于数据特点进行优化调整，是知识图谱应用的关键研究内容。<br>其中，语义搜索是指基于知识图谱中的知识，解决传统搜索中遇到的关键字语义多样性及语义消歧的难题，通过实体链接实现知识与文档的混合检索。<br>语义检索需要考虑如何解决自然语言输入带来的表达多样性问题，同时需要解决语言中实体的歧义性问题。<br>而智能问答是指针对用户输入的自然语言进行理解，从知识图谱或目标数据中给出用户问题的答案。智能问答的关键技术及难点包括：<br>1）准确的语义解析，如何正确理解用户的真实意图。<br>2）对于返回的答案，如何评分以确定优先级顺序。<br>可视化决策支持则指通过提供统一的图形接口，结合可视化、推理、检索等，为用户提供信息获取的入口。<br>对于可视化决策支持，需要考虑的关键问题包括：如何通过可视化方式辅助用户快速发现业务模式；<br>如何提升可视化组件的交互友好程度，例如高效地缩放和导航；大规模图环境下底层算法的效率。</li>
</ol>
<h1 id="领域知识图谱的应用案例"><a href="#领域知识图谱的应用案例" class="headerlink" title="领域知识图谱的应用案例"></a>领域知识图谱的应用案例</h1><p>典型的通用知识图谱项目有 DBpedia、WordNet、ConceptNet、YAGO、Wikidata 等</p>
<ol>
<li>电商知识图谱<br>当下，电商的交易规模巨大，对每个人的生活都有影响。随着 O2O 和零售行业的发展，电商交易场景不再是单纯的线上交易场景，而是新零售、多语言、<br>线上线下相结合的复杂购物场景，电商企业对数据互联的需求越来越强烈。<br>在此基础上，电商交易逐渐转变为集 B2C、B2B、跨境为一体，覆盖“实物+虚拟”商品，结合跨领域搜索发现、导购、交互多功能的新型电商交易。<br>因而电商知识图谱变得非常重要。相对于通用知识图谱，它有很多不同之处。<br>首先，电商平台是围绕着商品，买卖双方在线上进行交易的平台。<br>故而电商知识图谱的核心是商品。整个商业活动中有品牌商、平台运营、消费者、国家机构、物流商等多角色参与，<br>相对于网页来说，数据的产生、加工、使用、反馈控制得更加严格，约束性更强。<br>如果电商数据以知识图谱的方法组织，可以从数据的生产端开始，就遵循顶层设计。<br>电商数据的结构化程度相对于通用域来说做得更好。<br>此外，面向不同的消费者和细分市场，不同角色、不同市场、不同平台对商品描述的侧重都不同，<br>使得对同一个实体描述时会有不同的定义。知识融合就变得非常重要。最后，与通用知识图谱比较而言，电商知识图谱有大量的国家标准、<br>行业规则、法律法规对商品描述进行着约束。存在大量的人的经验来描述商品做到跟消费者需求的匹配，知识推理显得更为重要。<br>下面以阿里巴巴知识图谱为例，介绍电商知识图谱的相应技术模块和应用。<br>在商品知识的表示方面，电商知识图谱以商品为核心，以人、货、场为主要框架。目前共涉及9大类一级本体和27大类二级本体。<br>一级本体分别为人、货、场、百科知识、行业竞争对手、品质、类目、资质和舆情。人、货、场构成了商品信息流通的闭环，其他本体主要给予商品更丰富的信息描述。<br>如图9-3所示为电商知识图谱的数据模型，数据来源包含国内—国外数据、商业—国家数据、线上—线下等多源数据。目前有百亿级的节点和百亿级的关系边。</li>
</ol>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里三大营销模型</title>
    <url>/2021/03/03/%E9%98%BF%E9%87%8C%E4%B8%89%E5%A4%A7%E8%90%A5%E9%94%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<ol>
<li>AIPL</li>
<li>FAST</li>
<li>GROW<blockquote>
<p><a href="http://www.woshipm.com/marketing/3321749.html">http://www.woshipm.com/marketing/3321749.html</a></p>
</blockquote>
</li>
</ol>
<h1 id="AIPL模型"><a href="#AIPL模型" class="headerlink" title="AIPL模型"></a>AIPL模型</h1><p>首次实现品牌人群资产定量化、链路化运营<br>A（Awareness），品牌认知人群。包括被品牌广告触达和品类词搜索的人；<br>I（Interest），品牌兴趣人群。包括广告点击、浏览品牌/店铺主页、参与品牌互动、浏览产品详情页、品牌词搜索、领取试用、订阅/关注/入会、加购收藏的人；<br>P（Purchase），品牌购买人群，指购买过品牌商品的人；<br>L（Loyalty），品牌忠诚人群，包括复购、评论、分享的人。<br>比如：针对“A人群”量太少这个问题，除了在站内可以通过“一夜霸屏”资源投放品牌广告外，还可以整合品牌市场部的资源来做投放拉新。传统媒介投放都是媒体投完之后，媒介公司给到甲方一些传播层面的数据，比如有多少曝光、多少点击这样，但是如果这些媒体用Uni Desk做投放，这些触达的用户数据还可以通过阿里的Uni ID匹配沉淀到数据银行，成为新增“A人群”。<br>再比如：针对链路中“I人群”到“P人群”流转率太低的问题，说明店铺目前缺少销售转化机制，做法是先把“I人群”根据标签分成不同的群组，有的可能是对促销折扣敏感，那就可以通过钻展给他们推送店铺折扣信息来做收割；而有的是通过明星活动拉进来的，那或许可以通过一些明星周边货品来吸引他们做下一步的购买动作。</p>
<h1 id="FAST模型"><a href="#FAST模型" class="headerlink" title="FAST模型"></a>FAST模型</h1><p>从数量和质量上衡量消费者运营健康度模型<br>如果说AIPL是帮助商家了解品牌人群资产总量，以及各链路人群的多少，那么FAST就是在此基础上，又从数量和质量两个维度，来衡量品牌在人群资产运营是否健康的模型。<br>A （Advancing），指AIPL人群转化率。多场景提高消费者活跃度，促进人群链路正向流转；多渠道种草人群沉淀后，进一步筛选优质人群，通过钻展渠道进行广告触达；品牌内沉淀人群细分，对消费者进行分层运营，差异化营销，促进整体消费者的流转与转化；<br>S（Superiority），高价值人群总量-会员总量。会员/粉丝人群对于品牌而言价值巨大，能够为品牌大 促提供惊人的爆发力；通过线上线下联动、联合品牌营销，以及借助平台的新零售等场景如天猫 U 先、淘宝彩蛋、智能母婴室扩大品牌的会员/粉丝量级，为后续的会员/粉丝运营打下基础；<br>T（Thriving），高价值人群活跃率-会员活跃率。借势大促，提高会员/粉丝活跃度，激发会员/粉丝 潜在价值，为品牌 GMV目标完成提供助力；对会员/粉丝按照 RFM 指标进行分层运营，优化激活效率，千人千权触达惩戒，公私域结合，赋能会员/粉丝运营；<br>FAST体系在数量指标层面，提供全网消费人群总量（Fertility）和高价值人群-会员总量 （Superiority）；在质量指标层面，提供了人群转化率 （Advancing）和会员活跃率 （Thriving）。</p>
<h1 id="GROW模型"><a href="#GROW模型" class="headerlink" title="GROW模型"></a>GROW模型</h1><p>指导大快消行业品类有的放矢的增长模型<br>增长，应该是营销人永恒的课题。特别是在互联网流量红利见顶下的存量时代，增长变得愈发的“难”。通常难在3个地方：找不到帮助品类增长的方向、缺乏明确的品类增长抓手、品类增长效率较低。<br>于是，作为如今定位为商业操作系统的阿里，就提出了适用于母婴、食品、家清、美妆、医药保健和个护等几大一级类目的大快消行业增长“仪表盘”——GROW模型。GROW中的4个单词分别代表着影响品类增长的“决策因子”：</p>
<p>渗透力（Gain）: 指消费者购买更多类型品类 / 产品对品牌总增长机会的贡献；<br>复购力（Retain）: 指消费者更频繁 / 重复购买产品对品牌总增长机会的贡献；<br>价格力（bOOst）: 指消费者购买价格升级产品对品牌总增长机会的贡献；<br>延展力（Widen）: 指品牌通过提供现有品类外其他关联类型产品所贡献的总增长机会。</p>
]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>营销</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark机器学习、自然语言处理与推荐系统</title>
    <url>/2021/03/11/pyspark%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>RDD会使用最后一个时点的数据流创建一个新的RDD,并且就算出现任何错误,也总是拥有重构的能力.<br>Spark Core 负责任务管理、I/O操作、容错以及内存管理等.</p>
<h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><p>无监督：<br>聚类算法<br>维度降低技术<br>主题模型<br>关联规则挖掘</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习是依托一套奖励系统来运行的，主要基于智能体为变更状态而执行某些操作，从而尝试最大化奖励来进行决策。<br>（智能体、操作、奖励、环境、状态)</p>
<h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><p>加载和读取数据</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span> <span class="keyword">import</span> SparkSession</span><br><span class="line">spark=SparkSession.builder.appName(<span class="string">&#x27;data_processing&#x27;</span>).getOrCreate()</span><br><span class="line"># 自行推断数据集中的数据类型</span><br><span class="line">df=spark.<span class="keyword">read</span>.csv(<span class="string">&#x27;sample_data.csv&#x27;</span>,inferSchema=<span class="keyword">True</span>,<span class="keyword">header</span>=<span class="keyword">True</span>)</span><br><span class="line">print((df,ciybt),(len*=(df.<span class="keyword">columns</span>))</span><br><span class="line">df.printSchema()</span><br><span class="line">df.<span class="keyword">show</span>(<span class="number">5</span>)</span><br><span class="line">df.<span class="keyword">select</span>(<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;mobile&#x27;</span>).<span class="keyword">show</span>(<span class="number">5</span>)</span><br><span class="line">df.describe().<span class="keyword">show</span>()</span><br><span class="line"># 添加一个新列</span><br><span class="line">df.withColumn(&quot;age_after_10yrs&quot;,(df[&quot;age&quot;]+<span class="number">10</span>)).<span class="keyword">show</span>(<span class="number">10</span>,Falwe)</span><br><span class="line"><span class="keyword">from</span> pyspark.<span class="keyword">sql</span>.<span class="keyword">types</span> <span class="keyword">import</span> StringType,DoubleType</span><br><span class="line">df.withColumn(<span class="string">&#x27;age_double&#x27;</span>,df[<span class="string">&#x27;age&#x27;</span>].cast(DoubleType())).<span class="keyword">show</span>(<span class="number">10</span>,<span class="keyword">False</span>)</span><br><span class="line">df.<span class="keyword">filter</span>(df[<span class="string">&#x27;mobile&#x27;</span>]==<span class="string">&#x27;Vivo&#x27;</span>).<span class="keyword">show</span>()</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>work-related</category>
      </categories>
      <tags>
        <tag>pyspark</tag>
        <tag>udf</tag>
      </tags>
  </entry>
</search>
